{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a792e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyPDF2\n",
    "# import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dad3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_list = []\n",
    "\n",
    "# for page in pdf_text[2:]:\n",
    "#     doc = nlp(page)\n",
    "#     for sentence in doc.sents:\n",
    "#         sent_list.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df52c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_articles = 'data/articles'\n",
    "fname_out = 'data_structured/article_sentences.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36633a-df5e-4d84-8d17-435d6fb27270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coca-cola.pdf', 'nestle.pdf', 'p&g.pdf', 'pepsico.pdf', 'unilever.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3445efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnt(text):\n",
    "    cnt = 0\n",
    "    for word in text.split():\n",
    "        if word.isalnum():\n",
    "            cnt += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a99207d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(block_lst):\n",
    "\n",
    "    \n",
    "    text_lst = []\n",
    "    for block in block_lst:\n",
    "        if block[6] != 0: continue # block_type: 0 = text\n",
    "    \n",
    "        text = ''.join([i if ord(i) < 128 else ' ' for i in block[4]]) #removes non-ascii characters already \n",
    "        #text = text.replace('fi ', 'fi') # PyMuPDF(fitz) bug fix: 'fi ' --> 'fi'\n",
    "    \n",
    "        #if get_cnt(text) > 5: \n",
    "        text_lst.append(text)\n",
    "        \n",
    "    return (text_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed39987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sent = sent_tokenize(text)[2]\n",
    "\n",
    "# r_sent = ' '.join(test_sent.split()) #split splits the words of the sentence into a list - and gets rid of /n etc.\n",
    "\n",
    "# ' '.join(test_sent.split()) #joins the items of the list with a space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb346fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sentence(fname, skip_page = (0,)):\n",
    " \n",
    "#     doc = fitz.open(fname)\n",
    "    \n",
    "#     sent_lst = []\n",
    "#     for page_no, page in enumerate(doc):\n",
    "\n",
    "#         # Skip page\n",
    "#         if page_no+1 in skip_page: continue\n",
    "        \n",
    "#         block_lst = page.get_text_blocks()\n",
    "#         text = get_text(block_lst)\n",
    "        \n",
    "# #         for i,sentence in enumerate(text):\n",
    "# #             if sentence == \"Body\\n\":\n",
    "# #                 beg = i+1\n",
    "# #             if sentence == \"Classification\\n\":\n",
    "# #                 end = i\n",
    "# #                 lst += tester[beg:end]\n",
    "    \n",
    "#         for i, sentence in enumerate(sent_tokenize(text)):\n",
    "#             r_sent = ' '.join(sentence.split()) # Delete '\\n', '\\t' and strip\n",
    "#             sent_lst.append(r_sent)\n",
    "            \n",
    "#     doc.close()\n",
    "\n",
    "#     return sent_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79a96f84-2a61-4807-ba30-4e83a827426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence(fname):\n",
    " \n",
    "    doc = fitz.open(fname)\n",
    "    \n",
    "    text_lst = []\n",
    "    for page_no, page in enumerate(doc):\n",
    "        block_lst = page.get_text_blocks()\n",
    "        text = get_text(block_lst)\n",
    "        text_lst += text\n",
    "    \n",
    "    lst = []\n",
    "    for i,text in enumerate(text_lst):\n",
    "        if text == \"Body\\n\":\n",
    "            beg = i+1\n",
    "        if text == \"End of Document\\n\":\n",
    "            end = i\n",
    "            chunk = text_lst[beg:end]\n",
    "            chunk[:] = (text for text in chunk if get_cnt(text) > 5)\n",
    "        # for block in chunk:\n",
    "        #     if get_cnt(block) < 5:\n",
    "        #         chunk.remove(block)\n",
    "        #     #block.replace('-\\n', '')\n",
    "            to_tokenize ='\\n'.join(chunk)\n",
    "            sent_lst = []\n",
    "            for i, sentence in enumerate(sent_tokenize(to_tokenize)):\n",
    "                r_sent = ' '.join(sentence.split())\n",
    "                sent_lst.append(r_sent)\n",
    "            lst += sent_lst\n",
    "        \n",
    "# for block in lst:\n",
    "#     if get_cnt(block) < 5:\n",
    "#         lst.remove(block)\n",
    "#     #block.replace('-\\n', '')\n",
    "# to_tokenize ='\\n'.join(lst)\n",
    "    \n",
    "# sent_lst = []\n",
    "# for i, sentence in enumerate(sent_tokenize(to_tokenize)):\n",
    "#     r_sent = ' '.join(sentence.split())\n",
    "#     sent_lst.append(r_sent)\n",
    "            \n",
    "    doc.close()\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61746d83-a84b-46f9-9676-879c997f95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = fitz.open('coca_cola_nexis.pdf')\n",
    "    \n",
    "# text_lst = []\n",
    "# for page_no, page in enumerate(doc):\n",
    "#     block_lst = page.get_text_blocks()\n",
    "#     text = get_text(block_lst)\n",
    "#     text_lst += text\n",
    "    \n",
    "# lst = []\n",
    "# for i,text in enumerate(text_lst):\n",
    "#     if text == \"Body\\n\":\n",
    "#         beg = i+1\n",
    "#     if text == \"Classification\\n\":\n",
    "#         end = i\n",
    "#         lst += text_lst[beg:end]\n",
    "        \n",
    "# lst[:] = (block for block in lst if get_cnt(block) > 5)\n",
    "#     #block.replace('-\\n', '')\n",
    "# to_tokenize ='\\n'.join(lst)\n",
    "    \n",
    "# sent_lst = []\n",
    "# for i, sentence in enumerate(sent_tokenize(to_tokenize)):\n",
    "#     r_sent = ' '.join(sentence.split())\n",
    "#     sent_lst.append(r_sent)\n",
    "            \n",
    "# doc.close()\n",
    "# sent_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2db731b-360d-43dc-86b4-a399f1b03976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = fitz.open('coca_cola_nexis.pdf')\n",
    "    \n",
    "# text_lst = []\n",
    "# for page_no, page in enumerate(doc):\n",
    "#     block_lst = page.get_text_blocks()\n",
    "#     text = get_text(block_lst)\n",
    "#     text_lst += text\n",
    "    \n",
    "# lst = []\n",
    "# for i,text in enumerate(text_lst):\n",
    "#     if text == \"Body\\n\":\n",
    "#         beg = i+1\n",
    "#     if text == \"Classification\\n\":\n",
    "#         end = i\n",
    "#         chunk = text_lst[beg:end]\n",
    "#         chunk[:] = (text for text in chunk if get_cnt(text) > 5)\n",
    "#         # for block in chunk:\n",
    "#         #     if get_cnt(block) < 5:\n",
    "#         #         chunk.remove(block)\n",
    "#         #     #block.replace('-\\n', '')\n",
    "#         to_tokenize ='\\n'.join(chunk)\n",
    "#         sent_lst = []\n",
    "#         for i, sentence in enumerate(sent_tokenize(to_tokenize)):\n",
    "#             r_sent = ' '.join(sentence.split())\n",
    "#             sent_lst.append(r_sent)\n",
    "#         lst += sent_lst\n",
    "        \n",
    "# # for block in lst:\n",
    "# #     if get_cnt(block) < 5:\n",
    "# #         lst.remove(block)\n",
    "# #     #block.replace('-\\n', '')\n",
    "# # to_tokenize ='\\n'.join(lst)\n",
    "    \n",
    "# # sent_lst = []\n",
    "# # for i, sentence in enumerate(sent_tokenize(to_tokenize)):\n",
    "# #     r_sent = ' '.join(sentence.split())\n",
    "# #     sent_lst.append(r_sent)\n",
    "            \n",
    "# doc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c025765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_document(fname, sent_lst):\n",
    "\n",
    "    res_df = pd.DataFrame(\n",
    "        {\n",
    "            'doc_type': \"news\",\n",
    "            'company': fname.split(\".\")[0],\n",
    "            'sentence': sent_lst\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23aa88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_filelist(path):\n",
    "\n",
    "    # Create empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Read file list (directory)\n",
    "    for idx, fname in enumerate(os.listdir(path)):\n",
    "        p_fname = os.path.join(path, fname)\n",
    "        print('path + fname >>>', p_fname)\n",
    "        \n",
    "        if p_fname.split('.')[-1] != 'PDF': continue\n",
    "        print('fname >>>',fname)\n",
    "    \n",
    "#         doc_id = int(idx)\n",
    "        \n",
    "#         print(f'doc_id = [{doc_id}], fname = [{fname}]')\n",
    "#         print('')\n",
    "    \n",
    "        sent_lst = get_sentence(p_fname)\n",
    "        df_doc   = gen_document(fname, sent_lst)\n",
    "        \n",
    "        df = pd.concat([df,df_doc])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24b348bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path + fname >>> data/articles\\coca-cola.PDF\n",
      "fname >>> coca-cola.PDF\n",
      "path + fname >>> data/articles\\nestle.PDF\n",
      "fname >>> nestle.PDF\n",
      "path + fname >>> data/articles\\pepsico.PDF\n",
      "fname >>> pepsico.PDF\n",
      "path + fname >>> data/articles\\procter-gamble.PDF\n",
      "fname >>> procter-gamble.PDF\n",
      "path + fname >>> data/articles\\unilever.PDF\n",
      "fname >>> unilever.PDF\n",
      "==== End of jobs ====\n",
      "CPU times: total: 4.72 s\n",
      "Wall time: 5.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = read_filelist(path_articles)\n",
    "print('==== End of jobs ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bad321ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Recycling is one of the actions that the Mexic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>This will drive, in addition to returnability,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Reducing waste in the country is a priority is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>\"We continue to evolve, always committed to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Is this investment a great opportunity to grow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>Similarly, they will contribute to their globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>This goal is part of Unilever's ambitions in i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>\"Producing large amounts of healthy and sustai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>There is a rapid transition in the food indust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>lvm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6046 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_type    company                                           sentence\n",
       "0        news  coca-cola  Recycling is one of the actions that the Mexic...\n",
       "1        news  coca-cola  This will drive, in addition to returnability,...\n",
       "2        news  coca-cola  Reducing waste in the country is a priority is...\n",
       "3        news  coca-cola  \"We continue to evolve, always committed to th...\n",
       "4        news  coca-cola  Is this investment a great opportunity to grow...\n",
       "...       ...        ...                                                ...\n",
       "1016     news   unilever  Similarly, they will contribute to their globa...\n",
       "1017     news   unilever  This goal is part of Unilever's ambitions in i...\n",
       "1018     news   unilever  \"Producing large amounts of healthy and sustai...\n",
       "1019     news   unilever  There is a rapid transition in the food indust...\n",
       "1020     news   unilever                                                lvm\n",
       "\n",
       "[6046 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1551118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.5\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2beaf-8acf-44e7-a373-23b058c29611",
   "metadata": {},
   "source": [
    "# Make a new document from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f31a58f9-ffc8-4f3f-a7fb-98220a1fbdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "143b1b92-b5a2-4f43-b949-7dff41b7d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a3be101-13a0-4660-abd9-71cfd0a8d0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "character_to_remove = r'[^!\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_\\`{|}~\\\\\\\\0-9a-zA-Z]'\n",
    "df_article[\"sentence\"] = df_article[\"sentence\"].str.replace('\"','', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84f9ca84-e7a6-4bfa-a80f-272b779d9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testsentence =  'Feb 09, 2021( Digital Journal: http://www.digitaljournal.com Delivered by Newstex) The soda and beverage giant has often been criticized for being one of the biggest producers of plastic waste.'\n",
    "# s1 = re.sub('http\\S+','',testsentence)\n",
    "# print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac781d6b-a914-42eb-9d47-be93c30e4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = df.iloc[83]['sentence']\n",
    "# s1 = re.sub('http\\S+|\\[.\\d+\\]:|www\\S+|\\w+/\\S+|\\w+-\\w+-\\S+','',t)\n",
    "# s2 = re.sub('^\\s+|\\s+$','',s1)\n",
    "# s3 = re.sub('\\s{2,}',' ',s2)\n",
    "# print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b8cf263c-893b-4de9-bf25-34205625581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nestl sucks balls.  Nestle for some reason does not work\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[1] Nestle sucks balls. [2]: Nestle for some reason does not work'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '[1] Nestl sucks balls. [2]: Nestle for some reason does not work'\n",
    "s = re.sub('\\[.\\]:?','',test)\n",
    "print(s)\n",
    "\n",
    "test = test.replace('Nestl ','Nestle ')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1654f44b-8aad-45a7-b534-c7f75f79e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article[\"sentence\"] = df_article[\"sentence\"].replace(r'http\\S+|\\[.\\]:?|www\\S+|\\w+/\\S+|\\w+-\\w+-\\S+','',regex = True).replace(r'^\\s+|\\s+$','',regex=True).replace(r'\\s{2,}',' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "302e6396-45a3-4e8c-975c-43bf594d843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article['sentence'] = df_article['sentence'].str.replace('Nestl ', 'Nestle ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc95321e-f6de-4d72-8053-2a8da3a5fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article[\"word count\"] = [len(i) for i in df_article[\"sentence\"].str.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f38a85cf-0568-4387-a8d9-ad9ef44548db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article = df_article[df_article[\"word count\"] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fb68b93-0a78-4af9-a2b4-45d546fb906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article = df_article[df_article[\"word count\"] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8e919dd-da9c-4f11-b6b1-37c7e4cf1d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'word count'}>]], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "df_article.hist(column = 'word count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "293f43f4-d59c-4dc2-9dcb-06232cdc53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article.to_csv(fname_out, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14423ce6-8cb6-4b71-a515-5f02143f3035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Recycling is one of the actions that the Mexic...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>This will drive, in addition to returnability,...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Reducing waste in the country is a priority is...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>We continue to evolve, always committed to the...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Is this investment a great opportunity to grow...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>m{1420697} He said such plant-based innovation...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>Similarly, they will contribute to their globa...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>This goal is part of Unilever's ambitions in i...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>Producing large amounts of healthy and sustain...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>news</td>\n",
       "      <td>unilever</td>\n",
       "      <td>There is a rapid transition in the food indust...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_type    company                                           sentence  \\\n",
       "0        news  coca-cola  Recycling is one of the actions that the Mexic...   \n",
       "1        news  coca-cola  This will drive, in addition to returnability,...   \n",
       "2        news  coca-cola  Reducing waste in the country is a priority is...   \n",
       "3        news  coca-cola  We continue to evolve, always committed to the...   \n",
       "4        news  coca-cola  Is this investment a great opportunity to grow...   \n",
       "...       ...        ...                                                ...   \n",
       "1015     news   unilever  m{1420697} He said such plant-based innovation...   \n",
       "1016     news   unilever  Similarly, they will contribute to their globa...   \n",
       "1017     news   unilever  This goal is part of Unilever's ambitions in i...   \n",
       "1018     news   unilever  Producing large amounts of healthy and sustain...   \n",
       "1019     news   unilever  There is a rapid transition in the food indust...   \n",
       "\n",
       "      word count  \n",
       "0             78  \n",
       "1             30  \n",
       "2             77  \n",
       "3             17  \n",
       "4             24  \n",
       "...          ...  \n",
       "1015          15  \n",
       "1016          20  \n",
       "1017          41  \n",
       "1018          16  \n",
       "1019          42  \n",
       "\n",
       "[5909 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee3c0a-1933-46b8-bc56-8693ca1bfd54",
   "metadata": {},
   "source": [
    "# Loading in CLIMATEbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278a5e2f-7a0f-4557-b4d0-502b82fca0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b0bc10f-1e14-4a2b-896b-bbef57d3373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at climatebert/distilroberta-base-climate-f were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at climatebert/distilroberta-base-climate-f and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "model_name = 'climatebert/distilroberta-base-climate-f'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54986175-80d8-429a-9203-5a907aab46c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at climatebert/distilroberta-base-climate-f were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at climatebert/distilroberta-base-climate-f and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at climatebert/distilroberta-base-climate-f were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at climatebert/distilroberta-base-climate-f and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998254427493864\n"
     ]
    }
   ],
   "source": [
    "z = [\"This product is environmentally friendly.\",\n",
    "    'The offering happens to be good for nature.',\n",
    "    'The product is unsustainable and destroys the environment.']\n",
    "\n",
    "def transformer_embedding (name, inp): \n",
    "    model = AutoModel.from_pretrained(name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "    pipe = pipeline('feature-extraction', model=model, tokenizer = tokenizer)\n",
    "    features = pipe(inp)\n",
    "    features = np.squeeze(features)\n",
    "    return features\n",
    "\n",
    "embedding_features1=transformer_embedding(model_name,z[0])\n",
    "embedding_features2=transformer_embedding(model_name,z[2])\n",
    "distance=1-cosine(embedding_features1[0],embedding_features2[0])\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "753b91de-f669-44ee-9c72-e078b5d32ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1 = df_article['sentence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dab3b747-ad67-4f99-98cc-4c6e3193865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentences1, return_tensors='pt', padding=True, truncation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbc5ea67-f001-44e8-95ce-feecb85f3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31af7410-ffe6-4449-8ce9-1690b556763f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaskedLMOutput' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MaskedLMOutput' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "752e3de2-a588-44d2-b75f-4dc4d8ba6bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.19340062, 0.5186796 , 0.40626413]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the sentences to embed\n",
    "sentences = [\"This product is environmentally friendly.\", \n",
    "             \"Jello is amazing food.\", \n",
    "             \"Hello darkness, my old friend.\"]\n",
    "\n",
    "sentences2 = ['Hello darkness, my old friend.',\n",
    "              'The company is greenwashing.',\n",
    "              'The company has increased its emissions by a large amount.']\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenized = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "# Tokenize the sentences\n",
    "tokenized2 = tokenizer(sentences2, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the embeddings\n",
    "with torch.no_grad():\n",
    "    outputs2 = model(**tokenized2)\n",
    "    embeddings2 = outputs2.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Calculate the cosine similarity between all pairs of embeddings\n",
    "#cos_sim = torch.nn.functional.cosine_similarity(embeddings[0], embeddings2[0])\n",
    "\n",
    "# Convert the similarity matrix to a pandas dataframe\n",
    "#similarity_df = pd.DataFrame(similarity_matrix.numpy(), columns=sentences, index=sentences2)\n",
    "\n",
    "# Print the similarity matrix\n",
    "embeddings = embeddings.detach().numpy()\n",
    "embeddings2 = embeddings2.detach().numpy()\n",
    "\n",
    "cosine_similarity([embeddings[0]],\n",
    "                  embeddings2[0:]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec0b0713-9792-4f37-849d-bd1d5820fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d8e21c51-f30f-4a46-b2d8-16de3cf69b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {'input_ids': [], 'attention_mask': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5fcff12-6b0d-4a2e-a2fc-002541b1303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    new_tokens = tokenizer.encode_plus(sentence, max_length = 512,\n",
    "                          truncation = True, padding = 'max_length',\n",
    "                          return_tensors = 'pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0]) #list within a list - we want to extrac the list with the 0\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ae4ba9a7-f232-4cb0-8f3f-dbc44c4db37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "023a9846-c259-4211-a95a-b84a1138e934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "696433a4-b6c6-4aa0-badc-d2ddad19fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9011aa3b-c744-4288-8cf6-04a1be7d31f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "14c54ce5-84c8-4007-b6a5-ee83f6c46939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 768])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0f3c67d1-aa21-46a1-9eb8-c8131f671cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = tokens['attention_mask']\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "064ab4c9-5ea3-4e18-9295-352dae55eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = attention.unsqueeze(-1).expand(embeddings.shape).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c2831b65-194b-4685-a6fb-b6b88636fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_embeddings = embeddings*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b772926f-69e0-4c8d-bb38-340cf5646b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = torch.sum(mask_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8b63f77c-2c8e-4e10-b850-de081204e7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = torch.clamp(mask.sum(1), min = 1e-9)\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b16c13af-bf5b-4b1c-8483-803a2e67bbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = summed/counts\n",
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9a319f44-635e-49d3-814b-bd7c6c4f2479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4212029 , 0.19536817]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pool = mean_pooled.detach().numpy()\n",
    "\n",
    "cosine_similarity([mean_pool[0]],\n",
    "                  mean_pool[1:]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71bcf19d-6550-4d71-9a25-c45106caebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at climatebert/distilroberta-base-climate-f were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at climatebert/distilroberta-base-climate-f and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score between sentences 1 and 2: 0.0029\n",
      "Similarity score between sentences 2 and 3: 0.0023\n",
      "Similarity score between sentences 3 and 4: 0.0029\n"
     ]
    }
   ],
   "source": [
    "# Load ClimateBERT tokenizer and model\n",
    "model_name = \"climatebert/distilroberta-base-climate-f\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Define input sentences\n",
    "sentences = [\n",
    "    \"This product is environmentally friendly.\",\n",
    "    'The offering happens to be good for nature.',\n",
    "    'The product is unsustainable and destroys the environment.']\n",
    "# Tokenize and encode the sentences\n",
    "encoded_sentences = [tokenizer.encode(s, add_special_tokens=True) for s in sentences]\n",
    "max_len = max(len(s) for s in encoded_sentences)\n",
    "padded_sentences = [s + [tokenizer.pad_token_id] * (max_len - len(s)) for s in encoded_sentences]\n",
    "inputs = torch.tensor(padded_sentences)\n",
    "\n",
    "# Obtain sentence embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "# Normalize the embeddings\n",
    "norm_embeddings = normalize(embeddings.numpy())\n",
    "\n",
    "# Compute cosine similarity between sentence embeddings\n",
    "similarity_matrix = 1 - cosine_similarity(norm_embeddings)\n",
    "\n",
    "# Extract the upper triangular part of the matrix\n",
    "similarity_scores = similarity_matrix[np.triu_indices(len(sentences), k=1)]\n",
    "\n",
    "# Print the similarity scores\n",
    "for i, score in enumerate(similarity_scores):\n",
    "    print(f\"Similarity score between sentences {i+1} and {i+2}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "60dd5325-9333-4ec9-83c7-1c8c14fbc2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0214d64bf0f241388a3b92d52e8a65d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnguyen10\\Anaconda3\\envs\\thesis\\lib\\site-packages\\huggingface_hub-0.13.1-py3.8.egg\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tnguyen10\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0007f546453d41e3b1858aa5f89b76e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66580c2325544e5be50871ca7768d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba51e4388ed42f0baed108d877dd141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cf99d5b2e4467ab32f9abfc571fefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_extraction = pipeline('feature-extraction', model=\"distilroberta-base\", tokenizer=\"distilroberta-base\")\n",
    "features = feature_extraction([\"This product is environmentally friendly.\",\n",
    "                               'The offering happens to be good for nature.',\n",
    "                               'The product is unsustainable and destroys the environment.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1aed2098-282f-4a00-aea3-125572be2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1=np.array(features[0][0][0])\n",
    "sent2=np.array(features[1][0][0])\n",
    "sent3=np.array(features[2][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bebcf9e4-bc2e-4bf7-b2de-959f2a116821",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1=sent1.reshape(1,-1)\n",
    "sent2=sent2.reshape(1,-1)\n",
    "sent3 = sent3.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "650b62c9-4c47-4cc8-acea-05b312bc835a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99916961]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sent2,sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4927f1c4-3fce-4af5-9cd0-e94313446fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
