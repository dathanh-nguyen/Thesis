{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8683c1b0-64ec-4504-a7b7-7651baab993b",
   "metadata": {},
   "source": [
    "# Set-up and data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffcea15-10a6-468e-be7c-db19c7e64778",
   "metadata": {},
   "source": [
    "**Note**: Much of the code here related to loading and processing the reports is taken from https://github.com/llbtl/paper_ssm01/tree/main. Any copyright of the code belongs to the authors of that paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a792e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df52c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pdf = '..\\\\data\\\\reports'\n",
    "fname_out = '..\\\\data_structured\\\\report_sentences.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b6c35-dfa1-43a5-a8a9-2c70e107ccb7",
   "metadata": {},
   "source": [
    "# Loading and Processing the CSR Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba8b7c-346b-4b59-ab74-571b131665d8",
   "metadata": {},
   "source": [
    "The following functions help us process the PDF files (CSR reports) into a table, where each row is represented by a sentence from the report text. I split the document into sentences already as I will generate sentence embeddings later on using S-BERT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3445efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnt(text):\n",
    "    cnt = 0\n",
    "    for word in text.split():\n",
    "        if word.isalnum():\n",
    "            cnt += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99207d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(block_lst):\n",
    "\n",
    "    MIN_WORD_CNT = 6\n",
    "    \n",
    "    text_lst = []\n",
    "    for block in block_lst:\n",
    "        if block[6] != 0: continue # block_type: 0 = text\n",
    "        \n",
    "        #I'm replacing the non-ascii single quotation mark here, because it's used in Coca Cola's report\n",
    "        text = block[4].replace('’',\"'\")\n",
    "        text = ''.join([i if ord(i) < 128 else ' ' for i in text])\n",
    "    \n",
    "        if get_cnt(text) < MIN_WORD_CNT: continue # Delete sentences with less than MIN_WORD_CNT(10) \n",
    "    \n",
    "        text_lst.append(text.replace('-\\n', ''))\n",
    "        #.replace('-\\n', '')\n",
    "    return ('\\n'.join(text_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb346fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sentence(fname):\n",
    " \n",
    "    doc = fitz.open(fname)\n",
    "    \n",
    "    sent_lst = []\n",
    "    for page_no, page in enumerate(doc):\n",
    "        \n",
    "        block_lst = page.get_text_blocks()\n",
    "        text = get_text(block_lst)\n",
    "    \n",
    "        for token in sent_tokenize(text):\n",
    "            sentences = token.split('\\n\\n')\n",
    "            for sentence in sentences:\n",
    "                r_sent = ' '.join(sentence.split()) # Delete '\\n', '\\t' and strip\n",
    "                sent_lst.append(r_sent)\n",
    "            \n",
    "    doc.close()\n",
    "\n",
    "    return sent_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c025765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_document(fname, sent_lst):\n",
    "\n",
    "    res_df = pd.DataFrame(\n",
    "        {\n",
    "            'doc_type': 'report',\n",
    "            'company': fname.split('.')[0],\n",
    "            'sentence': sent_lst\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23aa88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_filelist(path):\n",
    "\n",
    "    # Create empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Read file list (directory)\n",
    "    for idx, fname in enumerate(os.listdir(path)):\n",
    "        p_fname = os.path.join(path, fname)\n",
    "        print('path + fname >>>', p_fname)\n",
    "        \n",
    "        if p_fname.split('.')[-1] != 'pdf': continue\n",
    "        print('fname >>>',fname)\n",
    "    \n",
    "#         doc_id = int(idx)\n",
    "        \n",
    "#         print(f'doc_id = [{doc_id}], fname = [{fname}]')\n",
    "#         print('')\n",
    "    \n",
    "        sent_lst = get_sentence(p_fname)\n",
    "        df_doc   = gen_document(fname, sent_lst)\n",
    "        \n",
    "        df = pd.concat([df,df_doc])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b348bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\abb.pdf\n",
      "fname >>> abb.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\adidas.pdf\n",
      "fname >>> adidas.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\airbus.pdf\n",
      "fname >>> airbus.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\apple.pdf\n",
      "fname >>> apple.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\bayer.pdf\n",
      "fname >>> bayer.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\beiersdorf.pdf\n",
      "fname >>> beiersdorf.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\blackrock.pdf\n",
      "fname >>> blackrock.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\bmw.pdf\n",
      "fname >>> bmw.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\boeing.pdf\n",
      "fname >>> boeing.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\cemex.pdf\n",
      "fname >>> cemex.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\chevron.pdf\n",
      "fname >>> chevron.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\chipotle.pdf\n",
      "fname >>> chipotle.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\citi.pdf\n",
      "fname >>> citi.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\coca-cola.pdf\n",
      "fname >>> coca-cola.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\colgate.pdf\n",
      "fname >>> colgate.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\danone.pdf\n",
      "fname >>> danone.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\dell.pdf\n",
      "fname >>> dell.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\dhl.pdf\n",
      "fname >>> dhl.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\diageo.pdf\n",
      "fname >>> diageo.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\dupont.pdf\n",
      "fname >>> dupont.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\edp.pdf\n",
      "fname >>> edp.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\enel.pdf\n",
      "fname >>> enel.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\eversource.pdf\n",
      "fname >>> eversource.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\exxon.pdf\n",
      "fname >>> exxon.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\ford-motor.pdf\n",
      "fname >>> ford-motor.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\general-mills.pdf\n",
      "fname >>> general-mills.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\google.pdf\n",
      "fname >>> google.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\h&m.pdf\n",
      "fname >>> h&m.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\henkel.pdf\n",
      "fname >>> henkel.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\hershey.pdf\n",
      "fname >>> hershey.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\honda.pdf\n",
      "fname >>> honda.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\hp.pdf\n",
      "fname >>> hp.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\hyundai.pdf\n",
      "fname >>> hyundai.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\ibm.pdf\n",
      "fname >>> ibm.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\inditex.pdf\n",
      "fname >>> inditex.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\intel.pdf\n",
      "fname >>> intel.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\komatsu.pdf\n",
      "fname >>> komatsu.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\linde.pdf\n",
      "fname >>> linde.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\mcdonald.pdf\n",
      "fname >>> mcdonald.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\mercedes.pdf\n",
      "fname >>> mercedes.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\microsoft.pdf\n",
      "fname >>> microsoft.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\mitsubishi.pdf\n",
      "fname >>> mitsubishi.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\mondelez.pdf\n",
      "fname >>> mondelez.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\nestle.pdf\n",
      "fname >>> nestle.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\nextera.pdf\n",
      "fname >>> nextera.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\nike.pdf\n",
      "fname >>> nike.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\p&g.pdf\n",
      "fname >>> p&g.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\pepsico.pdf\n",
      "fname >>> pepsico.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\ralph-lauren.pdf\n",
      "fname >>> ralph-lauren.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\renault.pdf\n",
      "fname >>> renault.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\rio-tinto.pdf\n",
      "fname >>> rio-tinto.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\schneider-electric.pdf\n",
      "fname >>> schneider-electric.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\shell.pdf\n",
      "fname >>> shell.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\sonoco.pdf\n",
      "fname >>> sonoco.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\starbucks.pdf\n",
      "fname >>> starbucks.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\tesco.pdf\n",
      "fname >>> tesco.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\tesla.pdf\n",
      "fname >>> tesla.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\totalenergies.pdf\n",
      "fname >>> totalenergies.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\toyota.pdf\n",
      "fname >>> toyota.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\veolia.pdf\n",
      "fname >>> veolia.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\volkswagen.pdf\n",
      "fname >>> volkswagen.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\volvo.pdf\n",
      "fname >>> volvo.pdf\n",
      "path + fname >>> C:\\Users\\tnguyen10\\OneDrive - Deloitte (O365D)\\Documents\\GitHub\\Thesis\\data\\reports\\walmart.pdf\n",
      "fname >>> walmart.pdf\n",
      "==== End of jobs ====\n",
      "CPU times: total: 1min 40s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = read_filelist(path_pdf)\n",
    "print('==== End of jobs ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a22723d-e071-4aba-b5e5-06bb3e93382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset = ['sentence'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc8ae1-0d0f-448d-bd98-2052402590da",
   "metadata": {},
   "source": [
    "# Further cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d119a78-5986-43ae-a351-68dc152c2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "443bf6a2-4aaf-4360-b64d-a35985e6eead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45892, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84ee4494-2ec2-457b-baf2-5ce65b72e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove double spaces with one space and remove most hyperlinks + remove whitespaces at the end and beginning of a sentence\n",
    "df_report[\"sentence\"] = df_report[\"sentence\"].replace(r'http\\S+|\\[.\\]:?|www\\S+|\\w+/\\S+|\\w+-\\w+-\\S+|\\[|\\]','',regex = True).replace(r'^\\s+|\\s+$','',regex=True).replace(r'\\s{2,}',' ',regex=True)\n",
    "df_report['sentence'] = df_report['sentence'].str.replace('Nestl ', 'Nestle ')\n",
    "df_report['sentence'] = df_report['sentence'].str.replace('Mondel z', 'Mondelez')\n",
    "df_report['sentence'] = df_report['sentence'].str.replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47ad94e-038d-472f-baae-6db62722903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report[\"word count\"] = [len(i) for i in df_report[\"sentence\"].str.split()]\n",
    "df_report = df_report[df_report[\"word count\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de3fe2fb-3ea0-4f66-8bab-9f1f2da1eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b55c1961-a468-424c-b297-29157e49397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my pdf package does not know how to deal with sentences that span across pages - define a funciton here, which will merge the two sentences following each other\n",
    "# if the previous one doesn't end with punctuation and the following starts with a lower case letter\n",
    "import string\n",
    "\n",
    "# define a function to check if a sentence ends with punctuation\n",
    "def ends_with_punctuation(s):\n",
    "    return s.strip()[-1] in string.punctuation\n",
    "\n",
    "# loop over each row in the DataFrame and concatenate the sentences as needed\n",
    "for i, row in df_report.iterrows():\n",
    "    # skip the first row as there is no previous row to compare with\n",
    "    if i == 0:\n",
    "        continue\n",
    "    \n",
    "    # get the current and previous sentences\n",
    "    prev_sentence = df_report.loc[i-1, 'sentence']\n",
    "    curr_sentence = df_report.loc[i, 'sentence']\n",
    "    \n",
    "    # check if the previous sentence ends with punctuation and the current sentence starts with a lowercase letter\n",
    "    if not ends_with_punctuation(prev_sentence) and curr_sentence[0].islower():\n",
    "        # concatenate the sentences with a space\n",
    "        df_report.at[i, 'sentence'] = prev_sentence + ' ' + curr_sentence\n",
    "        # drop the previous row\n",
    "        df_report.drop(i-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8aa393e-becb-4943-90af-38dec3f78318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report[\"word count\"] = [len(i) for i in df_report[\"sentence\"].str.split()]\n",
    "df_report = df_report[df_report[\"word count\"] > 5]\n",
    "df_report = df_report[df_report[\"word count\"] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d394a11-7a27-4300-9f9c-aa3d1cf193b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>One year into ABB's 2030 sustainability strate...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Last year, we recorded no work-related fatalit...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>We also increased the number of women in senio...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45878</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Building on our experiences as a founding memb...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45879</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>LABS works with engineering companies to devel...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45880</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Factories develop supervised corrective action...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45881</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>LABS has been active in India and Vietnam sinc...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45882</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>The program expanded to Cambodia in May 2022 a...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39059 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_type  company                                           sentence  \\\n",
       "0       report      abb  One year into ABB's 2030 sustainability strate...   \n",
       "1       report      abb  Compared with our baseline year of 2019, we ha...   \n",
       "2       report      abb  Last year, we recorded no work-related fatalit...   \n",
       "3       report      abb  We also increased the number of women in senio...   \n",
       "4       report      abb  Alongside these headline achievements, we made...   \n",
       "...        ...      ...                                                ...   \n",
       "45878   report  walmart  Building on our experiences as a founding memb...   \n",
       "45879   report  walmart  LABS works with engineering companies to devel...   \n",
       "45880   report  walmart  Factories develop supervised corrective action...   \n",
       "45881   report  walmart  LABS has been active in India and Vietnam sinc...   \n",
       "45882   report  walmart  The program expanded to Cambodia in May 2022 a...   \n",
       "\n",
       "       word count  \n",
       "0              21  \n",
       "1              27  \n",
       "2              13  \n",
       "3              39  \n",
       "4              26  \n",
       "...           ...  \n",
       "45878          49  \n",
       "45879          20  \n",
       "45880          18  \n",
       "45881          14  \n",
       "45882          17  \n",
       "\n",
       "[39059 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to check if a sentence is comprised of more than half uppercase characters (these are usually nonsensical sentences)\n",
    "def is_mostly_uppercase(sentence):\n",
    "    return sum(1 for c in sentence if c.isupper()) / len(sentence) > 0.5\n",
    "\n",
    "# apply the function to the 'sentence' column and filter out the rows where the condition is True\n",
    "df_report = df_report[~df_report['sentence'].apply(is_mostly_uppercase)]\n",
    "\n",
    "# print the resulting dataframe\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c7988ff-ba1c-472f-bb96-935a13299c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.drop_duplicates(subset = ['sentence'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adfcd0b3-5361-49e6-ab32-def238f629c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a1f7b03a-6dd9-4d0e-89a1-f8d02156237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.to_csv(fname_out, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
