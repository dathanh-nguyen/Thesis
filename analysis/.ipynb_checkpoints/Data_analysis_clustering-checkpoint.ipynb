{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb74356a-3ad6-47d8-b07f-016678130249",
   "metadata": {},
   "source": [
    "# Set-up and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a0760-6129-4c7b-acc1-7ca6d8ff3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer, util, models\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba769ac-f9f1-40f2-8589-3cd758f23b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'C:\\\\Users\\\\tnguyen10\\\\OneDrive - Deloitte (O365D)\\\\Documents\\\\GitHub\\\\Thesis\\\\data_structured'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855aecf7-c11c-4e10-b6ad-29d001a9d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_sentiment = pipeline(model = 'distilbert-base-uncased-finetuned-sst-2-english')\n",
    "sent_embedder = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea4b20-989d-4e2a-88a4-d6084b04ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article = pd.read_pickle('art.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0b0d5-6a03-4aa8-989a-1a0ff4b9f32a",
   "metadata": {},
   "source": [
    "The report already has most of the pre-processing we want done in the pickle state, so we will apply the same changes to the report dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e93834-2d9f-4bdd-8ac7-494da7ed592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.read_csv(os.path.join(path_data,'report_sentences.csv'))\n",
    "df_report = df_report[df_report[\"word count\"] > 5]\n",
    "df_report = df_report[df_report[\"word count\"] < 100]\n",
    "df_report.rename(columns = {'fname':'company'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4d640-af49-486d-831d-588e2c11865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_sent = df_report['sentence'].tolist()\n",
    "report_embeddings = sent_embedder.encode(report_sent)\n",
    "df_report['embeddings'] = list(report_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb864ab0-5b83-4e3e-8ddc-8c952aa48a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.to_pickle('rep.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd8d1ea-dad9-4cd0-9045-363bb11a6240",
   "metadata": {},
   "source": [
    "# Analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283cff8-e705-4f15-b3ca-6897594549ef",
   "metadata": {},
   "source": [
    "## K-Means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895312f-5bcb-4f28-9914-add68b48378b",
   "metadata": {},
   "source": [
    "First, we apply k-means clustering on the existing embeddings to identify the sustainability topic clusters within the text. Following Boelders' approach, we first overlap the embeddings to remove the inherent difference in language between the report and the articles (*not sure if this is necessary - maybe I can use those metrics to see whether it improves the clusters or not*). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e24e51-52c4-447b-8583-24293cb45c7c",
   "metadata": {},
   "source": [
    "### Overlapping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160681c0-30be-4c84-acdc-b414a4b73359",
   "metadata": {},
   "source": [
    "We first calculate the centroids as Boelders did and calculate the difference between the two. This difference is then subtracted from one of the embeddings (the article ones) to remove the inherent difference and create new embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede363d-270a-4d59-8254-6c7bf32f2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_centroid = np.mean(df_article['embeddings'].values, axis = 0)\n",
    "article_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce08e7-879e-497e-86ca-1c7b06b2def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_centroid = np.mean(report_embeddings, axis = 0)\n",
    "report_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b7004-e3dd-42e5-9262-6deb8f238d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = report_centroid - article_centroid \n",
    "# Convert the patents vectors\n",
    "def difference(org_vec):\n",
    "    return org_vec + dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97fba58-20d5-498f-a2ea-824943d5706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art = df_article.copy()\n",
    "df_rep = df_report.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3a212-8cdc-464b-a2d2-49626a3358c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art['new_embeddings'] = df_art['embeddings'].apply(difference)\n",
    "df_rep['new_embeddings'] = df_rep['embeddings']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2649f58-da19-4389-850f-34bf285d18a5",
   "metadata": {},
   "source": [
    "### Running the algorithm and plotting a word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac24a6c-d723-47df-bfe3-c3193b1333f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the two datasets in preparation for the clustering\n",
    "df_comb = pd.concat([df_art, df_rep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772abb97-589f-480c-9b39-4bd40e7dbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling the combined dataset here\n",
    "df_comb.to_pickle('data_structured/comb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0331b-e56b-4c24-9af1-859acd05a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(df,min_k,max_k):\n",
    "    embeddings = list(df['new_embeddings'])\n",
    "    embeddings = np.array(embeddings)\n",
    "    \n",
    "    min_clusters = min_k\n",
    "    max_clusters = max_k\n",
    "    inertias = []\n",
    "    for k in range(min_clusters, max_clusters):\n",
    "        kmeans = KMeans(n_clusters = k, init = 'k-means++',random_state = 1542, n_init = 10).fit(embeddings)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.plot(range(min_clusters, max_clusters), inertias, '-o')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.title('Scree plot')\n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60be4f5-acf8-4c39-bb28-39851241846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clusters(df,k):\n",
    "    embeddings = list(df['new_embeddings'])\n",
    "    embeddings = np.array(embeddings)\n",
    "    kmeans = KMeans(n_clusters = k, init = 'k-means++',random_state = 1542, n_init = 10).fit(embeddings)\n",
    "    clusters = kmeans.labels_\n",
    "    df['clusters'] = clusters\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf7d46-8fd2-4fb3-bc1f-2443039108eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud(df, cluster):\n",
    "    cluster_text = ' '.join([sentence for sentence in df[df['clusters'] == cluster]['sentence'].str.lower()])\n",
    "    word_cloud = WordCloud(collocation_threshold = 2, width = 1000, height = 500, background_color = 'white'\n",
    "                      ).generate(cluster_text)\n",
    "\n",
    "    plt.figure(figsize = (10,5))\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis('off')\n",
    "    return plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105deb48-0a25-4721-94be-c55550b9123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(df_comb, 2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc74274-e5cc-4965-8d97-3d308b75980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = add_clusters(df_comb, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6f9c2-f2e8-4041-9ba6-5f8c76da60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df_comb, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74d226-00e6-45ba-b765-adf78b851c85",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93328481-97b2-4edc-84bb-6de02418cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb['sentiment'] = df_comb['sentence'].map(lambda x: pipe_sentiment(x)[0]['label'])\n",
    "df_comb['sentiment_score'] = df_comb['sentence'].map(lambda x: pipe_sentiment(x)[0]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db093f3-13b7-4fcd-981f-1ff7b2051f65",
   "metadata": {},
   "source": [
    "Similarly to Kang and Kim we reverse negative scores, so all the scores are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9686e07-7b47-42ae-9b16-3829666f18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_score(row):\n",
    "    if row['sentiment'] == 'NEGATIVE':\n",
    "        return 1 - row['sentiment_score']\n",
    "    else:\n",
    "        return row['sentiment_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5269b-65d2-4b15-a516-8a62e6765294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb['sentiment_score'] = df_comb.apply(reverse_score, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb044c-15b2-4722-9751-21979a759817",
   "metadata": {},
   "source": [
    "### Score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463ebd9-5917-4da7-a93b-d7dfd99a35df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd71b86-7d83-4214-b2eb-32173b226837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff95d92-0467-47f1-957a-f2063a2786d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
