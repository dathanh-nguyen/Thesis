{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66c81ae-bf25-4c7e-aedc-83cdb2540b23",
   "metadata": {},
   "source": [
    "# Set-up and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7ea0dd-fb65-491b-99fc-4fb59463c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer, util, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ead8ee9-829b-4667-a182-9dce6cac5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'C:\\\\Users\\\\tnguyen10\\\\OneDrive - Deloitte (O365D)\\\\Documents\\\\GitHub\\\\Thesis\\\\data_structured'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8606a26-1cc5-4a94-bb56-562dbe6a32d8",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1908e6a8-38eb-429d-8b2c-f1a70e339679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.read_csv(os.path.join(path_data,'report_sentences.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a4bada9-bf96-4bc9-87fe-c14def1871a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdf = pd.read_csv(os.path.join(path_data,'article_sentences_pdf.csv'))\n",
    "df_gnews = pd.read_csv(os.path.join(path_data,'article_sentences_gnews.csv'))\n",
    "df_article = pd.concat([df_pdf,df_gnews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd1e7d02-ec01-4a0b-ac37-e329efa90d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = df_report[df_report[\"word count\"] > 5]\n",
    "df_report = df_report[df_report[\"word count\"] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee41a973-ef80-46de-b499-78fb30701713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.rename(columns = {'fname':'company'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "592184b6-bf51-4875-91f1-8915d324a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article = df_article[df_article[\"word count\"] > 5]\n",
    "df_article = df_article[df_article[\"word count\"] < 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bc05c-484a-4081-9493-099b1b069b32",
   "metadata": {},
   "source": [
    "# Applying the pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99b2683-8ac1-49a8-bf58-9c2871cd6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_checker = pipeline(model = \"climatebert/environmental-claims\")\n",
    "sem_search = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "nli_model = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7625233a-959f-4dcf-b9e6-220ae96f5d33",
   "metadata": {},
   "source": [
    "The claim verification model consists of three stages - claim identification, evidence sentence selection and finally inference analysis. The three models above will help us achieve these three tasks. The ClimateBERT model is pre-trained to detect environmental and climate claims, semantic search will help us identify the 5 most relevant sentences from the corpus and finally the actual model can be used to check the entailment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d3e25-0f4f-44b6-a19e-61ac94148326",
   "metadata": {},
   "source": [
    "First, we apply the ClimateBERT model to identify environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff3a59cf-a6ed-48ab-b0a5-e0dcc6bb656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report['claim'] = df_report['sentence'].map(lambda x: claim_checker(x)[0]['label'])\n",
    "df_report['claim_score'] = df_report['sentence'].map(lambda x: claim_checker(x)[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7481b47-28b4-427e-adfa-df700fb71c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims = df_report[df_report['claim']=='yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c316f-b561-4249-b7ab-47dc60a70ed0",
   "metadata": {},
   "source": [
    "Now we create the sentence embeddings using the semantic search model. These embeddings will be used by the sentence transformers package to find the top 5 most similar sentences from the article corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63a36ad0-1a65-4caa-b9b2-9b85003f37a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnguyen10\\AppData\\Local\\Temp\\ipykernel_25844\\2746180871.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['embeddings'] = list(claims_embeddings)\n"
     ]
    }
   ],
   "source": [
    "claims_sent = df_claims['sentence'].tolist()\n",
    "claims_embeddings = sem_search.encode(claims_sent)\n",
    "df_claims['embeddings'] = list(claims_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5999e0f-8c14-4aef-af13-788eb7988901",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_sent = df_article['sentence'].tolist()\n",
    "article_embeddings = sem_search.encode(article_sent)\n",
    "df_article['embeddings'] = list(article_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728f552-a3b8-49b1-83d9-3cf96800e9e7",
   "metadata": {},
   "source": [
    "Since this took a while I will also pickle these to save my progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ee4f17-52d7-4072-9765-91a2708dbf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_article.to_pickle('art.pkl')\n",
    "# df_claims.to_pickle('claims.pkl')\n",
    "df_claims = pd.read_pickle('claims.pkl')\n",
    "df_article = pd.read_pickle('art.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75201a1e-dd5c-450a-a1e8-80bda9135b53",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sentence transformers has a utility called semantic search which can be used to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "810a93c3-b6db-4a3c-a476-750d808090c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in df_claims.iterrows():\n",
    "    query_embedding = row['embeddings']\n",
    "    company = row['company']\n",
    "    # search only the article embeddings/sentences of the specific company\n",
    "    corpus_embeddings = df_article[df_article['company']==company]['embeddings'].values\n",
    "    top_5 = util.semantic_search(torch.Tensor(query_embedding), torch.Tensor(list(corpus_embeddings)), top_k = 5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbd249-9b35-44c9-bc13-753777ab9925",
   "metadata": {},
   "source": [
    "Let us now create a new dataframe based on df_claims, which will store the same information as this dataframe, but will also additionally hold the top 5 most similar sentences in a separate column, as well as whether these sentences entail, contradict or are neutral towards each other. I use the MoritzLaurer NLI model for this purpose as it states that it is the best performing NLI model as of June 2022. The code used for the classification is mostly copied from the HuggingFace transformers website and modified for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fecfe0c6-d3f5-412a-addd-a2f29c52eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entailment = df_claims.copy()\n",
    "df_entailment.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bb41abc-2c0a-48aa-9bd0-2783e70a8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_entailment = df_entailment.reindex(df_entailment.columns.tolist() + ['top_sentences','predictions','probabilities'], axis=1)  # version > 0.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "afb20ca9-8aa8-49f1-b8ca-254f6aa7dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample = df_entailment[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a451f-6ccf-439d-913d-9e556958314b",
   "metadata": {},
   "source": [
    "We repeat the same code as above but expand upon it further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b225b238-35b4-417d-a925-9b690b923ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(nli_model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(nli_model)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4791e7e9-68eb-4e5c-b12d-28014c474ab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# search only the article embeddings/sentences of the specific company\u001b[39;00m\n\u001b[0;32m     12\u001b[0m corpus_embeddings \u001b[38;5;241m=\u001b[39m df_article[df_article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mcompany][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m---> 13\u001b[0m top_5 \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39msemantic_search(torch\u001b[38;5;241m.\u001b[39mTensor(query_embedding), \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcorpus_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# define a list to hold our top sentences and predictions to add these as a new variable after the loop\u001b[39;00m\n\u001b[0;32m     15\u001b[0m hard_predictions \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# making lists to store values for the new columns\n",
    "top_sentences_column = []\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "# we run a for loop for each claim in the df_entailment dataset and check the validity of the claim\n",
    "for i,row in df_entailment.iterrows():\n",
    "    # define our query (i.e. claim) and the company it's related to \n",
    "    query_embedding = row['embeddings']\n",
    "    company = row['company']\n",
    "    # search only the article embeddings/sentences of the specific company\n",
    "    corpus_embeddings = df_article[df_article['company']==company]['embeddings'].values\n",
    "    top_5 = util.semantic_search(torch.Tensor(query_embedding), torch.Tensor(list(corpus_embeddings)), top_k = 5)\n",
    "    # define a list to hold our top sentences and predictions to add these as a new variable after the loop\n",
    "    hard_predictions = []\n",
    "    top_sentences = []\n",
    "    soft_predictions =[]\n",
    "    for sentence in top_5[0]:\n",
    "        # the premise is the claim\n",
    "        premise = row['sentence']\n",
    "        # the hypothesis is the sentence from the article(identified using the corpus id, which gives us the index of the sentence)\n",
    "        hypothesis = df_article[df_article['company']==company]['sentence'].values[sentence['corpus_id']]\n",
    "        tokens = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "        output = model(tokens[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "        soft_prediction = torch.softmax(output[\"logits\"][0], -1)\n",
    "        label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "        hard_prediction = label_names[torch.argmax(output[\"logits\"][0], -1).item()]\n",
    "        # append the different values to the correct list\n",
    "        top_sentences.append(hypothesis)\n",
    "        soft_predictions.append(max(torch.softmax(output[\"logits\"][0], -1).tolist()))\n",
    "        hard_predictions.append(hard_prediction)\n",
    "    # # now add the different lists as new variables\n",
    "    # df_sample.at[i,'top_sentences'] = str(top_sentences)\n",
    "    # df_sample.at[i,'predictions'] = str(hard_predictions)\n",
    "    # df_sample.at[i,'probabilities'] = str(soft_predictions)\n",
    "    top_sentences_column.append(top_sentences)\n",
    "    predictions.append(hard_predictions)\n",
    "    probabilities.append(soft_predictions)\n",
    "\n",
    "df_entailment['top_sentences'] = top_sentences_column\n",
    "df_entailment['predictions'] = predictions\n",
    "df_entailment['probabilities'] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8fc24-d58b-45b1-bf47-a12f8321bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e5429-90fe-477e-866f-0174de88c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_frequent_category(categories_list):\n",
    "    counter = Counter(categories_list)\n",
    "    return counter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21cf198-b146-4f76-b669-46ff75b75c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entailment['consensus'] = df_entailment['predictions'].apply(most_frequent_category)\n",
    "df_entailment['consensus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8b8800c7-ba7f-4ab7-8400-a5c675649eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_score</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>top_sentences</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>customers to deliver annual savings of 100 meg...</td>\n",
       "      <td>13</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.993644</td>\n",
       "      <td>[-0.6807976, 0.4772148, -0.26226345, -0.029244...</td>\n",
       "      <td>['A key part of our 2030 sustainability strate...</td>\n",
       "      <td>['neutral', 'neutral', 'neutral', 'contradicti...</td>\n",
       "      <td>[0.9967696666717529, 0.9962621331214905, 0.995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>We found that 36 percent of our revenue in 202...</td>\n",
       "      <td>19</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.949681</td>\n",
       "      <td>[0.23194747, 0.085391074, -0.19298553, 0.04695...</td>\n",
       "      <td>['SN: Company report shows that ABBs greenhous...</td>\n",
       "      <td>['neutral', 'neutral', 'neutral', 'neutral', '...</td>\n",
       "      <td>[0.9966341853141785, 0.9991693496704102, 0.998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>We consider this to be a significant underesti...</td>\n",
       "      <td>33</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.989664</td>\n",
       "      <td>[-0.14990805, 0.17751908, -0.098325394, 0.1222...</td>\n",
       "      <td>['Theres a whole range of solutions that we ca...</td>\n",
       "      <td>['entailment', 'neutral', 'neutral', 'neutral'...</td>\n",
       "      <td>[0.9093318581581116, 0.9912990927696228, 0.998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>A second goal of our 2030 sustainability strat...</td>\n",
       "      <td>19</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.989790</td>\n",
       "      <td>[-0.24475533, 0.4377824, -0.21117015, -0.03091...</td>\n",
       "      <td>['A key part of our 2030 sustainability strate...</td>\n",
       "      <td>['neutral', 'neutral', 'neutral', 'neutral', '...</td>\n",
       "      <td>[0.9479023814201355, 0.9969388246536255, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>In December 2021, we unveiled a new company-wi...</td>\n",
       "      <td>21</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.992168</td>\n",
       "      <td>[-0.49132273, -0.4556106, -0.45783857, -0.3235...</td>\n",
       "      <td>['At ABB, weve set a target to take a circular...</td>\n",
       "      <td>['neutral', 'neutral', 'neutral', 'neutral', '...</td>\n",
       "      <td>[0.9995922446250916, 0.8719384670257568, 0.955...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_type company                                           sentence  \\\n",
       "0   report     abb  customers to deliver annual savings of 100 meg...   \n",
       "1   report     abb  We found that 36 percent of our revenue in 202...   \n",
       "2   report     abb  We consider this to be a significant underesti...   \n",
       "3   report     abb  A second goal of our 2030 sustainability strat...   \n",
       "4   report     abb  In December 2021, we unveiled a new company-wi...   \n",
       "\n",
       "   word count claim  claim_score  \\\n",
       "0          13   yes     0.993644   \n",
       "1          19   yes     0.949681   \n",
       "2          33   yes     0.989664   \n",
       "3          19   yes     0.989790   \n",
       "4          21   yes     0.992168   \n",
       "\n",
       "                                          embeddings  \\\n",
       "0  [-0.6807976, 0.4772148, -0.26226345, -0.029244...   \n",
       "1  [0.23194747, 0.085391074, -0.19298553, 0.04695...   \n",
       "2  [-0.14990805, 0.17751908, -0.098325394, 0.1222...   \n",
       "3  [-0.24475533, 0.4377824, -0.21117015, -0.03091...   \n",
       "4  [-0.49132273, -0.4556106, -0.45783857, -0.3235...   \n",
       "\n",
       "                                       top_sentences  \\\n",
       "0  ['A key part of our 2030 sustainability strate...   \n",
       "1  ['SN: Company report shows that ABBs greenhous...   \n",
       "2  ['Theres a whole range of solutions that we ca...   \n",
       "3  ['A key part of our 2030 sustainability strate...   \n",
       "4  ['At ABB, weve set a target to take a circular...   \n",
       "\n",
       "                                         predictions  \\\n",
       "0  ['neutral', 'neutral', 'neutral', 'contradicti...   \n",
       "1  ['neutral', 'neutral', 'neutral', 'neutral', '...   \n",
       "2  ['entailment', 'neutral', 'neutral', 'neutral'...   \n",
       "3  ['neutral', 'neutral', 'neutral', 'neutral', '...   \n",
       "4  ['neutral', 'neutral', 'neutral', 'neutral', '...   \n",
       "\n",
       "                                       probabilities  \n",
       "0  [0.9967696666717529, 0.9962621331214905, 0.995...  \n",
       "1  [0.9966341853141785, 0.9991693496704102, 0.998...  \n",
       "2  [0.9093318581581116, 0.9912990927696228, 0.998...  \n",
       "3  [0.9479023814201355, 0.9969388246536255, 0.999...  \n",
       "4  [0.9995922446250916, 0.8719384670257568, 0.955...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval lets us access it as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "28a77146-4cf1-408c-bad0-d23c0841de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment': 0.3, 'neutral': 99.7, 'contradiction': 0.1}\n",
      "{'entailment': 0.1, 'neutral': 99.6, 'contradiction': 0.3}\n",
      "{'entailment': 0.1, 'neutral': 99.6, 'contradiction': 0.3}\n",
      "{'entailment': 0.2, 'neutral': 1.7, 'contradiction': 98.1}\n",
      "{'entailment': 0.2, 'neutral': 99.2, 'contradiction': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(nli_model)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(nli_model)\n",
    "\n",
    "# for sentence in top_5[0]:\n",
    "#     premise = row['sentence']\n",
    "#     hypothesis = df_article[df_article['company']==company]['sentence'].values[sentence['corpus_id']]\n",
    "#     tokens = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "#     output = model(tokens[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "#     prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "#     label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "#     prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "#     print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03776886-9e61-4b47-bcba-85e2677ef4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in case the input sentence is too long:\n",
    "# input_id_chunks = tokens_plus['input_ids'][0].split(510)\n",
    "# mask_chunks = tokens_plus['attention_mask'][0].split(510)\n",
    "\n",
    "# input_id_chunks = list(input_id_chunks)\n",
    "# mask_chunks = list(mask_chunks)\n",
    "\n",
    "\n",
    "# chunksize = 512\n",
    "# for i in range(len(input_id_chunks)):\n",
    "#     input_id_chunks[i] = torch.cat([\n",
    "#         torch.Tensor([101]), input_id_chunks[i], torch.Tensor([102])\n",
    "#     ])\n",
    "#     mask_chunks[i] = torch.cat([\n",
    "#         torch.Tensor([1]), mask_chunks[i], torch.Tensor([1])\n",
    "#     ])\n",
    "#     pad_len = chunksize - input_id_chunks[i].shape[0]\n",
    "    \n",
    "#     if pad_len > 0:\n",
    "#         input_id_chunks[i] = torch.cat([\n",
    "#             input_id_chunks[i], torch.Tensor([0]*pad_len)\n",
    "#         ])\n",
    "#         mask_id_chunks[i] = torch.cat([\n",
    "#             mask_id_chunks[i], torch.Tensor([0]*pad_len)\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a129ad-0984-401c-8645-472ea2d7a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = torch.stack(input_id_chunks)\n",
    "# attention_mask = torch.stack(mask_chunks)\n",
    "\n",
    "# input_dict = {\n",
    "#     'input_ids':input_ids.long(),\n",
    "#     'attention_mask': attention_mask.int()\n",
    "# }\n",
    "# input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6609a51-4e76-45ad-acb5-7abd6b34ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model(**input_dict)\n",
    "\n",
    "# probs = torch.nn.functional.softmax(outputs[0], dim = -1)\n",
    "# probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489ae33-d833-4a7e-9063-180735017ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = probs.mean(dim = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
