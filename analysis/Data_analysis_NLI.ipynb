{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66c81ae-bf25-4c7e-aedc-83cdb2540b23",
   "metadata": {},
   "source": [
    "# Set-up and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e7ea0dd-fb65-491b-99fc-4fb59463c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer, util, models\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0e060b6-5a3d-4b80-b48f-703c6ce3effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ead8ee9-829b-4667-a182-9dce6cac5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '..\\\\data_structured'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8606a26-1cc5-4a94-bb56-562dbe6a32d8",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1908e6a8-38eb-429d-8b2c-f1a70e339679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = pd.read_pickle(os.path.join(path_data, 'comb.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63bfb2d4-f31a-444c-95ab-3b1dae145054",
   "metadata": {},
   "outputs": [],
   "source": [
    "sust_topics = [0,1,2,3,4,5,6,7,8,10,11,20,25]\n",
    "lim_topics = [1,2,3,4,5,7,8,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69b0cc0-985c-4273-8e32-9eae185ff80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyze = df_comb[df_comb['topics'].isin(sust_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592184b6-bf51-4875-91f1-8915d324a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = df_analyze[df_analyze['doc_type']=='report']\n",
    "df_article = df_analyze[df_analyze['doc_type']=='news']\n",
    "df_report.reset_index(drop = True, inplace = True)\n",
    "df_article.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bc05c-484a-4081-9493-099b1b069b32",
   "metadata": {},
   "source": [
    "# Applying the pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99b2683-8ac1-49a8-bf58-9c2871cd6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████| 854/854 [00:00<?, ?B/s]\n",
      "C:\\Users\\dathn\\anaconda3\\envs\\thesis_v2\\lib\\site-packages\\huggingface_hub-0.14.1-py3.8.egg\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dathn\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████| 329M/329M [00:12<00:00, 25.9MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████| 1.34k/1.34k [00:00<?, ?B/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████████████████████████████████████| 798k/798k [00:00<00:00, 15.9MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████████████████████████████████████| 456k/456k [00:00<00:00, 17.4MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████| 2.15M/2.15M [00:00<00:00, 16.1MB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|████████████████████████████████████████| 4.98k/4.98k [00:00<00:00, 4.10MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████| 280/280 [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "claim_checker = pipeline(model = \"climatebert/environmental-claims\",  device = 0, batch_size = 64)\n",
    "sem_search = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n",
    "nli_model = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7625233a-959f-4dcf-b9e6-220ae96f5d33",
   "metadata": {},
   "source": [
    "The claim verification model consists of three stages - claim identification, evidence sentence selection and finally inference analysis. The three models above will help us achieve these three tasks. The ClimateBERT model is pre-trained to detect environmental and climate claims, semantic search will help us identify the 5 most relevant sentences from the corpus and finally the actual model can be used to check the entailment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d3e25-0f4f-44b6-a19e-61ac94148326",
   "metadata": {},
   "source": [
    "First, we apply the ClimateBERT model to identify environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a59cf-a6ed-48ab-b0a5-e0dcc6bb656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\2836976421.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_report['claim'] = [result['label'] for result in results]\n",
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\2836976421.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_report['claim_probability'] = [result['score'] for result in results]\n"
     ]
    }
   ],
   "source": [
    "# first part of the pipeline - identifying claims\n",
    "sentences = df_report['sentence'].tolist()  # Convert the column to a list\n",
    "\n",
    "results = claim_checker(sentences)\n",
    "df_report['claim'] = [result['label'] for result in results]\n",
    "df_report['claim_probability'] = [result['score'] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e266e6ec-f4be-4eee-98d3-c8c4179da1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>char_length</th>\n",
       "      <th>anon_embeddings</th>\n",
       "      <th>topics</th>\n",
       "      <th>anon_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>One year into ABB's 2030 sustainability strate...</td>\n",
       "      <td>21</td>\n",
       "      <td>[-0.03387668, 0.04702735, 0.0067782644, 0.0184...</td>\n",
       "      <td>123</td>\n",
       "      <td>[-0.039394952, 0.055466365, 0.015991926, 0.016...</td>\n",
       "      <td>0</td>\n",
       "      <td>One year into the company 2030 sustainability ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>27</td>\n",
       "      <td>[0.072760716, 0.09948956, 0.077118196, 0.02812...</td>\n",
       "      <td>152</td>\n",
       "      <td>[0.07276068, 0.09948958, 0.077118136, 0.028125...</td>\n",
       "      <td>1</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>26</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>168</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>0</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>28</td>\n",
       "      <td>[0.0023520757, 0.040041316, 0.010221989, 0.016...</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.0023520836, 0.04004134, 0.010221971, 0.0164...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>36</td>\n",
       "      <td>[-0.06374183, -0.02712268, -0.040378235, -0.02...</td>\n",
       "      <td>212</td>\n",
       "      <td>[-0.06374184, -0.027122695, -0.040378183, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30498</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>The initiative invites suppliers (starting wit...</td>\n",
       "      <td>31</td>\n",
       "      <td>[-0.06545875, 0.027131714, -0.0116220275, 0.06...</td>\n",
       "      <td>228</td>\n",
       "      <td>[-0.06545872, 0.027131697, -0.0116220135, 0.06...</td>\n",
       "      <td>10</td>\n",
       "      <td>The initiative invites suppliers (starting wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30499</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.02941792, -0.038456682, -0.01928836, -0.00...</td>\n",
       "      <td>81</td>\n",
       "      <td>[-0.029417915, -0.038456634, -0.019288322, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30500</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>In FY2022, 87% of Walmart U.S. information, co...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.009387232, -0.017577449, -0.12768476, 0.02...</td>\n",
       "      <td>175</td>\n",
       "      <td>[-0.03227741, -0.036879178, -0.1515622, 0.0158...</td>\n",
       "      <td>1</td>\n",
       "      <td>In FY2022, 87% of the company U.S. information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30501</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To accelerate system-wide change, the Walmart ...</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.003541183, 0.046546437, -0.00028145174, -0....</td>\n",
       "      <td>260</td>\n",
       "      <td>[-0.02246362, 0.022425106, -0.013262148, -0.02...</td>\n",
       "      <td>6</td>\n",
       "      <td>To accelerate system-wide change, the the comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30502</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Factories develop supervised corrective action...</td>\n",
       "      <td>18</td>\n",
       "      <td>[-0.032323312, -0.01603831, 0.026886059, 0.030...</td>\n",
       "      <td>131</td>\n",
       "      <td>[-0.032323312, -0.01603831, 0.026886059, 0.030...</td>\n",
       "      <td>1</td>\n",
       "      <td>Factories develop supervised corrective action...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30503 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_type  company                                           sentence  \\\n",
       "0       report      abb  One year into ABB's 2030 sustainability strate...   \n",
       "1       report      abb  Compared with our baseline year of 2019, we ha...   \n",
       "2       report      abb  Alongside these headline achievements, we made...   \n",
       "3       report      abb  Our 2030 GHG emissions reduction target was va...   \n",
       "4       report      abb  We also joined the SBTi's Business Ambition fo...   \n",
       "...        ...      ...                                                ...   \n",
       "30498   report  walmart  The initiative invites suppliers (starting wit...   \n",
       "30499   report  walmart  We also promote the adoption of best practices...   \n",
       "30500   report  walmart  In FY2022, 87% of Walmart U.S. information, co...   \n",
       "30501   report  walmart  To accelerate system-wide change, the Walmart ...   \n",
       "30502   report  walmart  Factories develop supervised corrective action...   \n",
       "\n",
       "       word count                                         embeddings  \\\n",
       "0              21  [-0.03387668, 0.04702735, 0.0067782644, 0.0184...   \n",
       "1              27  [0.072760716, 0.09948956, 0.077118196, 0.02812...   \n",
       "2              26  [0.014213712, 0.033080414, 0.025592497, -0.021...   \n",
       "3              28  [0.0023520757, 0.040041316, 0.010221989, 0.016...   \n",
       "4              36  [-0.06374183, -0.02712268, -0.040378235, -0.02...   \n",
       "...           ...                                                ...   \n",
       "30498          31  [-0.06545875, 0.027131714, -0.0116220275, 0.06...   \n",
       "30499          13  [-0.02941792, -0.038456682, -0.01928836, -0.00...   \n",
       "30500          25  [-0.009387232, -0.017577449, -0.12768476, 0.02...   \n",
       "30501          38  [0.003541183, 0.046546437, -0.00028145174, -0....   \n",
       "30502          18  [-0.032323312, -0.01603831, 0.026886059, 0.030...   \n",
       "\n",
       "       char_length                                    anon_embeddings  topics  \\\n",
       "0              123  [-0.039394952, 0.055466365, 0.015991926, 0.016...       0   \n",
       "1              152  [0.07276068, 0.09948958, 0.077118136, 0.028125...       1   \n",
       "2              168  [0.014213712, 0.033080414, 0.025592497, -0.021...       0   \n",
       "3              161  [0.0023520836, 0.04004134, 0.010221971, 0.0164...       1   \n",
       "4              212  [-0.06374184, -0.027122695, -0.040378183, -0.0...       1   \n",
       "...            ...                                                ...     ...   \n",
       "30498          228  [-0.06545872, 0.027131697, -0.0116220135, 0.06...      10   \n",
       "30499           81  [-0.029417915, -0.038456634, -0.019288322, -0....       0   \n",
       "30500          175  [-0.03227741, -0.036879178, -0.1515622, 0.0158...       1   \n",
       "30501          260  [-0.02246362, 0.022425106, -0.013262148, -0.02...       6   \n",
       "30502          131  [-0.032323312, -0.01603831, 0.026886059, 0.030...       1   \n",
       "\n",
       "                                           anon_sentence  \n",
       "0      One year into the company 2030 sustainability ...  \n",
       "1      Compared with our baseline year of 2019, we ha...  \n",
       "2      Alongside these headline achievements, we made...  \n",
       "3      Our 2030 GHG emissions reduction target was va...  \n",
       "4      We also joined the SBTi's Business Ambition fo...  \n",
       "...                                                  ...  \n",
       "30498  The initiative invites suppliers (starting wit...  \n",
       "30499  We also promote the adoption of best practices...  \n",
       "30500  In FY2022, 87% of the company U.S. information...  \n",
       "30501  To accelerate system-wide change, the the comp...  \n",
       "30502  Factories develop supervised corrective action...  \n",
       "\n",
       "[30503 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7481b47-28b4-427e-adfa-df700fb71c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12906, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims = df_report[df_report['claim']=='yes']\n",
    "df_claims.reset_index(inplace = True, drop = True)\n",
    "df_claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e774c276-1487-4c66-80e6-7cf0a46b48dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>char_length</th>\n",
       "      <th>anon_embeddings</th>\n",
       "      <th>topics</th>\n",
       "      <th>anon_sentence</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_probability</th>\n",
       "      <th>top_sentences</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>One year into ABB's 2030 sustainability strate...</td>\n",
       "      <td>21</td>\n",
       "      <td>[-0.03387668, 0.04702735, 0.0067782644, 0.0184...</td>\n",
       "      <td>123</td>\n",
       "      <td>[-0.039394952, 0.055466365, 0.015991926, 0.016...</td>\n",
       "      <td>0</td>\n",
       "      <td>One year into the company 2030 sustainability ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.947520</td>\n",
       "      <td>[Last year, ABB released its Sustainability St...</td>\n",
       "      <td>[neutral, entailment, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9908430576324463, 0.965498685836792, 0.7367...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>27</td>\n",
       "      <td>[0.072760716, 0.09948956, 0.077118196, 0.02812...</td>\n",
       "      <td>152</td>\n",
       "      <td>[0.07276068, 0.09948958, 0.077118136, 0.028125...</td>\n",
       "      <td>1</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.975864</td>\n",
       "      <td>[SN: Company report shows that ABB's greenhous...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, contradic...</td>\n",
       "      <td>[0.999405026435852, 0.994537889957428, 0.99930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>26</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>168</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>0</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.982865</td>\n",
       "      <td>[We've been making concrete efforts towards ac...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9995107650756836, 0.9830822944641113, 0.995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>28</td>\n",
       "      <td>[0.0023520757, 0.040041316, 0.010221989, 0.016...</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.0023520836, 0.04004134, 0.010221971, 0.0164...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>[Our greenhouse gas emissions reduction target...</td>\n",
       "      <td>[entailment, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9383401274681091, 0.8523229956626892, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>36</td>\n",
       "      <td>[-0.06374183, -0.02712268, -0.040378235, -0.02...</td>\n",
       "      <td>212</td>\n",
       "      <td>[-0.06374184, -0.027122695, -0.040378183, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.966742</td>\n",
       "      <td>[Although borne from the electrification busin...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9956797361373901, 0.9982929825782776, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12901</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Our Responsible Sourcing program sets expectat...</td>\n",
       "      <td>34</td>\n",
       "      <td>[-0.06368477, 0.010128789, -0.021725688, -0.02...</td>\n",
       "      <td>257</td>\n",
       "      <td>[-0.06368478, 0.010128791, -0.02172569, -0.022...</td>\n",
       "      <td>0</td>\n",
       "      <td>Our Responsible Sourcing program sets expectat...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>[This collaboration supports the industry thro...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.995686948299408, 0.9650912880897522, 0.9904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12902</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Walmart has prioritized working with stakehold...</td>\n",
       "      <td>34</td>\n",
       "      <td>[0.0054569603, 0.021002548, 0.0049035875, 0.00...</td>\n",
       "      <td>258</td>\n",
       "      <td>[-0.027358495, 0.019750984, -0.0058520334, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>the company has prioritized working with stake...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.599842</td>\n",
       "      <td>[To promote human dignity, Walmart has also co...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9997122883796692, 0.994895875453949, 0.9991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12903</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To advance responsible recruitment across our ...</td>\n",
       "      <td>23</td>\n",
       "      <td>[-0.044291113, -0.04852808, -0.02642449, 0.013...</td>\n",
       "      <td>166</td>\n",
       "      <td>[-0.06653639, -0.061157897, -0.023344118, 0.01...</td>\n",
       "      <td>0</td>\n",
       "      <td>To advance responsible recruitment across our ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.825599</td>\n",
       "      <td>[Walmart recently held its seventh annual Supp...</td>\n",
       "      <td>[contradiction, neutral, neutral, neutral, neu...</td>\n",
       "      <td>[0.7207563519477844, 0.9993495345115662, 0.995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12904</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.02941792, -0.038456682, -0.01928836, -0.00...</td>\n",
       "      <td>81</td>\n",
       "      <td>[-0.029417915, -0.038456634, -0.019288322, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.792461</td>\n",
       "      <td>[We work closely with logistics partners, NGOs...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9987469911575317, 0.9983007311820984, 0.997...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12905</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To accelerate system-wide change, the Walmart ...</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.003541183, 0.046546437, -0.00028145174, -0....</td>\n",
       "      <td>260</td>\n",
       "      <td>[-0.02246362, 0.022425106, -0.013262148, -0.02...</td>\n",
       "      <td>6</td>\n",
       "      <td>To accelerate system-wide change, the the comp...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.913087</td>\n",
       "      <td>[She adds: The Walmart Foundation is supportin...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9987826943397522, 0.9405285716056824, 0.977...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12906 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_type  company                                           sentence  \\\n",
       "0       report      abb  One year into ABB's 2030 sustainability strate...   \n",
       "1       report      abb  Compared with our baseline year of 2019, we ha...   \n",
       "2       report      abb  Alongside these headline achievements, we made...   \n",
       "3       report      abb  Our 2030 GHG emissions reduction target was va...   \n",
       "4       report      abb  We also joined the SBTi's Business Ambition fo...   \n",
       "...        ...      ...                                                ...   \n",
       "12901   report  walmart  Our Responsible Sourcing program sets expectat...   \n",
       "12902   report  walmart  Walmart has prioritized working with stakehold...   \n",
       "12903   report  walmart  To advance responsible recruitment across our ...   \n",
       "12904   report  walmart  We also promote the adoption of best practices...   \n",
       "12905   report  walmart  To accelerate system-wide change, the Walmart ...   \n",
       "\n",
       "       word count                                         embeddings  \\\n",
       "0              21  [-0.03387668, 0.04702735, 0.0067782644, 0.0184...   \n",
       "1              27  [0.072760716, 0.09948956, 0.077118196, 0.02812...   \n",
       "2              26  [0.014213712, 0.033080414, 0.025592497, -0.021...   \n",
       "3              28  [0.0023520757, 0.040041316, 0.010221989, 0.016...   \n",
       "4              36  [-0.06374183, -0.02712268, -0.040378235, -0.02...   \n",
       "...           ...                                                ...   \n",
       "12901          34  [-0.06368477, 0.010128789, -0.021725688, -0.02...   \n",
       "12902          34  [0.0054569603, 0.021002548, 0.0049035875, 0.00...   \n",
       "12903          23  [-0.044291113, -0.04852808, -0.02642449, 0.013...   \n",
       "12904          13  [-0.02941792, -0.038456682, -0.01928836, -0.00...   \n",
       "12905          38  [0.003541183, 0.046546437, -0.00028145174, -0....   \n",
       "\n",
       "       char_length                                    anon_embeddings  topics  \\\n",
       "0              123  [-0.039394952, 0.055466365, 0.015991926, 0.016...       0   \n",
       "1              152  [0.07276068, 0.09948958, 0.077118136, 0.028125...       1   \n",
       "2              168  [0.014213712, 0.033080414, 0.025592497, -0.021...       0   \n",
       "3              161  [0.0023520836, 0.04004134, 0.010221971, 0.0164...       1   \n",
       "4              212  [-0.06374184, -0.027122695, -0.040378183, -0.0...       1   \n",
       "...            ...                                                ...     ...   \n",
       "12901          257  [-0.06368478, 0.010128791, -0.02172569, -0.022...       0   \n",
       "12902          258  [-0.027358495, 0.019750984, -0.0058520334, 0.0...       0   \n",
       "12903          166  [-0.06653639, -0.061157897, -0.023344118, 0.01...       0   \n",
       "12904           81  [-0.029417915, -0.038456634, -0.019288322, -0....       0   \n",
       "12905          260  [-0.02246362, 0.022425106, -0.013262148, -0.02...       6   \n",
       "\n",
       "                                           anon_sentence claim  \\\n",
       "0      One year into the company 2030 sustainability ...   yes   \n",
       "1      Compared with our baseline year of 2019, we ha...   yes   \n",
       "2      Alongside these headline achievements, we made...   yes   \n",
       "3      Our 2030 GHG emissions reduction target was va...   yes   \n",
       "4      We also joined the SBTi's Business Ambition fo...   yes   \n",
       "...                                                  ...   ...   \n",
       "12901  Our Responsible Sourcing program sets expectat...   yes   \n",
       "12902  the company has prioritized working with stake...   yes   \n",
       "12903  To advance responsible recruitment across our ...   yes   \n",
       "12904  We also promote the adoption of best practices...   yes   \n",
       "12905  To accelerate system-wide change, the the comp...   yes   \n",
       "\n",
       "       claim_probability                                      top_sentences  \\\n",
       "0               0.947520  [Last year, ABB released its Sustainability St...   \n",
       "1               0.975864  [SN: Company report shows that ABB's greenhous...   \n",
       "2               0.982865  [We've been making concrete efforts towards ac...   \n",
       "3               0.990115  [Our greenhouse gas emissions reduction target...   \n",
       "4               0.966742  [Although borne from the electrification busin...   \n",
       "...                  ...                                                ...   \n",
       "12901           0.645536  [This collaboration supports the industry thro...   \n",
       "12902           0.599842  [To promote human dignity, Walmart has also co...   \n",
       "12903           0.825599  [Walmart recently held its seventh annual Supp...   \n",
       "12904           0.792461  [We work closely with logistics partners, NGOs...   \n",
       "12905           0.913087  [She adds: The Walmart Foundation is supportin...   \n",
       "\n",
       "                                             predictions  \\\n",
       "0       [neutral, entailment, neutral, neutral, neutral]   \n",
       "1      [neutral, neutral, neutral, neutral, contradic...   \n",
       "2          [neutral, neutral, neutral, neutral, neutral]   \n",
       "3       [entailment, neutral, neutral, neutral, neutral]   \n",
       "4          [neutral, neutral, neutral, neutral, neutral]   \n",
       "...                                                  ...   \n",
       "12901      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12902      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12903  [contradiction, neutral, neutral, neutral, neu...   \n",
       "12904      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12905      [neutral, neutral, neutral, neutral, neutral]   \n",
       "\n",
       "                                           probabilities  \n",
       "0      [0.9908430576324463, 0.965498685836792, 0.7367...  \n",
       "1      [0.999405026435852, 0.994537889957428, 0.99930...  \n",
       "2      [0.9995107650756836, 0.9830822944641113, 0.995...  \n",
       "3      [0.9383401274681091, 0.8523229956626892, 0.999...  \n",
       "4      [0.9956797361373901, 0.9982929825782776, 0.999...  \n",
       "...                                                  ...  \n",
       "12901  [0.995686948299408, 0.9650912880897522, 0.9904...  \n",
       "12902  [0.9997122883796692, 0.994895875453949, 0.9991...  \n",
       "12903  [0.7207563519477844, 0.9993495345115662, 0.995...  \n",
       "12904  [0.9987469911575317, 0.9983007311820984, 0.997...  \n",
       "12905  [0.9987826943397522, 0.9405285716056824, 0.977...  \n",
       "\n",
       "[12906 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims = pd.read_pickle('entailment.pkl')\n",
    "df_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c316f-b561-4249-b7ab-47dc60a70ed0",
   "metadata": {},
   "source": [
    "Now we create the sentence embeddings using the semantic search model. These embeddings will be used by the sentence transformers package to find the top 5 most similar sentences from the article corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728f552-a3b8-49b1-83d9-3cf96800e9e7",
   "metadata": {},
   "source": [
    "Since this took a while I will also pickle these to save my progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ee4f17-52d7-4072-9765-91a2708dbf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_article.to_pickle('art.pkl')\n",
    "# df_claims.to_pickle('claims.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75201a1e-dd5c-450a-a1e8-80bda9135b53",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sentence transformers has a utility called semantic search which can be used to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "810a93c3-b6db-4a3c-a476-750d808090c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 18.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,row in df_claims.iterrows():\n",
    "    query_embedding = row['embeddings']\n",
    "    company = row['company']\n",
    "    # search only the article embeddings/sentences of the specific company\n",
    "    corpus_embeddings = df_article[df_article['company']==company]['embeddings'].values\n",
    "    top_5 = util.semantic_search(torch.Tensor(query_embedding), torch.Tensor(np.array(list(corpus_embeddings))), top_k = 5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a73c87-b632-4938-b0ba-7838316bf398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 132, 'score': 0.7928017377853394},\n",
       "  {'corpus_id': 524, 'score': 0.7137691974639893},\n",
       "  {'corpus_id': 320, 'score': 0.7048271894454956},\n",
       "  {'corpus_id': 609, 'score': 0.6708470582962036},\n",
       "  {'corpus_id': 40, 'score': 0.6677325367927551}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbd249-9b35-44c9-bc13-753777ab9925",
   "metadata": {},
   "source": [
    "Let us now create a new dataframe based on df_claims, which will store the same information as this dataframe, but will also additionally hold the top 5 most similar sentences in a separate column, as well as whether these sentences entail, contradict or are neutral towards each other. I use the MoritzLaurer NLI model for this purpose as it states that it is the best performing NLI model as of June 2022. The code used for the classification is mostly copied from the HuggingFace transformers website and modified for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bb41abc-2c0a-48aa-9bd0-2783e70a8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_entailment = df_entailment.reindex(df_entailment.columns.tolist() + ['top_sentences','predictions','probabilities'], axis=1)  # version > 0.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "afb20ca9-8aa8-49f1-b8ca-254f6aa7dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample = df_entailment[:5] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a451f-6ccf-439d-913d-9e556958314b",
   "metadata": {},
   "source": [
    "We repeat the same code as above but expand upon it further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b225b238-35b4-417d-a925-9b690b923ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(nli_model)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(nli_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4791e7e9-68eb-4e5c-b12d-28014c474ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\1041120475.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['top_sentences'] = top_sentences_column\n",
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\1041120475.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['predictions'] = predictions\n",
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\1041120475.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['probabilities'] = probabilities\n"
     ]
    }
   ],
   "source": [
    "# # making lists to store values for the new columns\n",
    "top_sentences_column = []\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "# we run a for loop for each claim in the df_entailment dataset and check the validity of the claim\n",
    "for i,row in df_claims.iterrows():\n",
    "    # define our query (i.e. claim) and the company it's related to \n",
    "    query_embedding = row['embeddings']\n",
    "    company = row['company']\n",
    "    # search only the article embeddings/sentences of the specific company\n",
    "    corpus_embeddings = df_article[df_article['company']==company]['embeddings'].values\n",
    "    top_5 = util.semantic_search(torch.Tensor(query_embedding), torch.Tensor(np.array(list(corpus_embeddings))), top_k = 5)\n",
    "    # define a list to hold our top sentences and predictions to add these as a new variable after the loop\n",
    "    hard_predictions = []\n",
    "    top_sentences = []\n",
    "    soft_predictions =[]\n",
    "    for sentence in  top_5[0]:\n",
    "        # the premise is the claim\n",
    "        premise = row['sentence']\n",
    "        # the hypothesis is the sentence from the article(identified using the corpus id, which gives us the index of the sentence)\n",
    "        hypothesis = df_article[df_article['company']==company]['sentence'].values[sentence['corpus_id']]\n",
    "        tokens = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "        output = model(tokens[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "        soft_prediction = torch.softmax(output[\"logits\"][0], -1)\n",
    "        label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "        hard_prediction = label_names[torch.argmax(output[\"logits\"][0], -1).item()]\n",
    "        # append the different values to the correct list\n",
    "        top_sentences.append(hypothesis)\n",
    "        soft_predictions.append(max(torch.softmax(output[\"logits\"][0], -1).tolist()))\n",
    "        hard_predictions.append(hard_prediction)\n",
    "    # # now add the different lists as new variables\n",
    "    # df_sample.at[i,'top_sentences'] = str(top_sentences)\n",
    "    # df_sample.at[i,'predictions'] = str(hard_predictions)\n",
    "    # df_sample.at[i,'probabilities'] = str(soft_predictions)\n",
    "    top_sentences_column.append(top_sentences)\n",
    "    predictions.append(hard_predictions)\n",
    "    probabilities.append(soft_predictions)\n",
    "\n",
    "df_claims['top_sentences'] = top_sentences_column\n",
    "df_claims['predictions'] = predictions\n",
    "df_claims['probabilities'] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7241f259-7473-4a12-a714-a0d345174c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>char_length</th>\n",
       "      <th>anon_embeddings</th>\n",
       "      <th>topics</th>\n",
       "      <th>anon_sentence</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_probability</th>\n",
       "      <th>top_sentences</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>top_sentences_cluster</th>\n",
       "      <th>predictions_cluster</th>\n",
       "      <th>probabilities_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>One year into ABB's 2030 sustainability strate...</td>\n",
       "      <td>21</td>\n",
       "      <td>[-0.03387668, 0.04702735, 0.0067782644, 0.0184...</td>\n",
       "      <td>123</td>\n",
       "      <td>[-0.039394952, 0.055466365, 0.015991926, 0.016...</td>\n",
       "      <td>0</td>\n",
       "      <td>One year into the company 2030 sustainability ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.947520</td>\n",
       "      <td>[Last year, ABB released its Sustainability St...</td>\n",
       "      <td>[neutral, entailment, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9908430576324463, 0.965498685836792, 0.7367...</td>\n",
       "      <td>[Recent projects include the Maid of the Mist ...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9993815422058105, 0.9931160807609558, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>27</td>\n",
       "      <td>[0.072760716, 0.09948956, 0.077118196, 0.02812...</td>\n",
       "      <td>152</td>\n",
       "      <td>[0.07276068, 0.09948958, 0.077118136, 0.028125...</td>\n",
       "      <td>1</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.975864</td>\n",
       "      <td>[SN: Company report shows that ABB's greenhous...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, contradic...</td>\n",
       "      <td>[0.999405026435852, 0.994537889957428, 0.99930...</td>\n",
       "      <td>[President Jesse Henson, the savings from a co...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9991391897201538, 0.9988901019096375, 0.991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>26</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>168</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>0</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.982865</td>\n",
       "      <td>[We've been making concrete efforts towards ac...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9995107650756836, 0.9830822944641113, 0.995...</td>\n",
       "      <td>[We are excited to include ABB among the trust...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9992584586143494, 0.9989070892333984, 0.998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>28</td>\n",
       "      <td>[0.0023520757, 0.040041316, 0.010221989, 0.016...</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.0023520836, 0.04004134, 0.010221971, 0.0164...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>[Our greenhouse gas emissions reduction target...</td>\n",
       "      <td>[entailment, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9383401274681091, 0.8523229956626892, 0.999...</td>\n",
       "      <td>[Ships won't require any other source of elect...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.7511304020881653, 0.9971051812171936, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>36</td>\n",
       "      <td>[-0.06374183, -0.02712268, -0.040378235, -0.02...</td>\n",
       "      <td>212</td>\n",
       "      <td>[-0.06374184, -0.027122695, -0.040378183, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.966742</td>\n",
       "      <td>[Although borne from the electrification busin...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9956797361373901, 0.9982929825782776, 0.999...</td>\n",
       "      <td>[Shaft generator power output on such vessels ...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9990100860595703, 0.9978340268135071, 0.988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12901</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Our Responsible Sourcing program sets expectat...</td>\n",
       "      <td>34</td>\n",
       "      <td>[-0.06368477, 0.010128789, -0.021725688, -0.02...</td>\n",
       "      <td>257</td>\n",
       "      <td>[-0.06368478, 0.010128791, -0.02172569, -0.022...</td>\n",
       "      <td>0</td>\n",
       "      <td>Our Responsible Sourcing program sets expectat...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>[This collaboration supports the industry thro...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.995686948299408, 0.9650912880897522, 0.9904...</td>\n",
       "      <td>[According to a news release from the WWF, the...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9992725253105164, 0.9987848401069641, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12902</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Walmart has prioritized working with stakehold...</td>\n",
       "      <td>34</td>\n",
       "      <td>[0.0054569603, 0.021002548, 0.0049035875, 0.00...</td>\n",
       "      <td>258</td>\n",
       "      <td>[-0.027358495, 0.019750984, -0.0058520334, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>the company has prioritized working with stake...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.599842</td>\n",
       "      <td>[To promote human dignity, Walmart has also co...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9997122883796692, 0.994895875453949, 0.9991...</td>\n",
       "      <td>[Walmart's giant rooftops and parking lots are...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9991181492805481, 0.9991711378097534, 0.997...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12903</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To advance responsible recruitment across our ...</td>\n",
       "      <td>23</td>\n",
       "      <td>[-0.044291113, -0.04852808, -0.02642449, 0.013...</td>\n",
       "      <td>166</td>\n",
       "      <td>[-0.06653639, -0.061157897, -0.023344118, 0.01...</td>\n",
       "      <td>0</td>\n",
       "      <td>To advance responsible recruitment across our ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.825599</td>\n",
       "      <td>[Walmart recently held its seventh annual Supp...</td>\n",
       "      <td>[contradiction, neutral, neutral, neutral, neu...</td>\n",
       "      <td>[0.7207563519477844, 0.9993495345115662, 0.995...</td>\n",
       "      <td>[Piloting innovative financial vehicles to sup...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9981316924095154, 0.9973798394203186, 0.998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12904</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.02941792, -0.038456682, -0.01928836, -0.00...</td>\n",
       "      <td>81</td>\n",
       "      <td>[-0.029417915, -0.038456634, -0.019288322, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.792461</td>\n",
       "      <td>[We work closely with logistics partners, NGOs...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9987469911575317, 0.9983007311820984, 0.997...</td>\n",
       "      <td>[Although it has mostly focused on using renew...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9993014335632324, 0.9990935325622559, 0.998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12905</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To accelerate system-wide change, the Walmart ...</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.003541183, 0.046546437, -0.00028145174, -0....</td>\n",
       "      <td>260</td>\n",
       "      <td>[-0.02246362, 0.022425106, -0.013262148, -0.02...</td>\n",
       "      <td>6</td>\n",
       "      <td>To accelerate system-wide change, the the comp...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.913087</td>\n",
       "      <td>[She adds: The Walmart Foundation is supportin...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9987826943397522, 0.9405285716056824, 0.977...</td>\n",
       "      <td>[Our Zero-Waste Inspired approach is intended ...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9974094033241272, 0.9990146160125732, 0.978...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12906 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_type  company                                           sentence  \\\n",
       "0       report      abb  One year into ABB's 2030 sustainability strate...   \n",
       "1       report      abb  Compared with our baseline year of 2019, we ha...   \n",
       "2       report      abb  Alongside these headline achievements, we made...   \n",
       "3       report      abb  Our 2030 GHG emissions reduction target was va...   \n",
       "4       report      abb  We also joined the SBTi's Business Ambition fo...   \n",
       "...        ...      ...                                                ...   \n",
       "12901   report  walmart  Our Responsible Sourcing program sets expectat...   \n",
       "12902   report  walmart  Walmart has prioritized working with stakehold...   \n",
       "12903   report  walmart  To advance responsible recruitment across our ...   \n",
       "12904   report  walmart  We also promote the adoption of best practices...   \n",
       "12905   report  walmart  To accelerate system-wide change, the Walmart ...   \n",
       "\n",
       "       word count                                         embeddings  \\\n",
       "0              21  [-0.03387668, 0.04702735, 0.0067782644, 0.0184...   \n",
       "1              27  [0.072760716, 0.09948956, 0.077118196, 0.02812...   \n",
       "2              26  [0.014213712, 0.033080414, 0.025592497, -0.021...   \n",
       "3              28  [0.0023520757, 0.040041316, 0.010221989, 0.016...   \n",
       "4              36  [-0.06374183, -0.02712268, -0.040378235, -0.02...   \n",
       "...           ...                                                ...   \n",
       "12901          34  [-0.06368477, 0.010128789, -0.021725688, -0.02...   \n",
       "12902          34  [0.0054569603, 0.021002548, 0.0049035875, 0.00...   \n",
       "12903          23  [-0.044291113, -0.04852808, -0.02642449, 0.013...   \n",
       "12904          13  [-0.02941792, -0.038456682, -0.01928836, -0.00...   \n",
       "12905          38  [0.003541183, 0.046546437, -0.00028145174, -0....   \n",
       "\n",
       "       char_length                                    anon_embeddings  topics  \\\n",
       "0              123  [-0.039394952, 0.055466365, 0.015991926, 0.016...       0   \n",
       "1              152  [0.07276068, 0.09948958, 0.077118136, 0.028125...       1   \n",
       "2              168  [0.014213712, 0.033080414, 0.025592497, -0.021...       0   \n",
       "3              161  [0.0023520836, 0.04004134, 0.010221971, 0.0164...       1   \n",
       "4              212  [-0.06374184, -0.027122695, -0.040378183, -0.0...       1   \n",
       "...            ...                                                ...     ...   \n",
       "12901          257  [-0.06368478, 0.010128791, -0.02172569, -0.022...       0   \n",
       "12902          258  [-0.027358495, 0.019750984, -0.0058520334, 0.0...       0   \n",
       "12903          166  [-0.06653639, -0.061157897, -0.023344118, 0.01...       0   \n",
       "12904           81  [-0.029417915, -0.038456634, -0.019288322, -0....       0   \n",
       "12905          260  [-0.02246362, 0.022425106, -0.013262148, -0.02...       6   \n",
       "\n",
       "                                           anon_sentence claim  \\\n",
       "0      One year into the company 2030 sustainability ...   yes   \n",
       "1      Compared with our baseline year of 2019, we ha...   yes   \n",
       "2      Alongside these headline achievements, we made...   yes   \n",
       "3      Our 2030 GHG emissions reduction target was va...   yes   \n",
       "4      We also joined the SBTi's Business Ambition fo...   yes   \n",
       "...                                                  ...   ...   \n",
       "12901  Our Responsible Sourcing program sets expectat...   yes   \n",
       "12902  the company has prioritized working with stake...   yes   \n",
       "12903  To advance responsible recruitment across our ...   yes   \n",
       "12904  We also promote the adoption of best practices...   yes   \n",
       "12905  To accelerate system-wide change, the the comp...   yes   \n",
       "\n",
       "       claim_probability                                      top_sentences  \\\n",
       "0               0.947520  [Last year, ABB released its Sustainability St...   \n",
       "1               0.975864  [SN: Company report shows that ABB's greenhous...   \n",
       "2               0.982865  [We've been making concrete efforts towards ac...   \n",
       "3               0.990115  [Our greenhouse gas emissions reduction target...   \n",
       "4               0.966742  [Although borne from the electrification busin...   \n",
       "...                  ...                                                ...   \n",
       "12901           0.645536  [This collaboration supports the industry thro...   \n",
       "12902           0.599842  [To promote human dignity, Walmart has also co...   \n",
       "12903           0.825599  [Walmart recently held its seventh annual Supp...   \n",
       "12904           0.792461  [We work closely with logistics partners, NGOs...   \n",
       "12905           0.913087  [She adds: The Walmart Foundation is supportin...   \n",
       "\n",
       "                                             predictions  \\\n",
       "0       [neutral, entailment, neutral, neutral, neutral]   \n",
       "1      [neutral, neutral, neutral, neutral, contradic...   \n",
       "2          [neutral, neutral, neutral, neutral, neutral]   \n",
       "3       [entailment, neutral, neutral, neutral, neutral]   \n",
       "4          [neutral, neutral, neutral, neutral, neutral]   \n",
       "...                                                  ...   \n",
       "12901      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12902      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12903  [contradiction, neutral, neutral, neutral, neu...   \n",
       "12904      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12905      [neutral, neutral, neutral, neutral, neutral]   \n",
       "\n",
       "                                           probabilities  \\\n",
       "0      [0.9908430576324463, 0.965498685836792, 0.7367...   \n",
       "1      [0.999405026435852, 0.994537889957428, 0.99930...   \n",
       "2      [0.9995107650756836, 0.9830822944641113, 0.995...   \n",
       "3      [0.9383401274681091, 0.8523229956626892, 0.999...   \n",
       "4      [0.9956797361373901, 0.9982929825782776, 0.999...   \n",
       "...                                                  ...   \n",
       "12901  [0.995686948299408, 0.9650912880897522, 0.9904...   \n",
       "12902  [0.9997122883796692, 0.994895875453949, 0.9991...   \n",
       "12903  [0.7207563519477844, 0.9993495345115662, 0.995...   \n",
       "12904  [0.9987469911575317, 0.9983007311820984, 0.997...   \n",
       "12905  [0.9987826943397522, 0.9405285716056824, 0.977...   \n",
       "\n",
       "                                   top_sentences_cluster  \\\n",
       "0      [Recent projects include the Maid of the Mist ...   \n",
       "1      [President Jesse Henson, the savings from a co...   \n",
       "2      [We are excited to include ABB among the trust...   \n",
       "3      [Ships won't require any other source of elect...   \n",
       "4      [Shaft generator power output on such vessels ...   \n",
       "...                                                  ...   \n",
       "12901  [According to a news release from the WWF, the...   \n",
       "12902  [Walmart's giant rooftops and parking lots are...   \n",
       "12903  [Piloting innovative financial vehicles to sup...   \n",
       "12904  [Although it has mostly focused on using renew...   \n",
       "12905  [Our Zero-Waste Inspired approach is intended ...   \n",
       "\n",
       "                                 predictions_cluster  \\\n",
       "0      [neutral, neutral, neutral, neutral, neutral]   \n",
       "1      [neutral, neutral, neutral, neutral, neutral]   \n",
       "2      [neutral, neutral, neutral, neutral, neutral]   \n",
       "3      [neutral, neutral, neutral, neutral, neutral]   \n",
       "4      [neutral, neutral, neutral, neutral, neutral]   \n",
       "...                                              ...   \n",
       "12901  [neutral, neutral, neutral, neutral, neutral]   \n",
       "12902  [neutral, neutral, neutral, neutral, neutral]   \n",
       "12903  [neutral, neutral, neutral, neutral, neutral]   \n",
       "12904  [neutral, neutral, neutral, neutral, neutral]   \n",
       "12905  [neutral, neutral, neutral, neutral, neutral]   \n",
       "\n",
       "                                   probabilities_cluster  \n",
       "0      [0.9993815422058105, 0.9931160807609558, 0.999...  \n",
       "1      [0.9991391897201538, 0.9988901019096375, 0.991...  \n",
       "2      [0.9992584586143494, 0.9989070892333984, 0.998...  \n",
       "3      [0.7511304020881653, 0.9971051812171936, 0.999...  \n",
       "4      [0.9990100860595703, 0.9978340268135071, 0.988...  \n",
       "...                                                  ...  \n",
       "12901  [0.9992725253105164, 0.9987848401069641, 0.999...  \n",
       "12902  [0.9991181492805481, 0.9991711378097534, 0.997...  \n",
       "12903  [0.9981316924095154, 0.9973798394203186, 0.998...  \n",
       "12904  [0.9993014335632324, 0.9990935325622559, 0.998...  \n",
       "12905  [0.9974094033241272, 0.9990146160125732, 0.978...  \n",
       "\n",
       "[12906 rows x 17 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd805970-7e22-464a-bca2-c46532ff4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims.to_pickle('entailment_cluster.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e68e5429-90fe-477e-866f-0174de88c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_frequent_category(categories_list):\n",
    "    counter = Counter(categories_list)\n",
    "    return counter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ef5e230-c8f8-4c6c-871b-c4473cc4ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_non_neutral(categories_list):\n",
    "    counter = Counter(categories_list)\n",
    "    for element,count in counter.items():\n",
    "        if (count >= 2) & (element!='neutral'):\n",
    "            return element\n",
    "    return 'neutral'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c21cf198-b146-4f76-b669-46ff75b75c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\4136441315.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['consensus'] = df_claims['predictions'].apply(most_frequent_category)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral          12796\n",
       "contradiction       71\n",
       "entailment          39\n",
       "Name: consensus, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims['consensus'] = df_claims['predictions'].apply(most_frequent_category)\n",
    "df_claims['consensus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b8800c7-ba7f-4ab7-8400-a5c675649eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral          12430\n",
       "contradiction      260\n",
       "entailment         216\n",
       "Name: consensus, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims['consensus'] = df_claims['predictions'].apply(count_non_neutral)\n",
    "df_claims['consensus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc0b3d84-3259-4e23-be4a-7ded9a3126a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>char_length</th>\n",
       "      <th>anon_embeddings</th>\n",
       "      <th>topics</th>\n",
       "      <th>anon_sentence</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_probability</th>\n",
       "      <th>top_sentences</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>top_sentences_cluster</th>\n",
       "      <th>predictions_cluster</th>\n",
       "      <th>probabilities_cluster</th>\n",
       "      <th>consensus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>One year into ABB's 2030 sustainability strate...</td>\n",
       "      <td>21</td>\n",
       "      <td>[-0.03387668, 0.04702735, 0.0067782644, 0.0184...</td>\n",
       "      <td>123</td>\n",
       "      <td>[-0.039394952, 0.055466365, 0.015991926, 0.016...</td>\n",
       "      <td>0</td>\n",
       "      <td>One year into the company 2030 sustainability ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.947520</td>\n",
       "      <td>[Last year, ABB released its Sustainability St...</td>\n",
       "      <td>[neutral, entailment, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9908430576324463, 0.965498685836792, 0.7367...</td>\n",
       "      <td>[Recent projects include the Maid of the Mist ...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9993815422058105, 0.9931160807609558, 0.999...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>27</td>\n",
       "      <td>[0.072760716, 0.09948956, 0.077118196, 0.02812...</td>\n",
       "      <td>152</td>\n",
       "      <td>[0.07276068, 0.09948958, 0.077118136, 0.028125...</td>\n",
       "      <td>1</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.975864</td>\n",
       "      <td>[SN: Company report shows that ABB's greenhous...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, contradic...</td>\n",
       "      <td>[0.999405026435852, 0.994537889957428, 0.99930...</td>\n",
       "      <td>[President Jesse Henson, the savings from a co...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9991391897201538, 0.9988901019096375, 0.991...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>26</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>168</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>0</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.982865</td>\n",
       "      <td>[We've been making concrete efforts towards ac...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9995107650756836, 0.9830822944641113, 0.995...</td>\n",
       "      <td>[We are excited to include ABB among the trust...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9992584586143494, 0.9989070892333984, 0.998...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>28</td>\n",
       "      <td>[0.0023520757, 0.040041316, 0.010221989, 0.016...</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.0023520836, 0.04004134, 0.010221971, 0.0164...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>[Our greenhouse gas emissions reduction target...</td>\n",
       "      <td>[entailment, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9383401274681091, 0.8523229956626892, 0.999...</td>\n",
       "      <td>[Ships won't require any other source of elect...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.7511304020881653, 0.9971051812171936, 0.999...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>36</td>\n",
       "      <td>[-0.06374183, -0.02712268, -0.040378235, -0.02...</td>\n",
       "      <td>212</td>\n",
       "      <td>[-0.06374184, -0.027122695, -0.040378183, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.966742</td>\n",
       "      <td>[Although borne from the electrification busin...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9956797361373901, 0.9982929825782776, 0.999...</td>\n",
       "      <td>[Shaft generator power output on such vessels ...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9990100860595703, 0.9978340268135071, 0.988...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12901</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Our Responsible Sourcing program sets expectat...</td>\n",
       "      <td>34</td>\n",
       "      <td>[-0.06368477, 0.010128789, -0.021725688, -0.02...</td>\n",
       "      <td>257</td>\n",
       "      <td>[-0.06368478, 0.010128791, -0.02172569, -0.022...</td>\n",
       "      <td>0</td>\n",
       "      <td>Our Responsible Sourcing program sets expectat...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>[This collaboration supports the industry thro...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.995686948299408, 0.9650912880897522, 0.9904...</td>\n",
       "      <td>[According to a news release from the WWF, the...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9992725253105164, 0.9987848401069641, 0.999...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12902</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Walmart has prioritized working with stakehold...</td>\n",
       "      <td>34</td>\n",
       "      <td>[0.0054569603, 0.021002548, 0.0049035875, 0.00...</td>\n",
       "      <td>258</td>\n",
       "      <td>[-0.027358495, 0.019750984, -0.0058520334, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>the company has prioritized working with stake...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.599842</td>\n",
       "      <td>[To promote human dignity, Walmart has also co...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9997122883796692, 0.994895875453949, 0.9991...</td>\n",
       "      <td>[Walmart's giant rooftops and parking lots are...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9991181492805481, 0.9991711378097534, 0.997...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12903</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To advance responsible recruitment across our ...</td>\n",
       "      <td>23</td>\n",
       "      <td>[-0.044291113, -0.04852808, -0.02642449, 0.013...</td>\n",
       "      <td>166</td>\n",
       "      <td>[-0.06653639, -0.061157897, -0.023344118, 0.01...</td>\n",
       "      <td>0</td>\n",
       "      <td>To advance responsible recruitment across our ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.825599</td>\n",
       "      <td>[Walmart recently held its seventh annual Supp...</td>\n",
       "      <td>[contradiction, neutral, neutral, neutral, neu...</td>\n",
       "      <td>[0.7207563519477844, 0.9993495345115662, 0.995...</td>\n",
       "      <td>[Piloting innovative financial vehicles to sup...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9981316924095154, 0.9973798394203186, 0.998...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12904</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.02941792, -0.038456682, -0.01928836, -0.00...</td>\n",
       "      <td>81</td>\n",
       "      <td>[-0.029417915, -0.038456634, -0.019288322, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.792461</td>\n",
       "      <td>[We work closely with logistics partners, NGOs...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9987469911575317, 0.9983007311820984, 0.997...</td>\n",
       "      <td>[Although it has mostly focused on using renew...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9993014335632324, 0.9990935325622559, 0.998...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12905</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To accelerate system-wide change, the Walmart ...</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.003541183, 0.046546437, -0.00028145174, -0....</td>\n",
       "      <td>260</td>\n",
       "      <td>[-0.02246362, 0.022425106, -0.013262148, -0.02...</td>\n",
       "      <td>6</td>\n",
       "      <td>To accelerate system-wide change, the the comp...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.913087</td>\n",
       "      <td>[She adds: The Walmart Foundation is supportin...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9987826943397522, 0.9405285716056824, 0.977...</td>\n",
       "      <td>[Our Zero-Waste Inspired approach is intended ...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9974094033241272, 0.9990146160125732, 0.978...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12906 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_type  company                                           sentence  \\\n",
       "0       report      abb  One year into ABB's 2030 sustainability strate...   \n",
       "1       report      abb  Compared with our baseline year of 2019, we ha...   \n",
       "2       report      abb  Alongside these headline achievements, we made...   \n",
       "3       report      abb  Our 2030 GHG emissions reduction target was va...   \n",
       "4       report      abb  We also joined the SBTi's Business Ambition fo...   \n",
       "...        ...      ...                                                ...   \n",
       "12901   report  walmart  Our Responsible Sourcing program sets expectat...   \n",
       "12902   report  walmart  Walmart has prioritized working with stakehold...   \n",
       "12903   report  walmart  To advance responsible recruitment across our ...   \n",
       "12904   report  walmart  We also promote the adoption of best practices...   \n",
       "12905   report  walmart  To accelerate system-wide change, the Walmart ...   \n",
       "\n",
       "       word count                                         embeddings  \\\n",
       "0              21  [-0.03387668, 0.04702735, 0.0067782644, 0.0184...   \n",
       "1              27  [0.072760716, 0.09948956, 0.077118196, 0.02812...   \n",
       "2              26  [0.014213712, 0.033080414, 0.025592497, -0.021...   \n",
       "3              28  [0.0023520757, 0.040041316, 0.010221989, 0.016...   \n",
       "4              36  [-0.06374183, -0.02712268, -0.040378235, -0.02...   \n",
       "...           ...                                                ...   \n",
       "12901          34  [-0.06368477, 0.010128789, -0.021725688, -0.02...   \n",
       "12902          34  [0.0054569603, 0.021002548, 0.0049035875, 0.00...   \n",
       "12903          23  [-0.044291113, -0.04852808, -0.02642449, 0.013...   \n",
       "12904          13  [-0.02941792, -0.038456682, -0.01928836, -0.00...   \n",
       "12905          38  [0.003541183, 0.046546437, -0.00028145174, -0....   \n",
       "\n",
       "       char_length                                    anon_embeddings  topics  \\\n",
       "0              123  [-0.039394952, 0.055466365, 0.015991926, 0.016...       0   \n",
       "1              152  [0.07276068, 0.09948958, 0.077118136, 0.028125...       1   \n",
       "2              168  [0.014213712, 0.033080414, 0.025592497, -0.021...       0   \n",
       "3              161  [0.0023520836, 0.04004134, 0.010221971, 0.0164...       1   \n",
       "4              212  [-0.06374184, -0.027122695, -0.040378183, -0.0...       1   \n",
       "...            ...                                                ...     ...   \n",
       "12901          257  [-0.06368478, 0.010128791, -0.02172569, -0.022...       0   \n",
       "12902          258  [-0.027358495, 0.019750984, -0.0058520334, 0.0...       0   \n",
       "12903          166  [-0.06653639, -0.061157897, -0.023344118, 0.01...       0   \n",
       "12904           81  [-0.029417915, -0.038456634, -0.019288322, -0....       0   \n",
       "12905          260  [-0.02246362, 0.022425106, -0.013262148, -0.02...       6   \n",
       "\n",
       "                                           anon_sentence claim  \\\n",
       "0      One year into the company 2030 sustainability ...   yes   \n",
       "1      Compared with our baseline year of 2019, we ha...   yes   \n",
       "2      Alongside these headline achievements, we made...   yes   \n",
       "3      Our 2030 GHG emissions reduction target was va...   yes   \n",
       "4      We also joined the SBTi's Business Ambition fo...   yes   \n",
       "...                                                  ...   ...   \n",
       "12901  Our Responsible Sourcing program sets expectat...   yes   \n",
       "12902  the company has prioritized working with stake...   yes   \n",
       "12903  To advance responsible recruitment across our ...   yes   \n",
       "12904  We also promote the adoption of best practices...   yes   \n",
       "12905  To accelerate system-wide change, the the comp...   yes   \n",
       "\n",
       "       claim_probability                                      top_sentences  \\\n",
       "0               0.947520  [Last year, ABB released its Sustainability St...   \n",
       "1               0.975864  [SN: Company report shows that ABB's greenhous...   \n",
       "2               0.982865  [We've been making concrete efforts towards ac...   \n",
       "3               0.990115  [Our greenhouse gas emissions reduction target...   \n",
       "4               0.966742  [Although borne from the electrification busin...   \n",
       "...                  ...                                                ...   \n",
       "12901           0.645536  [This collaboration supports the industry thro...   \n",
       "12902           0.599842  [To promote human dignity, Walmart has also co...   \n",
       "12903           0.825599  [Walmart recently held its seventh annual Supp...   \n",
       "12904           0.792461  [We work closely with logistics partners, NGOs...   \n",
       "12905           0.913087  [She adds: The Walmart Foundation is supportin...   \n",
       "\n",
       "                                             predictions  \\\n",
       "0       [neutral, entailment, neutral, neutral, neutral]   \n",
       "1      [neutral, neutral, neutral, neutral, contradic...   \n",
       "2          [neutral, neutral, neutral, neutral, neutral]   \n",
       "3       [entailment, neutral, neutral, neutral, neutral]   \n",
       "4          [neutral, neutral, neutral, neutral, neutral]   \n",
       "...                                                  ...   \n",
       "12901      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12902      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12903  [contradiction, neutral, neutral, neutral, neu...   \n",
       "12904      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12905      [neutral, neutral, neutral, neutral, neutral]   \n",
       "\n",
       "                                           probabilities  \\\n",
       "0      [0.9908430576324463, 0.965498685836792, 0.7367...   \n",
       "1      [0.999405026435852, 0.994537889957428, 0.99930...   \n",
       "2      [0.9995107650756836, 0.9830822944641113, 0.995...   \n",
       "3      [0.9383401274681091, 0.8523229956626892, 0.999...   \n",
       "4      [0.9956797361373901, 0.9982929825782776, 0.999...   \n",
       "...                                                  ...   \n",
       "12901  [0.995686948299408, 0.9650912880897522, 0.9904...   \n",
       "12902  [0.9997122883796692, 0.994895875453949, 0.9991...   \n",
       "12903  [0.7207563519477844, 0.9993495345115662, 0.995...   \n",
       "12904  [0.9987469911575317, 0.9983007311820984, 0.997...   \n",
       "12905  [0.9987826943397522, 0.9405285716056824, 0.977...   \n",
       "\n",
       "                                   top_sentences_cluster  \\\n",
       "0      [Recent projects include the Maid of the Mist ...   \n",
       "1      [President Jesse Henson, the savings from a co...   \n",
       "2      [We are excited to include ABB among the trust...   \n",
       "3      [Ships won't require any other source of elect...   \n",
       "4      [Shaft generator power output on such vessels ...   \n",
       "...                                                  ...   \n",
       "12901  [According to a news release from the WWF, the...   \n",
       "12902  [Walmart's giant rooftops and parking lots are...   \n",
       "12903  [Piloting innovative financial vehicles to sup...   \n",
       "12904  [Although it has mostly focused on using renew...   \n",
       "12905  [Our Zero-Waste Inspired approach is intended ...   \n",
       "\n",
       "                                 predictions_cluster  \\\n",
       "0      [neutral, neutral, neutral, neutral, neutral]   \n",
       "1      [neutral, neutral, neutral, neutral, neutral]   \n",
       "2      [neutral, neutral, neutral, neutral, neutral]   \n",
       "3      [neutral, neutral, neutral, neutral, neutral]   \n",
       "4      [neutral, neutral, neutral, neutral, neutral]   \n",
       "...                                              ...   \n",
       "12901  [neutral, neutral, neutral, neutral, neutral]   \n",
       "12902  [neutral, neutral, neutral, neutral, neutral]   \n",
       "12903  [neutral, neutral, neutral, neutral, neutral]   \n",
       "12904  [neutral, neutral, neutral, neutral, neutral]   \n",
       "12905  [neutral, neutral, neutral, neutral, neutral]   \n",
       "\n",
       "                                   probabilities_cluster consensus  \n",
       "0      [0.9993815422058105, 0.9931160807609558, 0.999...   neutral  \n",
       "1      [0.9991391897201538, 0.9988901019096375, 0.991...   neutral  \n",
       "2      [0.9992584586143494, 0.9989070892333984, 0.998...   neutral  \n",
       "3      [0.7511304020881653, 0.9971051812171936, 0.999...   neutral  \n",
       "4      [0.9990100860595703, 0.9978340268135071, 0.988...   neutral  \n",
       "...                                                  ...       ...  \n",
       "12901  [0.9992725253105164, 0.9987848401069641, 0.999...   neutral  \n",
       "12902  [0.9991181492805481, 0.9991711378097534, 0.997...   neutral  \n",
       "12903  [0.9981316924095154, 0.9973798394203186, 0.998...   neutral  \n",
       "12904  [0.9993014335632324, 0.9990935325622559, 0.998...   neutral  \n",
       "12905  [0.9974094033241272, 0.9990146160125732, 0.978...   neutral  \n",
       "\n",
       "[12906 rows x 18 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d54534f-951d-42d0-b1ff-8569eb1da805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral          10435\n",
       "contradiction      242\n",
       "entailment         190\n",
       "Name: consensus, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims[df_claims['topics'].isin(lim_topics)]['consensus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a0e80b1-5cb7-4e51-b776-baedf7cb500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_database_total = {}\n",
    "for firm in set(df_claims['company']):\n",
    "     # calculate the average sentiment score for this firm for symbolic actions\n",
    "    ver_score = len(df_claims[(df_claims['company']==firm)&(df_claims['consensus']!='entailment')])/len(df_claims[df_claims['company']==firm])\n",
    "    gw_database_total[firm] = ver_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b94ff7a-1214-424b-95cd-44cff06a2518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'google': 0.9876543209876543,\n",
       " 'hershey': 0.9802631578947368,\n",
       " 'veolia': 1.0,\n",
       " 'colgate': 0.9957627118644068,\n",
       " 'dupont': 1.0,\n",
       " 'shell': 0.9759036144578314,\n",
       " 'microsoft': 0.9877862595419847,\n",
       " 'exxon': 1.0,\n",
       " 'inditex': 1.0,\n",
       " 'coca-cola': 0.9698275862068966,\n",
       " 'dell': 0.9761904761904762,\n",
       " 'cemex': 0.9826839826839827,\n",
       " 'airbus': 0.9696969696969697,\n",
       " 'tesla': 1.0,\n",
       " 'boeing': 0.9930555555555556,\n",
       " 'general-mills': 0.9716981132075472,\n",
       " 'bayer': 0.9824561403508771,\n",
       " 'nike': 0.9961832061068703,\n",
       " 'renault': 0.976,\n",
       " 'walmart': 1.0,\n",
       " 'mitsubishi': 0.993006993006993,\n",
       " 'apple': 0.9437689969604863,\n",
       " 'volvo': 0.953125,\n",
       " 'edp': 1.0,\n",
       " 'honda': 0.9885057471264368,\n",
       " 'tesco': 1.0,\n",
       " 'adidas': 0.981651376146789,\n",
       " 'citi': 1.0,\n",
       " 'abb': 0.9897959183673469,\n",
       " 'blackrock': 1.0,\n",
       " 'hp': 0.9855072463768116,\n",
       " 'ibm': 0.9636363636363636,\n",
       " 'hyundai': 0.9868852459016394,\n",
       " 'linde': 0.9897959183673469,\n",
       " 'beiersdorf': 1.0,\n",
       " 'h&m': 0.963076923076923,\n",
       " 'mercedes': 0.988795518207283,\n",
       " 'p&g': 0.9924242424242424,\n",
       " 'pepsico': 0.9547738693467337,\n",
       " 'sonoco': 1.0,\n",
       " 'toyota': 0.9863013698630136,\n",
       " 'ford-motor': 0.9961240310077519,\n",
       " 'enel': 1.0,\n",
       " 'chevron': 0.9875,\n",
       " 'mcdonald': 0.9735099337748344,\n",
       " 'dhl': 1.0,\n",
       " 'intel': 0.9828571428571429,\n",
       " 'eversource': 1.0,\n",
       " 'mondelez': 0.9946380697050938,\n",
       " 'chipotle': 1.0,\n",
       " 'schneider-electric': 0.9546313799621928,\n",
       " 'nextera': 0.994535519125683,\n",
       " 'diageo': 0.9839228295819936,\n",
       " 'ralph-lauren': 0.9907834101382489,\n",
       " 'nestle': 0.9927710843373494,\n",
       " 'henkel': 0.9780876494023905,\n",
       " 'rio-tinto': 0.9757085020242915,\n",
       " 'danone': 0.9811320754716981,\n",
       " 'starbucks': 0.9782608695652174,\n",
       " 'totalenergies': 0.9907120743034056,\n",
       " 'volkswagen': 0.9875518672199171,\n",
       " 'komatsu': 1.0,\n",
       " 'bmw': 1.0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_database_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64e4fb81-7f37-46d2-82d3-0583997f5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_gw_total = pd.DataFrame(gw_database_total.items(),columns=['company', 'verification_score'])\n",
    "scaler = MinMaxScaler()\n",
    "df_gw_total['verification_score'] = scaler.fit_transform(df_gw_total[['verification_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7361ea0e-0e14-4c54-9d9c-9f66a44edcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gw_total.to_csv('verification_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f90110b3-f47f-45c3-8f13-5ad0e9248bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10867, 16)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_lim = df_claims[df_claims['topics'].isin(lim_topics)]\n",
    "df_claims_lim.reset_index(inplace = True, drop = True)\n",
    "df_claims_lim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dfd44041-05cb-440c-909e-ac97030ea0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_database_total = {}\n",
    "for cluster in set(df_claims_lim['company']):\n",
    "     # calculate the average sentiment score for this firm for symbolic actions\n",
    "    ver_score = len(df_claims_lim[(df_claims_lim['company']==firm)&(df_claims_lim['consensus']!='entailment')])/len(df_claims_lim[df_claims_lim['company']==firm])\n",
    "    gw_database_total[firm] = ver_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de66ae06-9c68-4056-9684-7baf2d56ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gw_lim = pd.DataFrame(gw_database_total.items(),columns=['company', 'verification_score_lim'])\n",
    "df_gw_lim['verification_score_lim'] = scaler.fit_transform(df_gw_lim[['verification_score_lim']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2fda231-503c-4467-8993-0aa649dcd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verification = pd.merge(df_gw_total, df_gw_lim)\n",
    "df_verification.to_csv('verification_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42dc3c-cef3-46cc-8ce9-efb62158dc28",
   "metadata": {},
   "source": [
    "## Cluster-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a535140d-27ad-4fef-a99e-e7b9e441042a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # making lists to store values for the new columns\n",
    "top_sentences_column = []\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "# we run a for loop for each claim in the df_entailment dataset and check the validity of the claim\n",
    "for i,row in df_claims.iterrows():\n",
    "    # define our query (i.e. claim) and the company it's related to \n",
    "    query_embedding = row['embeddings']\n",
    "    company = row['company']\n",
    "    topic = row['topics']\n",
    "    # search only the article embeddings/sentences of the specific company\n",
    "    corpus_embeddings = df_article[(df_article['company']==company)&(df_article['topics']==topic)]['embeddings'].values\n",
    "    top_5 = util.semantic_search(torch.Tensor(query_embedding), torch.Tensor(np.array(list(corpus_embeddings))), top_k = 5)\n",
    "    # define a list to hold our top sentences and predictions to add these as a new variable after the loop\n",
    "    hard_predictions = []\n",
    "    top_sentences = []\n",
    "    soft_predictions =[]\n",
    "    for sentence in  top_5[0]:\n",
    "        # the premise is the claim\n",
    "        premise = row['sentence']\n",
    "        # the hypothesis is the sentence from the article(identified using the corpus id, which gives us the index of the sentence)\n",
    "        hypothesis = df_article[df_article['company']==company]['sentence'].values[sentence['corpus_id']]\n",
    "        tokens = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "        output = model(tokens[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "        soft_prediction = torch.softmax(output[\"logits\"][0], -1)\n",
    "        label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "        hard_prediction = label_names[torch.argmax(output[\"logits\"][0], -1).item()]\n",
    "        # append the different values to the correct list\n",
    "        top_sentences.append(hypothesis)\n",
    "        soft_predictions.append(max(torch.softmax(output[\"logits\"][0], -1).tolist()))\n",
    "        hard_predictions.append(hard_prediction)\n",
    "    # # now add the different lists as new variables\n",
    "    # df_sample.at[i,'top_sentences'] = str(top_sentences)\n",
    "    # df_sample.at[i,'predictions'] = str(hard_predictions)\n",
    "    # df_sample.at[i,'probabilities'] = str(soft_predictions)\n",
    "    top_sentences_column.append(top_sentences)\n",
    "    predictions.append(hard_predictions)\n",
    "    probabilities.append(soft_predictions)\n",
    "\n",
    "df_claims['top_sentences_cluster'] = top_sentences_column\n",
    "df_claims['predictions_cluster'] = predictions\n",
    "df_claims['probabilities_cluster'] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d401ab31-7d6d-4d52-8af6-b4468497e6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral          12430\n",
       "contradiction      260\n",
       "entailment         216\n",
       "Name: consensus, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims['consensus'] = df_claims['predictions'].apply(count_non_neutral)\n",
    "df_claims['consensus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34ee52ab-0777-4afa-bd84-3bc9317ccb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_database = {}\n",
    "for cluster in set(df_claims['topics']):\n",
    "    firm_cluster_score = {}\n",
    "    for firm in set(df_claims['company']):\n",
    "        try:\n",
    "            firm_cluster_score[firm] = len(df_claims[(df_claims['company']==firm)&(df_claims['topics']==cluster)&(df_claims['consensus']!='entailment')])/len(df_claims[(df_claims['company']==firm)&(df_claims['topics']==cluster)])\n",
    "        except:\n",
    "            firm_cluster_score[firm] = np.nan\n",
    "     # calculate the average sentiment score for this firm for symbolic actions\n",
    "    gw_database[cluster] = firm_cluster_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aeaf0d89-51f7-4925-9c8b-84e49c9ee0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gw = pd.DataFrame.from_dict(gw_database)\n",
    "df_gw['verification_cluster'] = df_gw[sust_topics].mean(axis = 1, skipna = True)\n",
    "df_gw['verification_cluster'] = scaler.fit_transform(df_gw[['verification_cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "211784e6-c002-45a7-9e23-ad4db50b519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gw.reset_index(inplace = True)\n",
    "df_gw.rename(columns = {'index':'company'}, inplace = True)\n",
    "df_gw = df_gw[['company', 'verification_cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "902aad29-f7a9-4206-a8b0-fffbb491254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>verification_score</th>\n",
       "      <th>verification_score_lim</th>\n",
       "      <th>verification_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google</td>\n",
       "      <td>0.780447</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>0.900646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hershey</td>\n",
       "      <td>0.649004</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>0.862687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veolia</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colgate</td>\n",
       "      <td>0.924645</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.962314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dupont</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>0.613396</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.889606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>totalenergies</td>\n",
       "      <td>0.834826</td>\n",
       "      <td>0.838762</td>\n",
       "      <td>0.949007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>0.778625</td>\n",
       "      <td>0.744845</td>\n",
       "      <td>0.957234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>komatsu</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>bmw</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          company  verification_score  verification_score_lim  \\\n",
       "0          google            0.780447                0.753731   \n",
       "1         hershey            0.649004                0.638686   \n",
       "2          veolia            1.000000                1.000000   \n",
       "3         colgate            0.924645                0.915385   \n",
       "4          dupont            1.000000                1.000000   \n",
       "..            ...                 ...                     ...   \n",
       "58      starbucks            0.613396                0.616279   \n",
       "59  totalenergies            0.834826                0.838762   \n",
       "60     volkswagen            0.778625                0.744845   \n",
       "61        komatsu            1.000000                1.000000   \n",
       "62            bmw            1.000000                1.000000   \n",
       "\n",
       "    verification_cluster  \n",
       "0               0.900646  \n",
       "1               0.862687  \n",
       "2               1.000000  \n",
       "3               0.962314  \n",
       "4               1.000000  \n",
       "..                   ...  \n",
       "58              0.889606  \n",
       "59              0.949007  \n",
       "60              0.957234  \n",
       "61              1.000000  \n",
       "62              1.000000  \n",
       "\n",
       "[63 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_verification = pd.read_csv('verification_scores.csv')\n",
    "df_verification = pd.merge(df_verification, df_gw)\n",
    "df_verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be400ebd-81e2-478d-b757-34a2a9bffcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10867, 18)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_lim = df_claims[df_claims['topics'].isin(lim_topics)]\n",
    "df_claims_lim.reset_index(inplace = True, drop = True)\n",
    "df_claims_lim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79b21eab-6109-447e-bd9c-63a27a7c6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_database_lim = {}\n",
    "for cluster in set(df_claims_lim['topics']):\n",
    "    firm_cluster_score = {}\n",
    "    for firm in set(df_claims_lim['company']):\n",
    "        try:\n",
    "            firm_cluster_score[firm] = len(df_claims_lim[(df_claims_lim['company']==firm)&(df_claims_lim['topics']==cluster)&(df_claims_lim['consensus']!='entailment')])/len(df_claims_lim[(df_claims_lim['company']==firm)&(df_claims_lim['topics']==cluster)])\n",
    "        except:\n",
    "            firm_cluster_score[firm] = np.nan\n",
    "     # calculate the average sentiment score for this firm for symbolic actions\n",
    "    gw_database_lim[cluster] = firm_cluster_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09ee9c06-993e-4079-b077-aaa8c9b709e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gw_lim = pd.DataFrame.from_dict(gw_database_lim)\n",
    "df_gw_lim['verification_cluster_lim'] = df_gw_lim[lim_topics].mean(axis = 1, skipna = True)\n",
    "df_gw_lim['verification_cluster_lim'] = scaler.fit_transform(df_gw_lim[['verification_cluster_lim']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36944177-22d0-417e-9018-2a09220b1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gw_lim.reset_index(inplace = True)\n",
    "df_gw_lim.rename(columns = {'index':'company'}, inplace = True)\n",
    "df_gw_lim = df_gw_lim[['company', 'verification_cluster_lim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "013696b1-e7c5-4742-bdb0-01f9a0a2a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verification = pd.merge(df_verification, df_gw_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f9f82b6-7910-4f2b-9a7d-02d6170ac2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verification.to_csv('verification_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "28a77146-4cf1-408c-bad0-d23c0841de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment': 0.3, 'neutral': 99.7, 'contradiction': 0.1}\n",
      "{'entailment': 0.1, 'neutral': 99.6, 'contradiction': 0.3}\n",
      "{'entailment': 0.1, 'neutral': 99.6, 'contradiction': 0.3}\n",
      "{'entailment': 0.2, 'neutral': 1.7, 'contradiction': 98.1}\n",
      "{'entailment': 0.2, 'neutral': 99.2, 'contradiction': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(nli_model)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(nli_model)\n",
    "\n",
    "# for sentence in top_5[0]:\n",
    "#     premise = row['sentence']\n",
    "#     hypothesis = df_article[df_article['company']==company]['sentence'].values[sentence['corpus_id']]\n",
    "#     tokens = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "#     output = model(tokens[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "#     prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "#     label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "#     prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "#     print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03776886-9e61-4b47-bcba-85e2677ef4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in case the input sentence is too long:\n",
    "# input_id_chunks = tokens_plus['input_ids'][0].split(510)\n",
    "# mask_chunks = tokens_plus['attention_mask'][0].split(510)\n",
    "\n",
    "# input_id_chunks = list(input_id_chunks)\n",
    "# mask_chunks = list(mask_chunks)\n",
    "\n",
    "\n",
    "# chunksize = 512\n",
    "# for i in range(len(input_id_chunks)):\n",
    "#     input_id_chunks[i] = torch.cat([\n",
    "#         torch.Tensor([101]), input_id_chunks[i], torch.Tensor([102])\n",
    "#     ])\n",
    "#     mask_chunks[i] = torch.cat([\n",
    "#         torch.Tensor([1]), mask_chunks[i], torch.Tensor([1])\n",
    "#     ])\n",
    "#     pad_len = chunksize - input_id_chunks[i].shape[0]\n",
    "    \n",
    "#     if pad_len > 0:\n",
    "#         input_id_chunks[i] = torch.cat([\n",
    "#             input_id_chunks[i], torch.Tensor([0]*pad_len)\n",
    "#         ])\n",
    "#         mask_id_chunks[i] = torch.cat([\n",
    "#             mask_id_chunks[i], torch.Tensor([0]*pad_len)\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a129ad-0984-401c-8645-472ea2d7a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = torch.stack(input_id_chunks)\n",
    "# attention_mask = torch.stack(mask_chunks)\n",
    "\n",
    "# input_dict = {\n",
    "#     'input_ids':input_ids.long(),\n",
    "#     'attention_mask': attention_mask.int()\n",
    "# }\n",
    "# input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6609a51-4e76-45ad-acb5-7abd6b34ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model(**input_dict)\n",
    "\n",
    "# probs = torch.nn.functional.softmax(outputs[0], dim = -1)\n",
    "# probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489ae33-d833-4a7e-9063-180735017ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = probs.mean(dim = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
