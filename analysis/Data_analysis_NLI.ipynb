{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66c81ae-bf25-4c7e-aedc-83cdb2540b23",
   "metadata": {},
   "source": [
    "# Set-up and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7ea0dd-fb65-491b-99fc-4fb59463c269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dathn\\anaconda3\\envs\\thesis_v2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer, util, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e060b6-5a3d-4b80-b48f-703c6ce3effd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ead8ee9-829b-4667-a182-9dce6cac5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '..\\\\data_structured'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8606a26-1cc5-4a94-bb56-562dbe6a32d8",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1908e6a8-38eb-429d-8b2c-f1a70e339679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = pd.read_pickle(os.path.join(path_data, 'comb.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "63bfb2d4-f31a-444c-95ab-3b1dae145054",
   "metadata": {},
   "outputs": [],
   "source": [
    "sust_topics = [0,1,2,3,4,5,6,7,8,10,11,20,25]\n",
    "lim_topics = [1,2,3,4,5,7,8,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69b0cc0-985c-4273-8e32-9eae185ff80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyze = df_comb[df_comb['topics'].isin(sust_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592184b6-bf51-4875-91f1-8915d324a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = df_analyze[df_analyze['doc_type']=='report']\n",
    "df_article = df_analyze[df_analyze['doc_type']=='news']\n",
    "df_report.reset_index(drop = True, inplace = True)\n",
    "df_article.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bc05c-484a-4081-9493-099b1b069b32",
   "metadata": {},
   "source": [
    "# Applying the pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99b2683-8ac1-49a8-bf58-9c2871cd6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████| 842/842 [00:00<?, ?B/s]\n",
      "C:\\Users\\dathn\\anaconda3\\envs\\thesis_v2\\lib\\site-packages\\huggingface_hub-0.14.1-py3.8.egg\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dathn\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████| 329M/329M [00:28<00:00, 11.4MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████| 1.42k/1.42k [00:00<?, ?B/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████████████████████████████████████| 798k/798k [00:00<00:00, 4.38MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████████████████████████████████████| 456k/456k [00:00<00:00, 1.75MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████| 2.15M/2.15M [00:00<00:00, 9.40MB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|████████████████████████████████████████| 4.95k/4.95k [00:00<00:00, 4.94MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|█████████████████████████████████████████████| 280/280 [00:00<00:00, 280kB/s]\n"
     ]
    }
   ],
   "source": [
    "claim_checker = pipeline(model = \"climatebert/environmental-claims\",  device = 0, batch_size = 64)\n",
    "sem_search = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n",
    "nli_model = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7625233a-959f-4dcf-b9e6-220ae96f5d33",
   "metadata": {},
   "source": [
    "The claim verification model consists of three stages - claim identification, evidence sentence selection and finally inference analysis. The three models above will help us achieve these three tasks. The ClimateBERT model is pre-trained to detect environmental and climate claims, semantic search will help us identify the 5 most relevant sentences from the corpus and finally the actual model can be used to check the entailment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d3e25-0f4f-44b6-a19e-61ac94148326",
   "metadata": {},
   "source": [
    "First, we apply the ClimateBERT model to identify environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a59cf-a6ed-48ab-b0a5-e0dcc6bb656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\2836976421.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_report['claim'] = [result['label'] for result in results]\n",
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\2836976421.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_report['claim_probability'] = [result['score'] for result in results]\n"
     ]
    }
   ],
   "source": [
    "# first part of the pipeline - identifying claims\n",
    "sentences = df_report['sentence'].tolist()  # Convert the column to a list\n",
    "\n",
    "results = claim_checker(sentences)\n",
    "df_report['claim'] = [result['label'] for result in results]\n",
    "df_report['claim_probability'] = [result['score'] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e266e6ec-f4be-4eee-98d3-c8c4179da1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>char_length</th>\n",
       "      <th>anon_embeddings</th>\n",
       "      <th>topics</th>\n",
       "      <th>anon_sentence</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>One year into ABB's 2030 sustainability strate...</td>\n",
       "      <td>21</td>\n",
       "      <td>[-0.03387668, 0.04702735, 0.0067782644, 0.0184...</td>\n",
       "      <td>123</td>\n",
       "      <td>[-0.039394952, 0.055466365, 0.015991926, 0.016...</td>\n",
       "      <td>0</td>\n",
       "      <td>One year into the company 2030 sustainability ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.947520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>27</td>\n",
       "      <td>[0.072760716, 0.09948956, 0.077118196, 0.02812...</td>\n",
       "      <td>152</td>\n",
       "      <td>[0.07276068, 0.09948958, 0.077118136, 0.028125...</td>\n",
       "      <td>1</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.975864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>26</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>168</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>0</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.982865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>28</td>\n",
       "      <td>[0.0023520757, 0.040041316, 0.010221989, 0.016...</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.0023520836, 0.04004134, 0.010221971, 0.0164...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.990115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>36</td>\n",
       "      <td>[-0.06374183, -0.02712268, -0.040378235, -0.02...</td>\n",
       "      <td>212</td>\n",
       "      <td>[-0.06374184, -0.027122695, -0.040378183, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.966742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30498</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>The initiative invites suppliers (starting wit...</td>\n",
       "      <td>31</td>\n",
       "      <td>[-0.06545875, 0.027131714, -0.0116220275, 0.06...</td>\n",
       "      <td>228</td>\n",
       "      <td>[-0.06545872, 0.027131697, -0.0116220135, 0.06...</td>\n",
       "      <td>10</td>\n",
       "      <td>The initiative invites suppliers (starting wit...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.814833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30499</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.02941792, -0.038456682, -0.01928836, -0.00...</td>\n",
       "      <td>81</td>\n",
       "      <td>[-0.029417915, -0.038456634, -0.019288322, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.792461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30500</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>In FY2022, 87% of Walmart U.S. information, co...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.009387232, -0.017577449, -0.12768476, 0.02...</td>\n",
       "      <td>175</td>\n",
       "      <td>[-0.03227741, -0.036879178, -0.1515622, 0.0158...</td>\n",
       "      <td>1</td>\n",
       "      <td>In FY2022, 87% of the company U.S. information...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.905760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30501</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To accelerate system-wide change, the Walmart ...</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.003541183, 0.046546437, -0.00028145174, -0....</td>\n",
       "      <td>260</td>\n",
       "      <td>[-0.02246362, 0.022425106, -0.013262148, -0.02...</td>\n",
       "      <td>6</td>\n",
       "      <td>To accelerate system-wide change, the the comp...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.913087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30502</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Factories develop supervised corrective action...</td>\n",
       "      <td>18</td>\n",
       "      <td>[-0.032323312, -0.01603831, 0.026886059, 0.030...</td>\n",
       "      <td>131</td>\n",
       "      <td>[-0.032323312, -0.01603831, 0.026886059, 0.030...</td>\n",
       "      <td>1</td>\n",
       "      <td>Factories develop supervised corrective action...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.996591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30503 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_type  company                                           sentence  \\\n",
       "0       report      abb  One year into ABB's 2030 sustainability strate...   \n",
       "1       report      abb  Compared with our baseline year of 2019, we ha...   \n",
       "2       report      abb  Alongside these headline achievements, we made...   \n",
       "3       report      abb  Our 2030 GHG emissions reduction target was va...   \n",
       "4       report      abb  We also joined the SBTi's Business Ambition fo...   \n",
       "...        ...      ...                                                ...   \n",
       "30498   report  walmart  The initiative invites suppliers (starting wit...   \n",
       "30499   report  walmart  We also promote the adoption of best practices...   \n",
       "30500   report  walmart  In FY2022, 87% of Walmart U.S. information, co...   \n",
       "30501   report  walmart  To accelerate system-wide change, the Walmart ...   \n",
       "30502   report  walmart  Factories develop supervised corrective action...   \n",
       "\n",
       "       word count                                         embeddings  \\\n",
       "0              21  [-0.03387668, 0.04702735, 0.0067782644, 0.0184...   \n",
       "1              27  [0.072760716, 0.09948956, 0.077118196, 0.02812...   \n",
       "2              26  [0.014213712, 0.033080414, 0.025592497, -0.021...   \n",
       "3              28  [0.0023520757, 0.040041316, 0.010221989, 0.016...   \n",
       "4              36  [-0.06374183, -0.02712268, -0.040378235, -0.02...   \n",
       "...           ...                                                ...   \n",
       "30498          31  [-0.06545875, 0.027131714, -0.0116220275, 0.06...   \n",
       "30499          13  [-0.02941792, -0.038456682, -0.01928836, -0.00...   \n",
       "30500          25  [-0.009387232, -0.017577449, -0.12768476, 0.02...   \n",
       "30501          38  [0.003541183, 0.046546437, -0.00028145174, -0....   \n",
       "30502          18  [-0.032323312, -0.01603831, 0.026886059, 0.030...   \n",
       "\n",
       "       char_length                                    anon_embeddings  topics  \\\n",
       "0              123  [-0.039394952, 0.055466365, 0.015991926, 0.016...       0   \n",
       "1              152  [0.07276068, 0.09948958, 0.077118136, 0.028125...       1   \n",
       "2              168  [0.014213712, 0.033080414, 0.025592497, -0.021...       0   \n",
       "3              161  [0.0023520836, 0.04004134, 0.010221971, 0.0164...       1   \n",
       "4              212  [-0.06374184, -0.027122695, -0.040378183, -0.0...       1   \n",
       "...            ...                                                ...     ...   \n",
       "30498          228  [-0.06545872, 0.027131697, -0.0116220135, 0.06...      10   \n",
       "30499           81  [-0.029417915, -0.038456634, -0.019288322, -0....       0   \n",
       "30500          175  [-0.03227741, -0.036879178, -0.1515622, 0.0158...       1   \n",
       "30501          260  [-0.02246362, 0.022425106, -0.013262148, -0.02...       6   \n",
       "30502          131  [-0.032323312, -0.01603831, 0.026886059, 0.030...       1   \n",
       "\n",
       "                                           anon_sentence claim  \\\n",
       "0      One year into the company 2030 sustainability ...   yes   \n",
       "1      Compared with our baseline year of 2019, we ha...   yes   \n",
       "2      Alongside these headline achievements, we made...   yes   \n",
       "3      Our 2030 GHG emissions reduction target was va...   yes   \n",
       "4      We also joined the SBTi's Business Ambition fo...   yes   \n",
       "...                                                  ...   ...   \n",
       "30498  The initiative invites suppliers (starting wit...    no   \n",
       "30499  We also promote the adoption of best practices...   yes   \n",
       "30500  In FY2022, 87% of the company U.S. information...    no   \n",
       "30501  To accelerate system-wide change, the the comp...   yes   \n",
       "30502  Factories develop supervised corrective action...    no   \n",
       "\n",
       "       claim_probability  \n",
       "0               0.947520  \n",
       "1               0.975864  \n",
       "2               0.982865  \n",
       "3               0.990115  \n",
       "4               0.966742  \n",
       "...                  ...  \n",
       "30498           0.814833  \n",
       "30499           0.792461  \n",
       "30500           0.905760  \n",
       "30501           0.913087  \n",
       "30502           0.996591  \n",
       "\n",
       "[30503 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7481b47-28b4-427e-adfa-df700fb71c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12906, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims = df_report[df_report['claim']=='yes']\n",
    "df_claims.reset_index(inplace = True, drop = True)\n",
    "df_claims.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c316f-b561-4249-b7ab-47dc60a70ed0",
   "metadata": {},
   "source": [
    "Now we create the sentence embeddings using the semantic search model. These embeddings will be used by the sentence transformers package to find the top 5 most similar sentences from the article corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728f552-a3b8-49b1-83d9-3cf96800e9e7",
   "metadata": {},
   "source": [
    "Since this took a while I will also pickle these to save my progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ee4f17-52d7-4072-9765-91a2708dbf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_article.to_pickle('art.pkl')\n",
    "# df_claims.to_pickle('claims.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75201a1e-dd5c-450a-a1e8-80bda9135b53",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sentence transformers has a utility called semantic search which can be used to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "810a93c3-b6db-4a3c-a476-750d808090c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 18.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,row in df_claims.iterrows():\n",
    "    query_embedding = row['embeddings']\n",
    "    company = row['company']\n",
    "    # search only the article embeddings/sentences of the specific company\n",
    "    corpus_embeddings = df_article[df_article['company']==company]['embeddings'].values\n",
    "    top_5 = util.semantic_search(torch.Tensor(query_embedding), torch.Tensor(np.array(list(corpus_embeddings))), top_k = 5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a73c87-b632-4938-b0ba-7838316bf398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 132, 'score': 0.7928017377853394},\n",
       "  {'corpus_id': 524, 'score': 0.7137691974639893},\n",
       "  {'corpus_id': 320, 'score': 0.7048271894454956},\n",
       "  {'corpus_id': 609, 'score': 0.6708470582962036},\n",
       "  {'corpus_id': 40, 'score': 0.6677325367927551}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbd249-9b35-44c9-bc13-753777ab9925",
   "metadata": {},
   "source": [
    "Let us now create a new dataframe based on df_claims, which will store the same information as this dataframe, but will also additionally hold the top 5 most similar sentences in a separate column, as well as whether these sentences entail, contradict or are neutral towards each other. I use the MoritzLaurer NLI model for this purpose as it states that it is the best performing NLI model as of June 2022. The code used for the classification is mostly copied from the HuggingFace transformers website and modified for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bb41abc-2c0a-48aa-9bd0-2783e70a8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_entailment = df_entailment.reindex(df_entailment.columns.tolist() + ['top_sentences','predictions','probabilities'], axis=1)  # version > 0.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "afb20ca9-8aa8-49f1-b8ca-254f6aa7dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample = df_entailment[:5] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a451f-6ccf-439d-913d-9e556958314b",
   "metadata": {},
   "source": [
    "We repeat the same code as above but expand upon it further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b225b238-35b4-417d-a925-9b690b923ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(nli_model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(nli_model).to(device)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4791e7e9-68eb-4e5c-b12d-28014c474ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\1041120475.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['top_sentences'] = top_sentences_column\n",
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\1041120475.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['predictions'] = predictions\n",
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\1041120475.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['probabilities'] = probabilities\n"
     ]
    }
   ],
   "source": [
    "# # making lists to store values for the new columns\n",
    "top_sentences_column = []\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "# we run a for loop for each claim in the df_entailment dataset and check the validity of the claim\n",
    "for i,row in df_claims.iterrows():\n",
    "    # define our query (i.e. claim) and the company it's related to \n",
    "    query_embedding = row['embeddings']\n",
    "    company = row['company']\n",
    "    # search only the article embeddings/sentences of the specific company\n",
    "    corpus_embeddings = df_article[df_article['company']==company]['embeddings'].values\n",
    "    top_5 = util.semantic_search(torch.Tensor(query_embedding), torch.Tensor(np.array(list(corpus_embeddings))), top_k = 5)\n",
    "    # define a list to hold our top sentences and predictions to add these as a new variable after the loop\n",
    "    hard_predictions = []\n",
    "    top_sentences = []\n",
    "    soft_predictions =[]\n",
    "    for sentence in  top_5[0]:\n",
    "        # the premise is the claim\n",
    "        premise = row['sentence']\n",
    "        # the hypothesis is the sentence from the article(identified using the corpus id, which gives us the index of the sentence)\n",
    "        hypothesis = df_article[df_article['company']==company]['sentence'].values[sentence['corpus_id']]\n",
    "        tokens = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "        output = model(tokens[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "        soft_prediction = torch.softmax(output[\"logits\"][0], -1)\n",
    "        label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "        hard_prediction = label_names[torch.argmax(output[\"logits\"][0], -1).item()]\n",
    "        # append the different values to the correct list\n",
    "        top_sentences.append(hypothesis)\n",
    "        soft_predictions.append(max(torch.softmax(output[\"logits\"][0], -1).tolist()))\n",
    "        hard_predictions.append(hard_prediction)\n",
    "    # # now add the different lists as new variables\n",
    "    # df_sample.at[i,'top_sentences'] = str(top_sentences)\n",
    "    # df_sample.at[i,'predictions'] = str(hard_predictions)\n",
    "    # df_sample.at[i,'probabilities'] = str(soft_predictions)\n",
    "    top_sentences_column.append(top_sentences)\n",
    "    predictions.append(hard_predictions)\n",
    "    probabilities.append(soft_predictions)\n",
    "\n",
    "df_claims['top_sentences'] = top_sentences_column\n",
    "df_claims['predictions'] = predictions\n",
    "df_claims['probabilities'] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd805970-7e22-464a-bca2-c46532ff4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims.to_pickle('entailment.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e68e5429-90fe-477e-866f-0174de88c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_frequent_category(categories_list):\n",
    "    counter = Counter(categories_list)\n",
    "    return counter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3a6c3af-d665-4f38-b8b7-bd09ee63a8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_list = ['neutral','neutral','entailment','neutral','contradiction']\n",
    "count_non_neutral(cat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ef5e230-c8f8-4c6c-871b-c4473cc4ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_non_neutral(categories_list):\n",
    "    counter = Counter(categories_list)\n",
    "    for element,count in counter.items():\n",
    "        if (count >= 2) & (element!='neutral'):\n",
    "            return element\n",
    "    return 'neutral'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c21cf198-b146-4f76-b669-46ff75b75c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\4136441315.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['consensus'] = df_claims['predictions'].apply(most_frequent_category)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral          12796\n",
       "contradiction       71\n",
       "entailment          39\n",
       "Name: consensus, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims['consensus'] = df_claims['predictions'].apply(most_frequent_category)\n",
    "df_claims['consensus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b8800c7-ba7f-4ab7-8400-a5c675649eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dathn\\AppData\\Local\\Temp\\ipykernel_8476\\1825575629.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_claims['consensus'] = df_claims['predictions'].apply(count_non_neutral)\n"
     ]
    }
   ],
   "source": [
    "df_claims['consensus'] = df_claims['predictions'].apply(count_non_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc0b3d84-3259-4e23-be4a-7ded9a3126a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>char_length</th>\n",
       "      <th>anon_embeddings</th>\n",
       "      <th>topics</th>\n",
       "      <th>anon_sentence</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_probability</th>\n",
       "      <th>top_sentences</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>consensus</th>\n",
       "      <th>most_similar_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>One year into ABB's 2030 sustainability strate...</td>\n",
       "      <td>21</td>\n",
       "      <td>[-0.03387668, 0.04702735, 0.0067782644, 0.0184...</td>\n",
       "      <td>123</td>\n",
       "      <td>[-0.039394952, 0.055466365, 0.015991926, 0.016...</td>\n",
       "      <td>0</td>\n",
       "      <td>One year into the company 2030 sustainability ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.947520</td>\n",
       "      <td>[Last year, ABB released its Sustainability St...</td>\n",
       "      <td>[neutral, entailment, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9908430576324463, 0.965498685836792, 0.7367...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>27</td>\n",
       "      <td>[0.072760716, 0.09948956, 0.077118196, 0.02812...</td>\n",
       "      <td>152</td>\n",
       "      <td>[0.07276068, 0.09948958, 0.077118136, 0.028125...</td>\n",
       "      <td>1</td>\n",
       "      <td>Compared with our baseline year of 2019, we ha...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.975864</td>\n",
       "      <td>[SN: Company report shows that ABB's greenhous...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, contradic...</td>\n",
       "      <td>[0.999405026435852, 0.994537889957428, 0.99930...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>26</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>168</td>\n",
       "      <td>[0.014213712, 0.033080414, 0.025592497, -0.021...</td>\n",
       "      <td>0</td>\n",
       "      <td>Alongside these headline achievements, we made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.982865</td>\n",
       "      <td>[We've been making concrete efforts towards ac...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9995107650756836, 0.9830822944641113, 0.995...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>28</td>\n",
       "      <td>[0.0023520757, 0.040041316, 0.010221989, 0.016...</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.0023520836, 0.04004134, 0.010221971, 0.0164...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our 2030 GHG emissions reduction target was va...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>[Our greenhouse gas emissions reduction target...</td>\n",
       "      <td>[entailment, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9383401274681091, 0.8523229956626892, 0.999...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report</td>\n",
       "      <td>abb</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>36</td>\n",
       "      <td>[-0.06374183, -0.02712268, -0.040378235, -0.02...</td>\n",
       "      <td>212</td>\n",
       "      <td>[-0.06374184, -0.027122695, -0.040378183, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>We also joined the SBTi's Business Ambition fo...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.966742</td>\n",
       "      <td>[Although borne from the electrification busin...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9956797361373901, 0.9982929825782776, 0.999...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12901</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Our Responsible Sourcing program sets expectat...</td>\n",
       "      <td>34</td>\n",
       "      <td>[-0.06368477, 0.010128789, -0.021725688, -0.02...</td>\n",
       "      <td>257</td>\n",
       "      <td>[-0.06368478, 0.010128791, -0.02172569, -0.022...</td>\n",
       "      <td>0</td>\n",
       "      <td>Our Responsible Sourcing program sets expectat...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>[This collaboration supports the industry thro...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.995686948299408, 0.9650912880897522, 0.9904...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12902</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>Walmart has prioritized working with stakehold...</td>\n",
       "      <td>34</td>\n",
       "      <td>[0.0054569603, 0.021002548, 0.0049035875, 0.00...</td>\n",
       "      <td>258</td>\n",
       "      <td>[-0.027358495, 0.019750984, -0.0058520334, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>the company has prioritized working with stake...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.599842</td>\n",
       "      <td>[To promote human dignity, Walmart has also co...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9997122883796692, 0.994895875453949, 0.9991...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12903</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To advance responsible recruitment across our ...</td>\n",
       "      <td>23</td>\n",
       "      <td>[-0.044291113, -0.04852808, -0.02642449, 0.013...</td>\n",
       "      <td>166</td>\n",
       "      <td>[-0.06653639, -0.061157897, -0.023344118, 0.01...</td>\n",
       "      <td>0</td>\n",
       "      <td>To advance responsible recruitment across our ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.825599</td>\n",
       "      <td>[Walmart recently held its seventh annual Supp...</td>\n",
       "      <td>[contradiction, neutral, neutral, neutral, neu...</td>\n",
       "      <td>[0.7207563519477844, 0.9993495345115662, 0.995...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12904</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.02941792, -0.038456682, -0.01928836, -0.00...</td>\n",
       "      <td>81</td>\n",
       "      <td>[-0.029417915, -0.038456634, -0.019288322, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>We also promote the adoption of best practices...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.792461</td>\n",
       "      <td>[We work closely with logistics partners, NGOs...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9987469911575317, 0.9983007311820984, 0.997...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12905</th>\n",
       "      <td>report</td>\n",
       "      <td>walmart</td>\n",
       "      <td>To accelerate system-wide change, the Walmart ...</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.003541183, 0.046546437, -0.00028145174, -0....</td>\n",
       "      <td>260</td>\n",
       "      <td>[-0.02246362, 0.022425106, -0.013262148, -0.02...</td>\n",
       "      <td>6</td>\n",
       "      <td>To accelerate system-wide change, the the comp...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.913087</td>\n",
       "      <td>[She adds: The Walmart Foundation is supportin...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>[0.9987826943397522, 0.9405285716056824, 0.977...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12906 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_type  company                                           sentence  \\\n",
       "0       report      abb  One year into ABB's 2030 sustainability strate...   \n",
       "1       report      abb  Compared with our baseline year of 2019, we ha...   \n",
       "2       report      abb  Alongside these headline achievements, we made...   \n",
       "3       report      abb  Our 2030 GHG emissions reduction target was va...   \n",
       "4       report      abb  We also joined the SBTi's Business Ambition fo...   \n",
       "...        ...      ...                                                ...   \n",
       "12901   report  walmart  Our Responsible Sourcing program sets expectat...   \n",
       "12902   report  walmart  Walmart has prioritized working with stakehold...   \n",
       "12903   report  walmart  To advance responsible recruitment across our ...   \n",
       "12904   report  walmart  We also promote the adoption of best practices...   \n",
       "12905   report  walmart  To accelerate system-wide change, the Walmart ...   \n",
       "\n",
       "       word count                                         embeddings  \\\n",
       "0              21  [-0.03387668, 0.04702735, 0.0067782644, 0.0184...   \n",
       "1              27  [0.072760716, 0.09948956, 0.077118196, 0.02812...   \n",
       "2              26  [0.014213712, 0.033080414, 0.025592497, -0.021...   \n",
       "3              28  [0.0023520757, 0.040041316, 0.010221989, 0.016...   \n",
       "4              36  [-0.06374183, -0.02712268, -0.040378235, -0.02...   \n",
       "...           ...                                                ...   \n",
       "12901          34  [-0.06368477, 0.010128789, -0.021725688, -0.02...   \n",
       "12902          34  [0.0054569603, 0.021002548, 0.0049035875, 0.00...   \n",
       "12903          23  [-0.044291113, -0.04852808, -0.02642449, 0.013...   \n",
       "12904          13  [-0.02941792, -0.038456682, -0.01928836, -0.00...   \n",
       "12905          38  [0.003541183, 0.046546437, -0.00028145174, -0....   \n",
       "\n",
       "       char_length                                    anon_embeddings  topics  \\\n",
       "0              123  [-0.039394952, 0.055466365, 0.015991926, 0.016...       0   \n",
       "1              152  [0.07276068, 0.09948958, 0.077118136, 0.028125...       1   \n",
       "2              168  [0.014213712, 0.033080414, 0.025592497, -0.021...       0   \n",
       "3              161  [0.0023520836, 0.04004134, 0.010221971, 0.0164...       1   \n",
       "4              212  [-0.06374184, -0.027122695, -0.040378183, -0.0...       1   \n",
       "...            ...                                                ...     ...   \n",
       "12901          257  [-0.06368478, 0.010128791, -0.02172569, -0.022...       0   \n",
       "12902          258  [-0.027358495, 0.019750984, -0.0058520334, 0.0...       0   \n",
       "12903          166  [-0.06653639, -0.061157897, -0.023344118, 0.01...       0   \n",
       "12904           81  [-0.029417915, -0.038456634, -0.019288322, -0....       0   \n",
       "12905          260  [-0.02246362, 0.022425106, -0.013262148, -0.02...       6   \n",
       "\n",
       "                                           anon_sentence claim  \\\n",
       "0      One year into the company 2030 sustainability ...   yes   \n",
       "1      Compared with our baseline year of 2019, we ha...   yes   \n",
       "2      Alongside these headline achievements, we made...   yes   \n",
       "3      Our 2030 GHG emissions reduction target was va...   yes   \n",
       "4      We also joined the SBTi's Business Ambition fo...   yes   \n",
       "...                                                  ...   ...   \n",
       "12901  Our Responsible Sourcing program sets expectat...   yes   \n",
       "12902  the company has prioritized working with stake...   yes   \n",
       "12903  To advance responsible recruitment across our ...   yes   \n",
       "12904  We also promote the adoption of best practices...   yes   \n",
       "12905  To accelerate system-wide change, the the comp...   yes   \n",
       "\n",
       "       claim_probability                                      top_sentences  \\\n",
       "0               0.947520  [Last year, ABB released its Sustainability St...   \n",
       "1               0.975864  [SN: Company report shows that ABB's greenhous...   \n",
       "2               0.982865  [We've been making concrete efforts towards ac...   \n",
       "3               0.990115  [Our greenhouse gas emissions reduction target...   \n",
       "4               0.966742  [Although borne from the electrification busin...   \n",
       "...                  ...                                                ...   \n",
       "12901           0.645536  [This collaboration supports the industry thro...   \n",
       "12902           0.599842  [To promote human dignity, Walmart has also co...   \n",
       "12903           0.825599  [Walmart recently held its seventh annual Supp...   \n",
       "12904           0.792461  [We work closely with logistics partners, NGOs...   \n",
       "12905           0.913087  [She adds: The Walmart Foundation is supportin...   \n",
       "\n",
       "                                             predictions  \\\n",
       "0       [neutral, entailment, neutral, neutral, neutral]   \n",
       "1      [neutral, neutral, neutral, neutral, contradic...   \n",
       "2          [neutral, neutral, neutral, neutral, neutral]   \n",
       "3       [entailment, neutral, neutral, neutral, neutral]   \n",
       "4          [neutral, neutral, neutral, neutral, neutral]   \n",
       "...                                                  ...   \n",
       "12901      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12902      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12903  [contradiction, neutral, neutral, neutral, neu...   \n",
       "12904      [neutral, neutral, neutral, neutral, neutral]   \n",
       "12905      [neutral, neutral, neutral, neutral, neutral]   \n",
       "\n",
       "                                           probabilities consensus  \\\n",
       "0      [0.9908430576324463, 0.965498685836792, 0.7367...   neutral   \n",
       "1      [0.999405026435852, 0.994537889957428, 0.99930...   neutral   \n",
       "2      [0.9995107650756836, 0.9830822944641113, 0.995...   neutral   \n",
       "3      [0.9383401274681091, 0.8523229956626892, 0.999...   neutral   \n",
       "4      [0.9956797361373901, 0.9982929825782776, 0.999...   neutral   \n",
       "...                                                  ...       ...   \n",
       "12901  [0.995686948299408, 0.9650912880897522, 0.9904...   neutral   \n",
       "12902  [0.9997122883796692, 0.994895875453949, 0.9991...   neutral   \n",
       "12903  [0.7207563519477844, 0.9993495345115662, 0.995...   neutral   \n",
       "12904  [0.9987469911575317, 0.9983007311820984, 0.997...   neutral   \n",
       "12905  [0.9987826943397522, 0.9405285716056824, 0.977...   neutral   \n",
       "\n",
       "      most_similar_sentence  \n",
       "0                   neutral  \n",
       "1                   neutral  \n",
       "2                   neutral  \n",
       "3                   neutral  \n",
       "4                   neutral  \n",
       "...                     ...  \n",
       "12901               neutral  \n",
       "12902               neutral  \n",
       "12903               neutral  \n",
       "12904               neutral  \n",
       "12905               neutral  \n",
       "\n",
       "[12906 rows x 16 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d54534f-951d-42d0-b1ff-8569eb1da805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral          10435\n",
       "contradiction      242\n",
       "entailment         190\n",
       "Name: consensus, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims[df_claims['topics'].isin(lim_topics)]['consensus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61ebd350-d01e-400e-b0e8-949f579195b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_type</th>\n",
       "      <th>company</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>char_length</th>\n",
       "      <th>anon_embeddings</th>\n",
       "      <th>topics</th>\n",
       "      <th>anon_sentence</th>\n",
       "      <th>claim</th>\n",
       "      <th>claim_probability</th>\n",
       "      <th>top_sentences</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>consensus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>report</td>\n",
       "      <td>airbus</td>\n",
       "      <td>CO2: reduce direct (scope 1) and indirect (sco...</td>\n",
       "      <td>19</td>\n",
       "      <td>[0.042349424, 0.10064642, 0.03514003, 0.009380...</td>\n",
       "      <td>103</td>\n",
       "      <td>[0.042349424, 0.10064642, 0.03514003, 0.009380...</td>\n",
       "      <td>1</td>\n",
       "      <td>CO2: reduce direct (scope 1) and indirect (sco...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.901820</td>\n",
       "      <td>[We're focused on carbon emission reduction of...</td>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>[0.9953846335411072, 0.5285486578941345, 0.643...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>report</td>\n",
       "      <td>airbus</td>\n",
       "      <td>SAF produced by using most advanced pathways c...</td>\n",
       "      <td>20</td>\n",
       "      <td>[-0.006607856, -0.035302263, -0.07366908, 0.02...</td>\n",
       "      <td>122</td>\n",
       "      <td>[-0.0066078347, -0.035302337, -0.0736691, 0.02...</td>\n",
       "      <td>8</td>\n",
       "      <td>SAF produced by using most advanced pathways c...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.990116</td>\n",
       "      <td>[SAF produced using the most advanced pathways...</td>\n",
       "      <td>[contradiction, entailment, contradiction, neu...</td>\n",
       "      <td>[0.9935458302497864, 0.9918025135993958, 0.864...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>report</td>\n",
       "      <td>apple</td>\n",
       "      <td>213 suppliers committed to renewable electrici...</td>\n",
       "      <td>28</td>\n",
       "      <td>[-0.0044368203, -0.008024681, 0.02283219, -0.0...</td>\n",
       "      <td>202</td>\n",
       "      <td>[-0.019847926, -0.008363879, -0.02822676, -0.0...</td>\n",
       "      <td>3</td>\n",
       "      <td>213 suppliers committed to renewable electrici...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.994511</td>\n",
       "      <td>[As of the report date, 213 of the company's m...</td>\n",
       "      <td>[entailment, contradiction, neutral, contradic...</td>\n",
       "      <td>[0.8047620058059692, 0.9574432969093323, 0.998...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>report</td>\n",
       "      <td>apple</td>\n",
       "      <td>In fiscal year 2021, Apple and its suppliers b...</td>\n",
       "      <td>27</td>\n",
       "      <td>[-0.035300363, 0.025236329, 0.055155836, 0.037...</td>\n",
       "      <td>159</td>\n",
       "      <td>[-0.08419936, 0.03195669, 0.010630614, 0.05460...</td>\n",
       "      <td>3</td>\n",
       "      <td>In fiscal year 2021, the company and its suppl...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.994993</td>\n",
       "      <td>[The projects will generate 1.2 gigawatts of r...</td>\n",
       "      <td>[contradiction, contradiction, entailment, neu...</td>\n",
       "      <td>[0.8817325830459595, 0.9783431887626648, 0.935...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>report</td>\n",
       "      <td>apple</td>\n",
       "      <td>Together, these new initiatives reduced total ...</td>\n",
       "      <td>26</td>\n",
       "      <td>[0.023158113, 0.11676854, 0.08528477, 0.051681...</td>\n",
       "      <td>156</td>\n",
       "      <td>[0.023158146, 0.11676853, 0.085284784, 0.05168...</td>\n",
       "      <td>1</td>\n",
       "      <td>Together, these new initiatives reduced total ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.994826</td>\n",
       "      <td>[This change will effectively avoid 18 million...</td>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>[0.9969239830970764, 0.5747354626655579, 0.996...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11648</th>\n",
       "      <td>report</td>\n",
       "      <td>tesco</td>\n",
       "      <td>In 2009, Tesco became the first business globa...</td>\n",
       "      <td>18</td>\n",
       "      <td>[0.015835347, 0.041475583, -0.042232767, 0.046...</td>\n",
       "      <td>100</td>\n",
       "      <td>[-0.012548159, 0.027339203, -0.026353557, 0.03...</td>\n",
       "      <td>1</td>\n",
       "      <td>In 2009, the company became the first business...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>[Last year, Tesco committed to net-zero emissi...</td>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>[0.867167592048645, 0.9900526404380798, 0.7065...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11669</th>\n",
       "      <td>report</td>\n",
       "      <td>tesco</td>\n",
       "      <td>targets in line with a 1.5 C trajectory, commi...</td>\n",
       "      <td>19</td>\n",
       "      <td>[0.0045745503, -0.029099684, -0.0049787, 0.024...</td>\n",
       "      <td>102</td>\n",
       "      <td>[0.004574552, -0.029099733, -0.004978734, 0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>targets in line with a 1.5 C trajectory, commi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.992899</td>\n",
       "      <td>[Building on the good progress we've made in c...</td>\n",
       "      <td>[contradiction, contradiction, neutral, contra...</td>\n",
       "      <td>[0.9856816530227661, 0.9069458842277527, 0.998...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>report</td>\n",
       "      <td>totalenergies</td>\n",
       "      <td>Republic of the Congo In March 2021, TotalEner...</td>\n",
       "      <td>39</td>\n",
       "      <td>[-0.07422443, 0.015132636, -0.009076298, -0.00...</td>\n",
       "      <td>249</td>\n",
       "      <td>[-0.063250385, 0.01810402, -0.024252135, 0.009...</td>\n",
       "      <td>1</td>\n",
       "      <td>Republic of the Congo In March 2021, the compa...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.994960</td>\n",
       "      <td>[TOTALENERGIES has signed Corporate Power Purc...</td>\n",
       "      <td>[neutral, contradiction, contradiction, neutra...</td>\n",
       "      <td>[0.5680773854255676, 0.8769581317901611, 0.969...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12165</th>\n",
       "      <td>report</td>\n",
       "      <td>toyota</td>\n",
       "      <td>Toyota revealed in the CDP2 A List, the highes...</td>\n",
       "      <td>26</td>\n",
       "      <td>[0.016821591, -0.01882537, 0.0045505436, -0.02...</td>\n",
       "      <td>148</td>\n",
       "      <td>[-0.012330274, -0.040687118, -0.025833614, -0....</td>\n",
       "      <td>6</td>\n",
       "      <td>the company revealed in the CDP2 A List, the h...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.650870</td>\n",
       "      <td>[According to an article published by Electrek...</td>\n",
       "      <td>[contradiction, contradiction, neutral, contra...</td>\n",
       "      <td>[0.9970995187759399, 0.9604046940803528, 0.999...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12181</th>\n",
       "      <td>report</td>\n",
       "      <td>toyota</td>\n",
       "      <td>Based on this electrified vehicle strategy, To...</td>\n",
       "      <td>19</td>\n",
       "      <td>[0.04694206, -0.039846536, -0.004500647, -0.05...</td>\n",
       "      <td>129</td>\n",
       "      <td>[0.030652108, -0.014310505, -0.030372433, -0.0...</td>\n",
       "      <td>5</td>\n",
       "      <td>Based on this electrified vehicle strategy, th...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.768779</td>\n",
       "      <td>[Toyota expects to sell 8 million electrified ...</td>\n",
       "      <td>[contradiction, contradiction, neutral, contra...</td>\n",
       "      <td>[0.7136600613594055, 0.7362513542175293, 0.999...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_type        company  \\\n",
       "335     report         airbus   \n",
       "396     report         airbus   \n",
       "468     report          apple   \n",
       "469     report          apple   \n",
       "584     report          apple   \n",
       "...        ...            ...   \n",
       "11648   report          tesco   \n",
       "11669   report          tesco   \n",
       "11978   report  totalenergies   \n",
       "12165   report         toyota   \n",
       "12181   report         toyota   \n",
       "\n",
       "                                                sentence  word count  \\\n",
       "335    CO2: reduce direct (scope 1) and indirect (sco...          19   \n",
       "396    SAF produced by using most advanced pathways c...          20   \n",
       "468    213 suppliers committed to renewable electrici...          28   \n",
       "469    In fiscal year 2021, Apple and its suppliers b...          27   \n",
       "584    Together, these new initiatives reduced total ...          26   \n",
       "...                                                  ...         ...   \n",
       "11648  In 2009, Tesco became the first business globa...          18   \n",
       "11669  targets in line with a 1.5 C trajectory, commi...          19   \n",
       "11978  Republic of the Congo In March 2021, TotalEner...          39   \n",
       "12165  Toyota revealed in the CDP2 A List, the highes...          26   \n",
       "12181  Based on this electrified vehicle strategy, To...          19   \n",
       "\n",
       "                                              embeddings  char_length  \\\n",
       "335    [0.042349424, 0.10064642, 0.03514003, 0.009380...          103   \n",
       "396    [-0.006607856, -0.035302263, -0.07366908, 0.02...          122   \n",
       "468    [-0.0044368203, -0.008024681, 0.02283219, -0.0...          202   \n",
       "469    [-0.035300363, 0.025236329, 0.055155836, 0.037...          159   \n",
       "584    [0.023158113, 0.11676854, 0.08528477, 0.051681...          156   \n",
       "...                                                  ...          ...   \n",
       "11648  [0.015835347, 0.041475583, -0.042232767, 0.046...          100   \n",
       "11669  [0.0045745503, -0.029099684, -0.0049787, 0.024...          102   \n",
       "11978  [-0.07422443, 0.015132636, -0.009076298, -0.00...          249   \n",
       "12165  [0.016821591, -0.01882537, 0.0045505436, -0.02...          148   \n",
       "12181  [0.04694206, -0.039846536, -0.004500647, -0.05...          129   \n",
       "\n",
       "                                         anon_embeddings  topics  \\\n",
       "335    [0.042349424, 0.10064642, 0.03514003, 0.009380...       1   \n",
       "396    [-0.0066078347, -0.035302337, -0.0736691, 0.02...       8   \n",
       "468    [-0.019847926, -0.008363879, -0.02822676, -0.0...       3   \n",
       "469    [-0.08419936, 0.03195669, 0.010630614, 0.05460...       3   \n",
       "584    [0.023158146, 0.11676853, 0.085284784, 0.05168...       1   \n",
       "...                                                  ...     ...   \n",
       "11648  [-0.012548159, 0.027339203, -0.026353557, 0.03...       1   \n",
       "11669  [0.004574552, -0.029099733, -0.004978734, 0.02...       1   \n",
       "11978  [-0.063250385, 0.01810402, -0.024252135, 0.009...       1   \n",
       "12165  [-0.012330274, -0.040687118, -0.025833614, -0....       6   \n",
       "12181  [0.030652108, -0.014310505, -0.030372433, -0.0...       5   \n",
       "\n",
       "                                           anon_sentence claim  \\\n",
       "335    CO2: reduce direct (scope 1) and indirect (sco...   yes   \n",
       "396    SAF produced by using most advanced pathways c...   yes   \n",
       "468    213 suppliers committed to renewable electrici...   yes   \n",
       "469    In fiscal year 2021, the company and its suppl...   yes   \n",
       "584    Together, these new initiatives reduced total ...   yes   \n",
       "...                                                  ...   ...   \n",
       "11648  In 2009, the company became the first business...   yes   \n",
       "11669  targets in line with a 1.5 C trajectory, commi...   yes   \n",
       "11978  Republic of the Congo In March 2021, the compa...   yes   \n",
       "12165  the company revealed in the CDP2 A List, the h...   yes   \n",
       "12181  Based on this electrified vehicle strategy, th...   yes   \n",
       "\n",
       "       claim_probability                                      top_sentences  \\\n",
       "335             0.901820  [We're focused on carbon emission reduction of...   \n",
       "396             0.990116  [SAF produced using the most advanced pathways...   \n",
       "468             0.994511  [As of the report date, 213 of the company's m...   \n",
       "469             0.994993  [The projects will generate 1.2 gigawatts of r...   \n",
       "584             0.994826  [This change will effectively avoid 18 million...   \n",
       "...                  ...                                                ...   \n",
       "11648           0.992157  [Last year, Tesco committed to net-zero emissi...   \n",
       "11669           0.992899  [Building on the good progress we've made in c...   \n",
       "11978           0.994960  [TOTALENERGIES has signed Corporate Power Purc...   \n",
       "12165           0.650870  [According to an article published by Electrek...   \n",
       "12181           0.768779  [Toyota expects to sell 8 million electrified ...   \n",
       "\n",
       "                                             predictions  \\\n",
       "335    [contradiction, contradiction, contradiction, ...   \n",
       "396    [contradiction, entailment, contradiction, neu...   \n",
       "468    [entailment, contradiction, neutral, contradic...   \n",
       "469    [contradiction, contradiction, entailment, neu...   \n",
       "584    [contradiction, contradiction, contradiction, ...   \n",
       "...                                                  ...   \n",
       "11648  [contradiction, contradiction, contradiction, ...   \n",
       "11669  [contradiction, contradiction, neutral, contra...   \n",
       "11978  [neutral, contradiction, contradiction, neutra...   \n",
       "12165  [contradiction, contradiction, neutral, contra...   \n",
       "12181  [contradiction, contradiction, neutral, contra...   \n",
       "\n",
       "                                           probabilities      consensus  \n",
       "335    [0.9953846335411072, 0.5285486578941345, 0.643...  contradiction  \n",
       "396    [0.9935458302497864, 0.9918025135993958, 0.864...  contradiction  \n",
       "468    [0.8047620058059692, 0.9574432969093323, 0.998...  contradiction  \n",
       "469    [0.8817325830459595, 0.9783431887626648, 0.935...  contradiction  \n",
       "584    [0.9969239830970764, 0.5747354626655579, 0.996...  contradiction  \n",
       "...                                                  ...            ...  \n",
       "11648  [0.867167592048645, 0.9900526404380798, 0.7065...  contradiction  \n",
       "11669  [0.9856816530227661, 0.9069458842277527, 0.998...  contradiction  \n",
       "11978  [0.5680773854255676, 0.8769581317901611, 0.969...  contradiction  \n",
       "12165  [0.9970995187759399, 0.9604046940803528, 0.999...  contradiction  \n",
       "12181  [0.7136600613594055, 0.7362513542175293, 0.999...  contradiction  \n",
       "\n",
       "[71 rows x 15 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims[df_claims['consensus'] == 'contradiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bbecd45-400f-46c4-b41c-e1de4ae12d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"According to an article published by Electrek, a recent Greenpeace study ranked Toyota last among the world's top 10 automotive companies as far as its decarbonization efforts are concerned.\",\n",
       " \"Sure, Toyota is behind nine other companies, but it arguably shouldn't be on the list at all.\",\n",
       " \"This is the organization's highest rating, and one that acknowledges the standard Toyota Safety Sense 2.5+ system that includes:\",\n",
       " \"The world's top-selling carmaker Toyota has come joint last in a Greenpeace ranking of carbon emission efforts by auto firms, according to a list published Thursday during the COP26 climate summit.\",\n",
       " 'It may come as a surprise for some fans of Toyota and its fuel-efficient hybrid vehicles to learn that it ranks near Chevron and Exxon Mobil when it comes to its overall climate policy footprint.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims.iloc[12165]['top_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0302abd-a6b9-45e9-a2de-e41e19cd2700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toyota revealed in the CDP2 A List, the highest rank, in both the climate change and water security categories scored by CDP (2016 2017, 2019 2020).'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims.iloc[12165]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a0e80b1-5cb7-4e51-b776-baedf7cb500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_database_total = {}\n",
    "for firm in set(df_claims['company']):\n",
    "     # calculate the average sentiment score for this firm for symbolic actions\n",
    "    ver_score = len(df_claims[(df_claims['company']==firm)&(df_claims['consensus']!='entailment')])/len(df_claims[df_claims['company']==firm])\n",
    "    gw_database_total[firm] = ver_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b94ff7a-1214-424b-95cd-44cff06a2518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'google': 0.9876543209876543,\n",
       " 'hershey': 0.9802631578947368,\n",
       " 'veolia': 1.0,\n",
       " 'colgate': 0.9957627118644068,\n",
       " 'dupont': 1.0,\n",
       " 'shell': 0.9759036144578314,\n",
       " 'microsoft': 0.9877862595419847,\n",
       " 'exxon': 1.0,\n",
       " 'inditex': 1.0,\n",
       " 'coca-cola': 0.9698275862068966,\n",
       " 'dell': 0.9761904761904762,\n",
       " 'cemex': 0.9826839826839827,\n",
       " 'airbus': 0.9696969696969697,\n",
       " 'tesla': 1.0,\n",
       " 'boeing': 0.9930555555555556,\n",
       " 'general-mills': 0.9716981132075472,\n",
       " 'bayer': 0.9824561403508771,\n",
       " 'nike': 0.9961832061068703,\n",
       " 'renault': 0.976,\n",
       " 'walmart': 1.0,\n",
       " 'mitsubishi': 0.993006993006993,\n",
       " 'apple': 0.9437689969604863,\n",
       " 'volvo': 0.953125,\n",
       " 'edp': 1.0,\n",
       " 'honda': 0.9885057471264368,\n",
       " 'tesco': 1.0,\n",
       " 'adidas': 0.981651376146789,\n",
       " 'citi': 1.0,\n",
       " 'abb': 0.9897959183673469,\n",
       " 'blackrock': 1.0,\n",
       " 'hp': 0.9855072463768116,\n",
       " 'ibm': 0.9636363636363636,\n",
       " 'hyundai': 0.9868852459016394,\n",
       " 'linde': 0.9897959183673469,\n",
       " 'beiersdorf': 1.0,\n",
       " 'h&m': 0.963076923076923,\n",
       " 'mercedes': 0.988795518207283,\n",
       " 'p&g': 0.9924242424242424,\n",
       " 'pepsico': 0.9547738693467337,\n",
       " 'sonoco': 1.0,\n",
       " 'toyota': 0.9863013698630136,\n",
       " 'ford-motor': 0.9961240310077519,\n",
       " 'enel': 1.0,\n",
       " 'chevron': 0.9875,\n",
       " 'mcdonald': 0.9735099337748344,\n",
       " 'dhl': 1.0,\n",
       " 'intel': 0.9828571428571429,\n",
       " 'eversource': 1.0,\n",
       " 'mondelez': 0.9946380697050938,\n",
       " 'chipotle': 1.0,\n",
       " 'schneider-electric': 0.9546313799621928,\n",
       " 'nextera': 0.994535519125683,\n",
       " 'diageo': 0.9839228295819936,\n",
       " 'ralph-lauren': 0.9907834101382489,\n",
       " 'nestle': 0.9927710843373494,\n",
       " 'henkel': 0.9780876494023905,\n",
       " 'rio-tinto': 0.9757085020242915,\n",
       " 'danone': 0.9811320754716981,\n",
       " 'starbucks': 0.9782608695652174,\n",
       " 'totalenergies': 0.9907120743034056,\n",
       " 'volkswagen': 0.9875518672199171,\n",
       " 'komatsu': 1.0,\n",
       " 'bmw': 1.0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_database_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64e4fb81-7f37-46d2-82d3-0583997f5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_gw_total = pd.DataFrame(gw_database_total.items(),columns=['company', 'verification_score'])\n",
    "scaler = MinMaxScaler()\n",
    "df_gw_total['verification_score'] = scaler.fit_transform(df_gw_total[['verification_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7361ea0e-0e14-4c54-9d9c-9f66a44edcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gw_total.to_csv('verification_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f90110b3-f47f-45c3-8f13-5ad0e9248bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10867, 16)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims_lim = df_claims[df_claims['topics'].isin(lim_topics)]\n",
    "df_claims_lim.reset_index(inplace = True, drop = True)\n",
    "df_claims_lim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dfd44041-05cb-440c-909e-ac97030ea0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_database_total = {}\n",
    "for firm in set(df_claims_lim['company']):\n",
    "     # calculate the average sentiment score for this firm for symbolic actions\n",
    "    ver_score = len(df_claims_lim[(df_claims_lim['company']==firm)&(df_claims_lim['consensus']!='entailment')])/len(df_claims_lim[df_claims_lim['company']==firm])\n",
    "    gw_database_total[firm] = ver_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de66ae06-9c68-4056-9684-7baf2d56ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gw_lim = pd.DataFrame(gw_database_total.items(),columns=['company', 'verification_score_lim'])\n",
    "df_gw_lim['verification_score_lim'] = scaler.fit_transform(df_gw_lim[['verification_score_lim']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2fda231-503c-4467-8993-0aa649dcd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verification = pd.merge(df_gw_total, df_gw_lim)\n",
    "df_verification.to_csv('verification_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "23c7ef90-34ef-41df-8b0b-91b2d87211e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>verification_score_lim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google</td>\n",
       "      <td>0.753731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hershey</td>\n",
       "      <td>0.638686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veolia</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colgate</td>\n",
       "      <td>0.915385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dupont</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>0.616279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>totalenergies</td>\n",
       "      <td>0.838762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>0.744845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>komatsu</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>bmw</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          company  verification_score_lim\n",
       "0          google                0.753731\n",
       "1         hershey                0.638686\n",
       "2          veolia                1.000000\n",
       "3         colgate                0.915385\n",
       "4          dupont                1.000000\n",
       "..            ...                     ...\n",
       "58      starbucks                0.616279\n",
       "59  totalenergies                0.838762\n",
       "60     volkswagen                0.744845\n",
       "61        komatsu                1.000000\n",
       "62            bmw                1.000000\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gw_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "28a77146-4cf1-408c-bad0-d23c0841de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment': 0.3, 'neutral': 99.7, 'contradiction': 0.1}\n",
      "{'entailment': 0.1, 'neutral': 99.6, 'contradiction': 0.3}\n",
      "{'entailment': 0.1, 'neutral': 99.6, 'contradiction': 0.3}\n",
      "{'entailment': 0.2, 'neutral': 1.7, 'contradiction': 98.1}\n",
      "{'entailment': 0.2, 'neutral': 99.2, 'contradiction': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(nli_model)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(nli_model)\n",
    "\n",
    "# for sentence in top_5[0]:\n",
    "#     premise = row['sentence']\n",
    "#     hypothesis = df_article[df_article['company']==company]['sentence'].values[sentence['corpus_id']]\n",
    "#     tokens = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "#     output = model(tokens[\"input_ids\"].to(device))  # device = \"cuda:0\" or \"cpu\"\n",
    "#     prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "#     label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "#     prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "#     print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03776886-9e61-4b47-bcba-85e2677ef4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in case the input sentence is too long:\n",
    "# input_id_chunks = tokens_plus['input_ids'][0].split(510)\n",
    "# mask_chunks = tokens_plus['attention_mask'][0].split(510)\n",
    "\n",
    "# input_id_chunks = list(input_id_chunks)\n",
    "# mask_chunks = list(mask_chunks)\n",
    "\n",
    "\n",
    "# chunksize = 512\n",
    "# for i in range(len(input_id_chunks)):\n",
    "#     input_id_chunks[i] = torch.cat([\n",
    "#         torch.Tensor([101]), input_id_chunks[i], torch.Tensor([102])\n",
    "#     ])\n",
    "#     mask_chunks[i] = torch.cat([\n",
    "#         torch.Tensor([1]), mask_chunks[i], torch.Tensor([1])\n",
    "#     ])\n",
    "#     pad_len = chunksize - input_id_chunks[i].shape[0]\n",
    "    \n",
    "#     if pad_len > 0:\n",
    "#         input_id_chunks[i] = torch.cat([\n",
    "#             input_id_chunks[i], torch.Tensor([0]*pad_len)\n",
    "#         ])\n",
    "#         mask_id_chunks[i] = torch.cat([\n",
    "#             mask_id_chunks[i], torch.Tensor([0]*pad_len)\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a129ad-0984-401c-8645-472ea2d7a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = torch.stack(input_id_chunks)\n",
    "# attention_mask = torch.stack(mask_chunks)\n",
    "\n",
    "# input_dict = {\n",
    "#     'input_ids':input_ids.long(),\n",
    "#     'attention_mask': attention_mask.int()\n",
    "# }\n",
    "# input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6609a51-4e76-45ad-acb5-7abd6b34ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model(**input_dict)\n",
    "\n",
    "# probs = torch.nn.functional.softmax(outputs[0], dim = -1)\n",
    "# probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489ae33-d833-4a7e-9063-180735017ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = probs.mean(dim = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
