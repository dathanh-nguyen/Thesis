{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470c609e-f856-43ef-a53e-4188fb5e0dea",
   "metadata": {},
   "source": [
    "# Set-up and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9a74b-c33f-4797-bf10-ed52a96e1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import fitz\n",
    "from scipy.stats import pearsonr, ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9106575b-4b84-47b8-ac6b-eef20e13f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining paths for the data sources - refinitiv, nexisuni articles and reports\n",
    "path_ref = '..\\\\data\\\\refinitiv'\n",
    "path_nexis = '..\\\\data\\\\articles'\n",
    "path_reports = '..\\\\data\\\\reports'\n",
    "path_data = '..\\\\data_structured'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c39efe-091e-4a64-8392-1bd8e2d95ec9",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c77d8-4a7d-4ddb-b84c-a2d6d4ad932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = pd.read_excel(os.path.join(path_ref,'refinitiv.xlsx'), sheet_name = 1)\n",
    "df_sentiment = pd.read_csv('sentiment_scores.csv') #drop h&m and dhl\n",
    "df_similarity = pd.read_csv('similarity_scores.csv')\n",
    "df_verification = pd.read_csv('verification_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e26c7-643b-489a-be7b-f099db17e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the combined dataset, which holds all the sentences to get the news article sentence count for futher analysis\n",
    "df_comb = pd.read_pickle(os.path.join(path_data, 'comb.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6bb64-d0b6-4f8e-bc14-33e2e105716f",
   "metadata": {},
   "source": [
    "# Calculating the discrepancy index (Kruisheer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3237ddd-7c6e-4ebf-bc8e-22aaab4e8175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and scale the discrepancy index\n",
    "df_ref['average_practice'] = df_ref[['resource_use', 'emissions', 'environmental_innovation']].replace(0, np.nan).mean(axis = 1)\n",
    "df_ref['green_practice'] = StandardScaler().fit_transform(np.array(df_ref['average_practice']).reshape(-1,1))\n",
    "df_ref['green_communication'] = StandardScaler().fit_transform(np.array(df_ref['CSR_strategy']).reshape(-1,1))\n",
    "df_ref['discrepancy_index'] = df_ref['green_communication']-df_ref['green_practice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7aab2-7065-4b24-9c1a-f5d8f61630de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the discrepancy index to values between 0 and 1\n",
    "df_ref['discrepancy_index'] = MinMaxScaler().fit_transform(np.array(df_ref['discrepancy_index']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8b55c-609e-4f51-9825-384677704aa9",
   "metadata": {},
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1bea0-789c-4efd-9858-26c37ed99100",
   "metadata": {},
   "source": [
    "## Creating one unified dataframe to hold all scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2e089-7bbe-43cc-9cf2-6fff68df3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = df_ref[['company','discrepancy_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d20949-e1d4-4f60-958f-805f24323043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.merge(df_scores, df_similarity, how = 'left')\n",
    "df_scores = pd.merge(df_scores, df_sentiment)\n",
    "df_scores = pd.merge(df_scores, df_verification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737b223-bc3a-491b-8018-c57fdf1bb94e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating a table with the correlation scores per developed measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e89d3-c96d-4a41-abd0-77020beefac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlation_scores = pd.DataFrame(columns = ['discrepancy_measure', 'correlation', 'p-value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf9b98-8c15-46cb-9b1a-b21974ddb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the developed measures first with a min max scaler (optional)\n",
    "for column in df_scores.columns[2:]:\n",
    "    df_scores[column] = MinMaxScaler().fit_transform(np.array(df_scores[column]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a6d18-a34c-4406-8aed-49ab0d4c66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the table\n",
    "x = df_scores['discrepancy_index']\n",
    "for column in df_scores.columns[2:]:\n",
    "    y = df_scores[column]\n",
    "    correlation, p_value = pearsonr(x,y)\n",
    "    temp_df = pd.DataFrame(\n",
    "        {\n",
    "            'discrepancy_measure':[column], \n",
    "            'correlation':[correlation],\n",
    "            'p-value':[p_value]\n",
    "        }\n",
    "    )\n",
    "    df_correlation_scores = pd.concat([df_correlation_scores, temp_df], ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b581dde-93b0-4ddc-b6d8-33cfbe421f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlation_scores\n",
    "# correlation scores when leaving out beiersdorf, hershey and henkel, which are companies for which I also included articles from 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a070b99-5e4a-4b24-afc3-f5e74686544f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Further exploration of the correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a279ca94-2790-4f62-b7dc-0335a66e03b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating additional variables for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc2a02-017c-4302-9da4-14be0f479a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting a list of low article companies (all the ones for which nexisuni search was necessary) for additional analysis later\n",
    "low_article_companies = sample = os.listdir(path_nexis)\n",
    "low_article_companies = [word.split('.')[0] for word in low_article_companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bd58d-c0e6-4ba2-a000-c99d508ee96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column, which has the value yes if the company belongs to one of the low article companies\n",
    "df_scores['low_coverage'] = df_scores['company'].apply(lambda x: 'Yes' if x in low_article_companies else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc6c32-10b9-401c-b94b-b99e7161d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the article sentence counts per company for a visualization later\n",
    "df_counts = df_comb[df_comb['doc_type'] == 'news'].groupby(['company'])['sentence'].count() \n",
    "df_counts = pd.DataFrame(df_counts)\n",
    "df_counts.reset_index(inplace = True)\n",
    "df_counts.rename(columns = {'sentence':'sentence_count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5801a1-f619-451a-8063-89bed23614f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rep_sentences =  df_comb[df_comb['doc_type'] == 'report'].groupby(['company'])['sentence'].count()\n",
    "# df_rep_sentences = pd.DataFrame(df_rep_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403f476-da43-4b6d-8595-550a738a8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.merge(df_scores, df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912e346-3728-429f-a6a2-d57706db13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for the report page count\n",
    "df = pd.DataFrame(columns = ['company', 'report_page_count'])\n",
    "\n",
    "for filename in os.listdir(path_reports):\n",
    "    if filename.endswith('.pdf'):\n",
    "        file_path = os.path.join(path_reports, filename)\n",
    "        doc = fitz.open(file_path)\n",
    "        page_count = doc.page_count\n",
    "        doc.close()\n",
    "        company_name = filename[:-4]  # remove the \".pdf\" extension\n",
    "        df_temp = pd.DataFrame({'company': [company_name], 'report_page_count': [page_count]})\n",
    "        df = pd.concat([df, df_temp], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157744d-45bc-491a-8db0-1f6950f89246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.merge(df_scores, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16deed-183f-4c28-b275-d75a3fcafb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scatterplot showcasing the general correlation and linear relationship between our indices\n",
    "\n",
    "df_scores.reset_index(drop = True, inplace = True)\n",
    "x = df_scores['discrepancy_index']\n",
    "y = df_scores['clim_sentiment_overall']\n",
    "companies = df_scores['company']\n",
    "\n",
    "# Fit a linear regression line\n",
    "coefficients = np.polyfit(x, y, 1)\n",
    "line = np.poly1d(coefficients)\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# Add the linear regression line\n",
    "plt.plot(x, line(x), color='red', label = 'Our Correlation')\n",
    "\n",
    "# Add labels for each point\n",
    "for i, company in enumerate(companies):\n",
    "    plt.text(x[i], y[i], company, ha='center', va='bottom')\n",
    "    \n",
    "plt.xlabel('Discrepancy Index')\n",
    "plt.ylabel('Sentiment Discrepancy (Firm-level)')\n",
    "\n",
    "#plt.savefig('correlationscatterplot.png', dpi = 200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c441d0-8a18-46c7-90d0-68859955235f",
   "metadata": {},
   "source": [
    "## Effect of News Coverage and Report Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d3124-0d10-4dd8-8eb2-bf72cfdd8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the same scatterplot, but also including the line for perfect correlation and indicating whether companies belong to the low article group\n",
    "\n",
    "x = df_scores['discrepancy_index']\n",
    "y = df_scores['clim_sentiment_overall']\n",
    "low_article_companies = df_scores['low_coverage']\n",
    "\n",
    "# Fit a linear regression line\n",
    "coefficients = np.polyfit(x, y, 1)\n",
    "line = np.poly1d(coefficients)\n",
    "\n",
    "# Scatter plot with color coding by coverage\n",
    "plt.figure(figsize=(16, 10))\n",
    "for company in set(low_article_companies):\n",
    "    plt.scatter(x[low_article_companies == company], y[low_article_companies == company], label=company)\n",
    "\n",
    "# Add the linear regression line\n",
    "plt.plot(x, line(x), color='red', label = 'Our Correlation')\n",
    "\n",
    "# Add the perfect correlation line\n",
    "plt.plot(x, x, color='green', linestyle='dotted', solid_capstyle='butt', label='Perfect Correlation')\n",
    "\n",
    "plt.xlabel('Discrepancy Index')\n",
    "plt.ylabel('Sentiment Discrepancy (Firm-level)')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Low Article Companies')\n",
    "\n",
    "#plt.savefig('correlationscatterplot-low articles.png', dpi=500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e155e9d-34aa-4901-8e9d-2cb6c550f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the effect of the amount of news coverage on our correlation\n",
    "\n",
    "x = df_scores['discrepancy_index']\n",
    "y = df_scores['clim_sentiment_overall']\n",
    "\n",
    "# Fit a linear regression line\n",
    "coefficients = np.polyfit(x, y, 1)\n",
    "line = np.poly1d(coefficients)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "plt.scatter(x,y,c = df_scores['sentence_count'], cmap = 'viridis')\n",
    "plt.colorbar(label='News Article Sentence Count')\n",
    "\n",
    "\n",
    "# Add the linear regression line\n",
    "plt.plot(x, line(x), color='red', label = 'Our Correlation')\n",
    "\n",
    "plt.plot(x, x, color='green', linestyle='dotted', solid_capstyle='butt', label='Perfect Correlation')\n",
    "\n",
    "plt.xlabel('Discrepancy Index')\n",
    "plt.ylabel('Sentiment Discrepancy (Firm-level)')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Legend')\n",
    "\n",
    "#plt.savefig('corr_scatter_news_coverage.png', dpi=500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac76b2-24f9-41bd-a2ec-8b28348fe67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the effect of report page count\n",
    "x = df_scores['discrepancy_index']\n",
    "y = df_scores['clim_sentiment_overall']\n",
    "\n",
    "# Fit a linear regression line\n",
    "coefficients = np.polyfit(x, y, 1)\n",
    "line = np.poly1d(coefficients)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.scatter(x,y,c = df_scores['report_page_count'], cmap = 'viridis')\n",
    "plt.colorbar(label='Report Page Count')\n",
    "\n",
    "# Add the linear regression line\n",
    "plt.plot(x, line(x), color='red', label = 'Our Correlation')\n",
    "\n",
    "plt.plot(x, x, color='green', linestyle='dotted', solid_capstyle='butt', label='Perfect Correlation')\n",
    "\n",
    "plt.xlabel('Discrepancy Index')\n",
    "plt.ylabel('Sentiment Discrepancy (Firm-level)')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Legend')\n",
    "\n",
    "#plt.savefig('corr_scatter_page_count.png', dpi=500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f35150-329d-43a9-a29f-b9b46e2d4c89",
   "metadata": {},
   "source": [
    "## Effect of Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c542b-be41-46c3-aa3d-d2cf8ef69cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptives = df_ref[['company','country','industry']]\n",
    "df_scores = pd.merge(df_scores, df_descriptives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36e654-2fd8-4177-978c-5ee0033317cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df_scores['discrepancy_index']\n",
    "y = df_scores['clim_sentiment_overall']\n",
    "industries = df_scores['industry']\n",
    "\n",
    "# Fit a linear regression line\n",
    "coefficients = np.polyfit(x, y, 1)\n",
    "line = np.poly1d(coefficients)\n",
    "\n",
    "# Scatter plot with color coding by industry\n",
    "plt.figure(figsize=(16, 10))\n",
    "for industry in set(industries):\n",
    "    plt.scatter(x[industries == industry], y[industries == industry], label=industry)\n",
    "\n",
    "# Add the linear regression line\n",
    "plt.plot(x, line(x), color='red', label = 'Our Correlation')\n",
    "\n",
    "plt.plot(x, x, color='green', linestyle='dotted', solid_capstyle='butt', label='Perfect Correlation')\n",
    "\n",
    "plt.xlabel('Discrepancy Index')\n",
    "plt.ylabel('Sentiment Discrepancy (Firm-level)')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Economic Sector (Refinitiv)')\n",
    "\n",
    "#plt.savefig('corr_scatter_sector.png', dpi=500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95819797-2af9-4806-be2d-979862a7a4cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Generating Result Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2683e566-26e5-4d00-8bd2-256b61634943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finbert_results = df_correlation_scores.iloc[[8,9,12,13]]\n",
    "df_finbert_results\n",
    "print(df_finbert_results.to_latex(index = False, caption = 'Comparison of the Performance of a Domain-Trained (ClimateBERT) and Non-Domain Trained sentiment model (FinBERT)', label = 'tab:sentimentcomparison', header = True, position = 'h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24cb79-ff55-41a5-8018-aa6a6b6d15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_results = []\n",
    "for measure in df_correlation_scores['discrepancy_measure']:\n",
    "    if ('_lim' in measure)|('waverage' in measure)|('wsum' in measure):\n",
    "        filter_results.append(False)\n",
    "    else:\n",
    "        filter_results.append(True)\n",
    "df_results = df_correlation_scores[filter_results]\n",
    "df_results.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be86a6-ae12-4df6-b770-4f87ec2063fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.iloc[[0,1,4,5,6,7]]\n",
    "df_results.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17794d7-30e6-4fc7-b80f-4b5ba4e135c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['discrepancy_measure'] = ['Dissimilarity_firm', 'Dissimilarity_firm-topic', 'Sentiment_firm', 'Sentiment_firm-topic', 'Verification_firm', 'Verification_firm-topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df203c-c80b-4953-8a95-468764e62c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results.to_latex(index = False, caption = 'Correlation Analysis Results for the Developed Greenwashing Scores on Document and Cluster Level', label = 'tab:correlationresults', header = True, position = 'h'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5024a7-266b-44fe-96c6-6060ee6e0c5d",
   "metadata": {},
   "source": [
    "# Sentiment Score Distributions and Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f86e5-3cce-496b-a607-43d674fa16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment['clim_sentiment_overall'].plot.box()\n",
    "# plt.savefig('boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0369e03-d0f0-4472-9b58-78ffdab3f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "df_sentiment['clim_sentiment_overall'].plot.hist(bins = 25)\n",
    "\n",
    "# Set plot labels\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Clim Sentiment Overall Scores')\n",
    "\n",
    "plt.savefig('sentimentdistribution.png')\n",
    "# Show the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f193bc1-d016-467b-ab41-aeb78670c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment['clim_sentiment_overall'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d04108-2826-45f0-a357-a0444c00c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_2 = df_sentiment[df_sentiment['clim_sentiment_overall']>0]\n",
    "df_results_2 = df_results_2[['company','clim_sentiment_overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5960eba-0f63-41a0-b504-2b167d2f641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_results_2.to_latex(index = False, caption = 'Companies With a Sentiment Discrepancy Above 0', label = 'tab:greenwashcompanies', header = True, position = 'h'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
