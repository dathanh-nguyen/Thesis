{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614c994f-ad2b-4e61-8b35-fc5314986f0c",
   "metadata": {},
   "source": [
    "## Set-up and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de441155-9dd7-45d9-91fc-e5f73188d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util, models\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "import os\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "# from octis.evaluation_metrics.diversity_metrics import TopicDiversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20c7e0-e245-4908-afee-e72805d49bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '..\\\\data_structured'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21feeb4-f1f5-4e60-865d-594755604e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_reports = '..\\\\data\\\\reports'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2fd46-f94e-4fcd-80bf-a1d3bf006c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = os.listdir(path_reports)\n",
    "# converting to panda series because I find it easier to manipulate\n",
    "company_list = [word.split('.')[0] for word in sample]\n",
    "company_list = pd.Series(company_list)\n",
    "publisher_list = company_list.str.replace('-',' ') #so make it two words\n",
    "publisher_list = publisher_list.str.replace('ford motor', 'ford')\n",
    "publisher_list = publisher_list.str.replace('p&g', 'procter')\n",
    "publisher_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ae1a4-862b-4796-9272-82bb8016e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = publisher_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99072dfc-cdf5-4ea0-8d6f-f992fb73a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list.append('p&g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2edff-975e-455d-abc8-94464d95bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692530d8-9d18-4b3a-bf8e-5130b54b7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.read_csv(os.path.join(path_data,'report_sentences.csv'))\n",
    "df_pdf = pd.read_csv(os.path.join(path_data,'article_sentences_pdf.csv'))\n",
    "df_gnews = pd.read_csv(os.path.join(path_data,'article_sentences_gnews.csv'))\n",
    "df_article = pd.concat([df_pdf,df_gnews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda0dba-3d58-4022-8a28-96474f6d26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96319692-6de7-4da7-b8f7-9f0e971f6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d091b4-3ac4-4c63-abbc-ec575afb358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article.drop_duplicates(subset = ['sentence'], inplace = True)\n",
    "df_article.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2911fce1-3354-4143-a796-359d84444ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## part of the extra step below\n",
    "#df_combined = pd.concat([df_article, df_report])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c7b79-0f2c-42e0-b143-34edec401a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_embedder = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6497c87-a151-4b84-8695-4e33ee470344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep = df_report.copy()\n",
    "df_art = df_article.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56335fda-1d8b-4a04-8850-b3bf5bb46f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating embeddings (useful for testing out later):\n",
    "def gen_embeddings(df,model):\n",
    "    sentences = df['sentence'].tolist()\n",
    "    return model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500fb49-18ad-42cc-9814-d64b08b5f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# creating embeddings for the report sentences and storing them in a new column\n",
    "df_rep['embeddings'] = list(gen_embeddings(df_rep,sent_embedder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93020e41-80e9-43a9-9d41-1b388da293c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_art['embeddings'] = list(gen_embeddings(df_art, sent_embedder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace169f-4bbd-444d-ad55-abe973a3c23a",
   "metadata": {},
   "source": [
    "- now we test out BERTopic \n",
    "- gonna try it with the overlapped sentence embeddings, non-overlapped?, and climateBERT + potentially FINbert\n",
    "- then we try to manipulate the different parameters - tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032ee3f-81f7-4edf-9b38-e4c20c0e0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep.to_pickle(os.path.join(path_data,'rep.pkl'))\n",
    "df_art.to_pickle(os.path.join(path_data,'art.pkl'))\n",
    "# df_art = pd.read_pickle(os.path.join(path_data,'art.pkl'))\n",
    "# df_rep = pd.read_pickle(os.path.join(path_data,'rep.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923dca8d-1d86-4597-adac-f5e8bafaec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the two datasets in preparation for the clustering\n",
    "df_comb = pd.concat([df_art, df_rep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d17519-c150-43e7-92ca-4720535758f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea008cdf-1f8f-4e37-8371-269067cf24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb['char_length'] = df_comb['sentence'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d46f357-e79b-471c-9aed-6754136064dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = df_comb[(df_comb['char_length'] > 20)]\n",
    "df_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770787c-fe40-4924-9c74-b4076669bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.drop_duplicates(subset = ['sentence'], inplace = True)\n",
    "df_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74046aa9-f291-4e3d-b578-7b43bfb7f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Escaping the names_list for safe inclusion in the regular expression pattern\n",
    "escaped_names = [re.escape(name) for name in names_list]\n",
    "\n",
    "# Constructing the modified regular expression pattern\n",
    "pattern = r\"\\b(?:{})(?:'s)?\\b\".format(\"|\".join(escaped_names))\n",
    "\n",
    "# Replace company names with 'company' using the regular expression pattern\n",
    "df_comb['anon_sentence'] = df_comb['sentence'].str.replace(pattern, 'the company', case=False, regex=True)\n",
    "\n",
    "# Print the modified dataframe\n",
    "df_comb['anon_sentence'].values[200:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83fb27-d222-4103-918d-e65122a51d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcac37-e2b2-4a48-90ca-dce38582619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sentence embeddings and doc types from the dataframe\n",
    "# embeddings = np.array(df_comb[\"embeddings\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8df1c5-a0ad-4cf0-9ff8-3ebe6678da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new embeddings based on the 'anonymized' sentences (without company names) - let's see how BERTopic handles it now\n",
    "df_comb['anon_embeddings'] = list(gen_embeddings(df_comb, sent_embedder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffb6bcb-1277-4f87-a510-53acff14b84a",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc0008-d22c-4ffa-a1e5-a04b554fe23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the word count\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_comb['word count'], bins=30, color='skyblue')\n",
    "plt.title('Word Count Distribution')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('word_count_hist.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeff762-f793-4169-89ec-c89363b6d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group the data by company, doc_type, and count the number of sentences\n",
    "# df_by_company_doc_type = df_comb.groupby(['company', 'doc_type'])['sentence'].count().reset_index()\n",
    "\n",
    "# # Pivot the dataframe to create separate columns for each doc_type\n",
    "# df_pivot = df_by_company_doc_type.pivot(index='company', columns='doc_type', values='sentence')\n",
    "\n",
    "# Create a line chart of the number of sentences by company and doc_type\n",
    "plt.figure(figsize=(20,5));\n",
    "df_pivot.plot.line(color=['red', 'blue'], marker='o', markersize=5)\n",
    "plt.title('Number of Sentences by Company and Doc Type')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Number of Sentences')\n",
    "plt.legend(title='Doc Type')\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('sentences_by_company_and_doc_type.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac6109-8785-44b1-a148-2416c2d4605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap2d = UMAP(n_components = 2, init = 'random', random_state = 0)\n",
    "# umap3d = UMAP(n_components = 3, init = 'random', random_state = 0)\n",
    "\n",
    "proj_2d = umap2d.fit_transform(embeddings)\n",
    "# proj_3d = umap3d.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdea811-db05-40b2-8c00-3d2081a7b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2d = px.scatter(\n",
    "    proj_2d, x = 0, y = 1, \n",
    "    color = df_comb.doc_type, labels = {'color': 'doc_type'},\n",
    "    width = 800, height = 500\n",
    ")\n",
    "# fig3d = px.scatter_3d(\n",
    "#     proj_3d, x = 0, y = 1, z = 2,\n",
    "#     color = df_comb.doc_type, labels = {'color': 'doc_type'}\n",
    "# )\n",
    "\n",
    "fig2d.show()\n",
    "# fig3d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3bdf6-6b13-4121-a42f-e8441e4eb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne2d = TSNE(n_components = 2, random_state = 0)\n",
    "tsne3d = TSNE(n_components = 3, random_state = 0)\n",
    "\n",
    "proj_2d_tsne = tsne2d.fit_transform(embeddings)\n",
    "proj_3d_tsne = tsne3d.fit_transform(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847810f8-0374-46da-89fd-f12e58234d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2d_tsne = px.scatter(\n",
    "    proj_2d_tsne, x = 0, y = 1, \n",
    "    color = df_comb.doc_type, labels = {'color': 'doc_type'}\n",
    ")\n",
    "\n",
    "# fig3d_tsne = px.scatter_3d(\n",
    "#     proj_3d_tsne, x = 0, y = 1, z = 2,\n",
    "#     color = df_comb.doc_type, labels = {'color': 'doc_type'}\n",
    "# )\n",
    "\n",
    "fig2d_tsne.show()\n",
    "# fig3d_tsne.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355bd75d-d026-4988-820c-5b9660e34db7",
   "metadata": {},
   "source": [
    "Based on the above visualizations, we can see that unlike Boelders, we do not require to overlap the sentence embeddings over each other, as there are not large semantic differences between the news articles and the reports. The jargon and language seems to be mostly the same, as such we can just use the original embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e423ea-1959-488e-9a75-afa3cd5bcc74",
   "metadata": {},
   "source": [
    "## BERTopic Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8813f8c-a8e0-4520-9028-ae3686624a86",
   "metadata": {},
   "source": [
    "### Testing UMAP parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcab7cc-d14f-41b3-8b5e-e28c63d46e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = df_comb['doc_type']\n",
    "c_map = {\n",
    "    'news': '#FAFF00',\n",
    "    'report': '#1C17FF'\n",
    "}\n",
    "colors = [c_map[x] for x in colors]\n",
    "len(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c6704-f403-41cb-b27f-64b873b66afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(21, 10))\n",
    "nns = [5,10, 15, 30, 50, 100]\n",
    "#2, 3, 4\n",
    "i, j = 0, 0\n",
    "for n_neighbors in tqdm(nns):\n",
    "    fit = UMAP(n_neighbors=n_neighbors, random_state = 0)\n",
    "    u = fit.fit_transform(embeddings)\n",
    "    sns.scatterplot(x=u[:,0], y=u[:,1], ax=ax[j, i])\n",
    "    ax[j, i].set_title(f'n={n_neighbors}')\n",
    "    if i < 2: i += 1\n",
    "    else: i = 0; j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21e0ec-8ce5-4302-ae1e-6cdbb4f228d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('full_figure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d32230-51a1-4f6b-85bb-ad7bfba805df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 14))\n",
    "nns = [3,4]\n",
    "#2, 3, 4\n",
    "i, j = 0, 0\n",
    "for n_neighbors in tqdm(nns):\n",
    "    fit = UMAP(n_neighbors=n_neighbors, random_state = 0)\n",
    "    u = fit.fit_transform(embeddings)\n",
    "    sns.scatterplot(x=u[:,0], y=u[:,1], c=colors, ax=ax[i])\n",
    "    ax[i].set_title(f'n={n_neighbors}')\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60662f12-090c-4ddb-81e5-58293876f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = UMAP(n_neighbors=10, n_components=3, min_dist=0.0, init = 'random', metric = 'cosine', random_state = 0)\n",
    "u = fit.fit_transform(embeddings)\n",
    "\n",
    "# the lowest min distance finally creates some separation - what does increasing it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b52986-e5ce-4c91-850a-734c48564651",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    x=u[:,0], y=u[:,1], z=u[:,2],\n",
    "    color=df_comb.doc_type,\n",
    "    labels = {'color': 'doc_type'}\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf2f5c-277f-4777-9c2c-e575c68b3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D representation\n",
    "fit2d = UMAP(n_neighbors=15, n_components=2, min_dist=0.0, init = 'random', metric = 'cosine', random_state = 0)\n",
    "u2d = fit2d.fit_transform(embeddings)\n",
    "\n",
    "fig2d = px.scatter(\n",
    "    x=u2d[:,0], y=u2d[:,1],\n",
    "    color=df_comb.doc_type,\n",
    "    labels = {'color': 'doc_type'},\n",
    "    width = 800, height = 500\n",
    ")\n",
    "\n",
    "fig2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351ecae-d341-4116-833a-0a0b8b194ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D representation\n",
    "fit2d = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, init = 'random', metric = 'cosine', random_state = 0)\n",
    "u2d = fit2d.fit_transform(embeddings)\n",
    "\n",
    "fig2d = px.scatter(\n",
    "    x=u2d[:,0], y=u2d[:,1],\n",
    "    color=df_comb.doc_type,\n",
    "    labels = {'color': 'doc_type'},\n",
    "    width = 800, height = 500\n",
    ")\n",
    "\n",
    "fig2d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c7cc98-2b9e-433d-9de1-17ee5af6d3cf",
   "metadata": {},
   "source": [
    "### Clustering with HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b8bb1-1339-476a-889f-ba735a606e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = HDBSCAN(min_cluster_size = 400)\n",
    "clusterer.fit(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9624a70-9da2-41c5-8ea5-5e0e14b027b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.condensed_tree_.plot(select_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f53f79-c800-49f8-b96c-0cbb6f263352",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = HDBSCAN(min_cluster_size = 400, min_samples = 50, metric = 'euclidean')\n",
    "clusterer.fit(u)\n",
    "clusterer.condensed_tree_.plot(select_clusters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf67447-517a-45ea-8d2f-711b30484235",
   "metadata": {},
   "source": [
    "## Running BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a687351-7243-4fe1-b9b3-b7317a3e61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df_comb['anon_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16c092-c584-4202-b8ba-ca266dae939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(df_comb[\"anon_embeddings\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f622186-8fd8-4537-ace5-8013d9bb516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0,init = 'random', metric = 'cosine', random_state = 0).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02a5b6-5f5c-444e-b983-702ce379d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting stopwords\n",
    "stopwords = list(stopwords.words('english')) + ['company','coca','cola'] + names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa25b91-b7da-424d-b01d-97d97535472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customizing parts of the BERTopic pipeline\n",
    "# vectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words = stopwords)\n",
    "\n",
    "# umap\n",
    "umap_model = UMAP(n_neighbors=10, n_components=5, min_dist=0.0, init = 'random', metric = 'cosine', random_state = 0)\n",
    "\n",
    "# hdbscan\n",
    "hdbscan_model = HDBSCAN(min_cluster_size = 200, metric='euclidean', prediction_data=True)\n",
    "# 200 has decent results\n",
    "# min_samples\n",
    "# diversity topic words\n",
    "representation_model = MaximalMarginalRelevance(diversity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f66707-5dfb-4224-85ac-f5c9e1815d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(\n",
    "    embedding_model = sent_embedder,\n",
    "    vectorizer_model = vectorizer_model,\n",
    "    umap_model = umap_model,\n",
    "    hdbscan_model = hdbscan_model,\n",
    "    language=\"english\", \n",
    "    representation_model = representation_model, #diversify topic words\n",
    "    calculate_probabilities=True, \n",
    "    verbose=True, \n",
    "    #nr_topics = 'auto'\n",
    "    # min_topic_size = 50, \n",
    "    # n_gram_range = (1,2)\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc30793-3f1d-4d6f-b023-bd6923195b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_highest_probability(array):\n",
    "    max_index = np.argmax(array)\n",
    "    max_prob = array[max_index]\n",
    "    return max_prob, max_index\n",
    "find_highest_probability(probs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da5ca2-d32c-463a-899e-fd0313301b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894843b6-202f-4eae-9c1d-7d80c6c05754",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc016d63-9a02-4d86-bf7d-e3a6e8adbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(top_n_topics=10, n_words = 10, height = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fd09c-89c4-4fef-ae01-8841b8e4f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings, \n",
    "                                hide_document_hover=True, hide_annotations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90449b79-05b6-44b3-ae2f-6fb189807cce",
   "metadata": {},
   "source": [
    "## Topic Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d8786-5201-4944-90ba-a140cca6796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe892a-cac4-4bf3-8e7f-f299f9963c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09d4aa-a0ff-462d-99cb-dde39d500c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_representative_docs(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f081f-4fd8-4494-849e-16c5e1dab71f",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    ">>> print(tree)\n",
    "\n",
    "# saf stands for sustainabile aviation fuel - together with topic 13 talks about the opportunities for sustainable fuel to reduce mostly emissions - can call it something like sustainable transportation? with dhl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3188162-c906-4b18-94c4-4a86e890f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchical_documents(docs, hierarchical_topics, reduced_embeddings=reduced_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7519f6f-a5eb-4a61-a381-b2b7c9e93c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reduction of topics - we will merge them manually based ont he above visualizations\n",
    "topics_to_merge = [\n",
    "    [20,33,3,14], #plastic packaging and recycling\n",
    "    [12,4,7,51,60,24,59,30], #recycling, more focus on circular economy other than just plastic - include 59? (printing), 32 (sustainable materials/sourcing?)\n",
    "    [58,56,35,21,13], #regenerative agriculture/sustainable agriculture\n",
    "    [8,23,27], #water, biodiversity, deforestation - could be called nature preservation\n",
    "    [43,16], #sustainability (tech) innovation\n",
    "    #[5,28], #climate change\n",
    "    [1,6,17,22], #sustainable leadership/governance?\n",
    "    [29,11,25,19], #sustainable fuels/transportations\n",
    "    [39,40,2,15,53,61,45,47,30,32], #decarbonisation,emission reductions - include 47? (air pollution), 30? (chemical substances)\n",
    "    [18,34,46]#EV's\n",
    "] \n",
    "topic_model.merge_topics(docs, topics_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a49939-df08-4eff-9917-586663c2a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f6466-28e1-410e-a508-4b1d43742281",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_representative_docs(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c5474-3acc-493d-b185-c69d711925db",
   "metadata": {},
   "source": [
    "## Outlier Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f6bd4-b06c-4f29-9d46-03073c219817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb = pd.read_pickle(os.path.join(path_data,'comb.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4551ae6f-026a-4b14-abab-f425a5af6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save('merged_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe7235-0a9f-48e4-a709-23325af71973",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load('merged_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904cdcd-bbbb-4870-9b13-4620f99020c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topic_model.topics_\n",
    "probs = topic_model.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c90f9-0eed-4689-bd12-88063a379f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#new_topics_probs = topic_model.reduce_outliers(docs, topics, probabilities=probs, strategy=\"probabilities\")\n",
    "#new_topics_tfidf = topic_model.reduce_outliers(docs, topics, strategy=\"c-tf-idf\", threshold = 0.1)\n",
    "new_topics_dist = topic_model.reduce_outliers(docs, topics, strategy = \"distributions\", threshold = 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7699c61-0acf-4549-8683-5940e1b7f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics_embed = topic_model.reduce_outliers(docs, topics, strategy = \"embeddings\", threshold = 0.23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4994b2-d008-4638-8595-a7d59661d6bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### HDBSCAN Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83460554-3680-464b-8706-8145921cda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.update_topics(docs, topics=new_topics_probs, vectorizer_model = vectorizer_model, representation_model = representation_model)\n",
    "topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings, \n",
    "                                hide_document_hover=True, hide_annotations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aea070-332e-43b2-adf9-8c73a2793985",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f37f7-2bff-4bcb-8bd7-fffd1cf7ee95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### C-TF-IDF similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb594d73-ce64-44bc-be25-a1a56f74dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.update_topics(docs, topics=new_topics_tfidf, vectorizer_model = vectorizer_model, representation_model = representation_model)\n",
    "topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings, \n",
    "                                hide_document_hover=True, hide_annotations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3d9e4-71ff-4880-bbd9-3af1e5844355",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32d04f-ad46-4a2b-9949-89da9a627913",
   "metadata": {},
   "source": [
    "### Using topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cebdc0-be9e-43e1-87ed-c53640f53556",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.update_topics(docs, topics=new_topics_dist, vectorizer_model = vectorizer_model, representation_model = representation_model) #  representation_model = representation_model\n",
    "topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings, \n",
    "                                hide_document_hover=True, hide_annotations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf5fbd-a500-4eb7-9fe4-db2765c751cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906dc33f-e165-4e19-83f6-37f5995dc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.set_topic_labels({0: \"ESG governance\", 1: \"Renewable Energy\", 2: \"Waste Management\", 3: \"Emission Reduction\", 4: \"Plastics Recyling\", 5: \"Nature Preservation\", 6:\"Sustainable Transportation\", 7: \"Climate Change\", 8: \"Sustainable Agriculture\", 9: \"Stocks\",\n",
    "#                              10: \"Electrical Vehicles\", 12:\"Sustainable Innovation\", 14:\"No Comment\", })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbf7cd-5973-4f2d-b9f5-97e90c6e5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topic_model.topics_\n",
    "df_comb['topics'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67418075-d252-4b46-83bd-4a544f5b5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.to_pickle(os.path.join(path_data,'comb.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23d6dd-17a6-4fd5-a86f-ff258a1b791e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_comb['topics'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff80f74-f78a-488c-b34d-042953613b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(df_comb[df_comb['topics'] == 27]['anon_sentence'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b46b58-7080-4678-82b4-e76babdaafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second merging after taking a look at the reports\n",
    "topics_to_merge = [\n",
    "    [26,10], #green cars/car production\n",
    "    [14,3], #pollution lawsuits included\n",
    "    \n",
    "] \n",
    "topic_model.merge_topics(docs, topics_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e496d82-98ba-484a-8d14-e81f5a166d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a844ff-ac5d-4487-b9a1-9b7b4ba8d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "def create_wordcloud(model, topic, save_path = None):\n",
    "    text = {word: value for word, value in model.get_topic(topic)}\n",
    "    wc = WordCloud(background_color=\"white\", max_words=1000)\n",
    "    wc.generate_from_frequencies(text)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f\"wordcloud_{topic}.png\"))\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02442c1-c739-4ccd-bde9-168fff9b29a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sust_topics = [0,1,2,3,4,5,6,7,8,10,11,20,25]\n",
    "save_path = \".\\\\visualizations\"\n",
    "\n",
    "for i in sust_topics:\n",
    "    create_wordcloud(topic_model, i, save_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353eb75b-4821-40e1-90db-cea77c65a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = {word: value for word, value in topic_model.get_topic(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198dec6a-d507-4813-8c42-0b78f00932b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d18c6-974c-4062-9e7c-535f4a1003e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using Sentence and Topic Embedding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246b87c-b843-408b-8ebc-9ac1c4823cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.update_topics(docs, topics=new_topics_embed, vectorizer_model = vectorizer_model,representation_model = representation_model)\n",
    "topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings, \n",
    "                                hide_document_hover=False, hide_annotations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6222048f-db22-422a-8a93-9f9b5f22597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25071a-e87c-4e57-98d5-19f9dc14e9d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Fitting different embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54539d6b-b58f-4d83-b09b-ad27db377968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpnet - don't have high hopes for this one\n",
    "model_mpnet = SentenceTransformer('all-mpnet-base-v2')\n",
    "mpnet_embeddings = gen_embeddings(len(df_comb), model_mpnet) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff67d0-bd6d-45e0-9089-c6e2b862e6fa",
   "metadata": {},
   "source": [
    "np.save('mpnet_embeddings', mpnet_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c2f07-696c-4174-8bfd-3fac2c2d0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clim_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b182c-1cef-4074-8159-96735d12d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_clim = topic_model.fit_transform(docs, clim_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb6e05-5ada-4225-ae28-dcd219476edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8303f-0ed7-4e43-a228-dc201a0f0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_clim_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0,init = 'random', metric = 'cosine', random_state = 0).fit_transform(clim_embeddings)\n",
    "topic_model.visualize_documents(docs, reduced_embeddings=reduced_clim_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e98cf-ff19-41eb-8d4e-b03842db85f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706ba02-c193-423d-a689-a2ae6af099ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_term_matrix = topic_model.c_tf_idf_\n",
    "words = topic_model.vectorizer_model.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cfbcb-9ece-4702-a963-41e57fa62968",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013fc42-10e8-4790-b36b-bee92d38bc97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculating Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9496b6-0129-43fc-81f6-54bf1103e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.DataFrame({\"Document\": filtered_text,\n",
    "                          \"ID\": range(len(filtered_text)),\n",
    "                          \"Topic\": topics[0]})\n",
    "documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n",
    "cleaned_docs = topic_model._preprocess_text(documents_per_topic.Document.values)\n",
    "\n",
    "# Extract vectorizer and analyzer from BERTopic\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "words = vectorizer.get_feature_names_out()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "               for topic in range(len(set(topics[0]))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb20630-b5d6-4930-9d83-d2861dd75ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ddbd0-1cc5-48c8-9748-2b651ec4a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters = k, init = 'k-means++',random_state = 0, n_init = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26636350-f489-4640-93f9-104208c8079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(\n",
    "    vectorizer_model = vectorizer_model,\n",
    "    umap_model = umap_model,\n",
    "    hdbscan_model = kmeans_model,\n",
    "    language=\"english\", \n",
    "    representation_model = representation_model, #diversify topic words\n",
    "    calculate_probabilities=False, \n",
    "    verbose=True, \n",
    "    #nr_topics = 'auto'\n",
    "    # min_topic_size = 50, \n",
    "    # n_gram_range = (1,2)\n",
    ")\n",
    "topics = topic_model.fit_transform(docs, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
